apiVersion: noetl.io/v2
kind: Playbook
metadata:
  name: execution_ai_analyze
  path: ops/execution_ai_analyze
  description: |
    AI-assisted execution triage playbook.
    Inputs include execution timeline, playbook YAML, event rows, and optional metrics.
    Output is a structured root-cause report with remediation and optional patch diff.

workload:
  gcp_auth: google_oauth
  openai_secret_path: projects/1014428265962/secrets/openai-api-key/versions/1
  model: gpt-4o-mini
  target_execution_id: ""
  target_playbook_path: ""
  target_playbook_status: ""
  ai_prompt: ""
  analysis_bundle: {}
  event_rows: []
  event_log_rows: []
  metric_rows: []
  cloud_context: {}
  include_patch_diff: true
  auto_fix_mode: report
  approval_required: true
  approved: false
  default_dry_run_commands:
    - noetl exec catalog://<playbook-path> -r distributed --dry-run
  default_test_commands:
    - pytest -q

keychain:
  - name: openai_token
    kind: secret_manager
    provider: gcp
    scope: global
    auth: '{{ gcp_auth }}'
    map:
      api_key: '{{ openai_secret_path }}'

workflow:
  - step: start
    desc: Validate mode and approval gates
    tool:
      kind: python
      args:
        auto_fix_mode: '{{ auto_fix_mode }}'
        approval_required: '{{ approval_required }}'
        approved: '{{ approved }}'
      code: |
        def to_bool(value):
            if isinstance(value, bool):
                return value
            return str(value).strip().lower() in {"1", "true", "yes", "y", "on"}

        mode = str(auto_fix_mode or "report").strip().lower()
        if mode not in {"report", "dry_run", "apply"}:
            mode = "report"

        need_approval = to_bool(approval_required)
        is_approved = to_bool(approved)
        blocked = mode == "apply" and need_approval and not is_approved

        result = {
            "mode": mode,
            "approval_required": need_approval,
            "approved": is_approved,
            "blocked": blocked,
            "apply_allowed": mode != "apply" or not need_approval or is_approved,
        }
    next:
      spec:
        mode: exclusive
      arcs:
        - step: approval_blocked
          when: '{{ start.blocked }}'
        - step: openai_triage
          when: '{{ not start.blocked }}'

  - step: approval_blocked
    desc: Return guardrail report when apply mode is not approved
    tool:
      kind: python
      args:
        default_dry_run_commands: '{{ default_dry_run_commands }}'
        default_test_commands: '{{ default_test_commands }}'
      code: |
        dry_run_commands = default_dry_run_commands if isinstance(default_dry_run_commands, list) else []
        test_commands = default_test_commands if isinstance(default_test_commands, list) else []

        result = {
            "ai_report": {
                "executive_summary": "Apply mode was requested without explicit approval. No patch was produced.",
                "primary_bottlenecks": ["Approval gate blocked apply mode."],
                "failure_risk_analysis": [
                    "Applying generated patches without review is disabled by policy.",
                ],
                "recommended_dsl_runtime_changes": [
                    {
                        "priority": "high",
                        "title": "Require explicit approve/apply",
                        "change": "Set approved=true only after reviewing proposed diff and validation plan.",
                        "rationale": "Prevents unsafe automated changes.",
                    }
                ],
                "validation_plan": [
                    "Run dry-run first.",
                    "Run test suite before manual apply.",
                ],
                "proposed_patch_diff": "",
                "dry_run_commands": dry_run_commands,
                "test_commands": test_commands,
                "apply_checklist": [
                    "Review report and diff.",
                    "Run dry-run + tests.",
                    "Approve and apply manually.",
                ],
            },
            "dry_run_recommended": True,
            "auto_fix_mode": "apply",
            "approval_required": True,
            "approved": False,
            "apply_allowed": False,
        }
    next:
      spec:
        mode: exclusive
      arcs:
        - step: end

  - step: openai_triage
    desc: Generate structured triage report with OpenAI
    tool:
      kind: http
      method: POST
      url: "https://api.openai.com/v1/chat/completions"
      headers:
        Authorization: "Bearer {{ keychain.openai_token.api_key }}"
        Content-Type: "application/json"
      payload:
        model: '{{ model }}'
        messages:
          - role: system
            content: |
              You are a senior NoETL platform engineer. Analyze execution diagnostics and produce actionable triage.
              Return strictly JSON (no markdown) with keys:
              - executive_summary: string
              - primary_bottlenecks: string[]
              - failure_risk_analysis: string[]
              - recommended_dsl_runtime_changes: array of objects {priority,title,change,rationale}
              - validation_plan: string[]
              - proposed_patch_diff: string (unified diff; empty string when not applicable)
              - dry_run_commands: string[]
              - test_commands: string[]
              - apply_checklist: string[]
              - confidence: number (0-1)

              Constraints:
              - Do NOT invent unavailable logs.
              - If uncertain, state assumptions explicitly in executive_summary.
              - proposed_patch_diff must stay proposal-only; never claim change is applied.
              - Keep recommendations prioritized and concrete.
          - role: user
            content: |
              {
                "target_execution_id": "{{ target_execution_id }}",
                "target_playbook_path": "{{ target_playbook_path }}",
                "target_playbook_status": "{{ target_playbook_status }}",
                "auto_fix_mode": "{{ start.mode }}",
                "include_patch_diff": {{ include_patch_diff | tojson }},
                "analysis_bundle": {{ analysis_bundle | tojson }},
                "event_rows": {{ event_rows | tojson }},
                "event_log_rows": {{ event_log_rows | tojson }},
                "metric_rows": {{ metric_rows | tojson }},
                "cloud_context": {{ cloud_context | tojson }},
                "fallback_prompt": {{ ai_prompt | tojson }},
                "default_dry_run_commands": {{ default_dry_run_commands | tojson }},
                "default_test_commands": {{ default_test_commands | tojson }}
              }
    next:
      spec:
        mode: exclusive
      arcs:
        - step: parse_ai_report

  - step: parse_ai_report
    desc: Parse OpenAI output into normalized report payload
    tool:
      kind: python
      libs:
        json: json
        re: re
      args:
        openai_response: '{{ openai_triage }}'
        auto_fix_mode: '{{ start.mode }}'
        include_patch_diff: '{{ include_patch_diff }}'
        default_dry_run_commands: '{{ default_dry_run_commands }}'
        default_test_commands: '{{ default_test_commands }}'
        approval_required: '{{ start.approval_required }}'
        approved: '{{ start.approved }}'
      code: |
        def to_bool(value):
            if isinstance(value, bool):
                return value
            return str(value).strip().lower() in {"1", "true", "yes", "y", "on"}

        raw = ""
        if isinstance(openai_response, dict):
            payload = openai_response.get("data")
            if isinstance(payload, str):
                try:
                    payload = json.loads(payload)
                except Exception:
                    payload = {}

            if isinstance(payload, dict):
                choices = payload.get("choices", [])
                if choices:
                    raw = choices[0].get("message", {}).get("content", "")

        raw = str(raw or "").strip()
        if raw.startswith("```"):
            raw = re.sub(r"^```[a-zA-Z0-9_\-]*\n?", "", raw)
            raw = re.sub(r"\n?```$", "", raw)
            raw = raw.strip()

        parsed = {}
        if raw:
            try:
                parsed = json.loads(raw)
            except Exception:
                parsed = {
                    "executive_summary": raw,
                    "primary_bottlenecks": [],
                    "failure_risk_analysis": [],
                    "recommended_dsl_runtime_changes": [],
                    "validation_plan": [],
                    "proposed_patch_diff": "",
                    "confidence": 0.0,
                }

        if not isinstance(parsed, dict):
            parsed = {}

        def as_list(value):
            if isinstance(value, list):
                return value
            if value is None:
                return []
            return [value]

        include_diff = to_bool(include_patch_diff)
        report = {
            "executive_summary": str(parsed.get("executive_summary") or "No executive summary generated."),
            "primary_bottlenecks": as_list(parsed.get("primary_bottlenecks")),
            "failure_risk_analysis": as_list(parsed.get("failure_risk_analysis")),
            "recommended_dsl_runtime_changes": as_list(parsed.get("recommended_dsl_runtime_changes")),
            "validation_plan": as_list(parsed.get("validation_plan")),
            "proposed_patch_diff": str(parsed.get("proposed_patch_diff") or "") if include_diff else "",
            "dry_run_commands": as_list(parsed.get("dry_run_commands")) or as_list(default_dry_run_commands),
            "test_commands": as_list(parsed.get("test_commands")) or as_list(default_test_commands),
            "apply_checklist": as_list(parsed.get("apply_checklist")) or [
                "Review proposed patch diff.",
                "Run dry-run commands.",
                "Run tests.",
                "Approve and apply manually.",
            ],
            "confidence": parsed.get("confidence", 0.0),
        }

        mode = str(auto_fix_mode or "report").strip().lower()
        need_approval = to_bool(approval_required)
        is_approved = to_bool(approved)

        result = {
            "ai_report": report,
            "raw_response_text": raw,
            "dry_run_recommended": True,
            "auto_fix_mode": mode,
            "approval_required": need_approval,
            "approved": is_approved,
            "apply_allowed": mode != "apply" or not need_approval or is_approved,
        }
    next:
      spec:
        mode: exclusive
      arcs:
        - step: end

  - step: end
    desc: Complete AI analysis
    tool:
      kind: noop
