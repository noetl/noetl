apiVersion: noetl.io/v2
kind: Playbook
metadata:
  name: test_pipeline_error_handling
  path: tests/pagination/pipeline/errors
  description: |
    Tests tool.eval error handling patterns in task sequence execution.

    Validates:
    - Retry on transient errors (500, 503)
    - Rate limit handling with Retry-After header
    - Continue on transform errors (skip pattern)
    - Fail on auth errors (401, 403)
    - outcome variable access in eval conditions

workload:
  api_url: "http://paginated-api.test-server.svc.cluster.local:5555"

vars:
  test_results: []
  current_test: null

workflow:
  - step: start
    desc: Initialize error handling tests
    tool:
      kind: python
      code: |
        result = {
          "status": "initialized",
          "tests_to_run": [
            "retry_on_500",
            "retry_on_rate_limit",
            "skip_transform_error",
            "fail_on_auth_error"
          ]
        }
    next:
      - step: test_retry_transient

  - step: test_retry_transient
    desc: Test retry on 500 errors with flaky endpoint
    tool:
      - reset_flaky:
          kind: http
          url: "{{ workload.api_url }}/api/v1/flaky/reset"
          method: POST

      - fetch_flaky:
          kind: http
          url: "{{ workload.api_url }}/api/v1/flaky"
          method: GET
          params:
            page: 1
            fail_on: "1"
          eval:
            - expr: "{{ outcome.error.retryable and outcome.error.kind == 'server_error' }}"
              do: retry
              attempts: 3
              backoff: linear
              delay: 0.5
            - expr: "{{ outcome.status == 'error' }}"
              do: fail
            - else:
                do: continue

      - validate:
          kind: python
          args:
            http_response: "{{ _prev }}"
          code: |
            response_body = http_response.get('data', {})
            data = response_body.get('data', [])
            result = {
              'test': 'retry_on_500',
              'status': 'passed' if len(data) > 0 else 'failed',
              'items_received': len(data),
              'message': 'Retry succeeded after 500 error'
            }
    next:
      - step: test_rate_limit

  - step: test_rate_limit
    desc: Test rate limit handling with Retry-After header
    tool:
      - fetch_1:
          kind: http
          url: "{{ workload.api_url }}/api/v1/rate-limited"
          method: GET
          params:
            page: 1
            requests_per_second: 1
          eval:
            - expr: "{{ outcome.error.kind == 'rate_limit' }}"
              do: retry
              attempts: 5
              delay: 2.0
            - expr: "{{ outcome.error.retryable }}"
              do: retry
              attempts: 3
            - expr: "{{ outcome.status == 'error' }}"
              do: fail
            - else:
                do: continue

      - fetch_2:
          kind: http
          url: "{{ workload.api_url }}/api/v1/rate-limited"
          method: GET
          params:
            page: 2
            requests_per_second: 1
          eval:
            - expr: "{{ outcome.error.kind == 'rate_limit' }}"
              do: retry
              attempts: 5
              delay: 2.0
            - expr: "{{ outcome.error.retryable }}"
              do: retry
              attempts: 3
            - expr: "{{ outcome.status == 'error' }}"
              do: fail
            - else:
                do: continue

      - validate:
          kind: python
          args:
            http_response: "{{ _prev }}"
          code: |
            response_body = http_response.get('data', {})
            data = response_body.get('data', [])
            result = {
              'test': 'retry_on_rate_limit',
              'status': 'passed',
              'items_received': len(data),
              'message': 'Rate limit handled correctly'
            }
    next:
      - step: test_skip_transform

  - step: test_skip_transform
    desc: Test continue action on transform errors (skip pattern)
    tool:
      - fetch:
          kind: http
          url: "{{ workload.api_url }}/api/v1/assessments"
          method: GET
          params:
            page: 1

      - transform_bad:
          kind: python
          args:
            http_response: "{{ _prev }}"
          code: |
            broken = http_response['nonexistent_key']['also_missing']
            result = broken
          eval:
            - expr: "{{ outcome.status == 'error' }}"
              do: continue
            - else:
                do: continue

      - validate:
          kind: python
          args:
            prev_data: "{{ _prev }}"
          code: |
            result = {
              'test': 'skip_transform_error',
              'status': 'passed',
              'skipped': True,
              'prev_after_skip': prev_data,
              'message': 'Transform error was skipped successfully'
            }
    next:
      - step: test_fail_auth

  - step: test_fail_auth
    desc: Test fail action on auth errors
    tool:
      - fetch_auth_error:
          kind: http
          url: "{{ workload.api_url }}/api/v1/errors"
          method: GET
          params:
            error_type: "auth"
          eval:
            - expr: "{{ outcome.error.kind == 'auth' }}"
              do: fail
            - else:
                do: continue

      - should_not_reach:
          kind: python
          code: |
            result = {'error': 'This should not execute'}
    next:
      - step: generate_report

  - step: generate_report
    desc: Generate test results report
    tool:
      kind: python
      args:
        results: "{{ vars.test_results }}"
      code: |
        passed = sum(1 for r in results if r.get('status') == 'passed')
        failed = sum(1 for r in results if r.get('status') == 'failed')
        total = len(results)

        result = {
          "status": "success" if failed == 0 else "failed",
          "summary": {
            "total_tests": total,
            "passed": passed,
            "failed": failed
          },
          "test_results": results,
          "tool_eval_features_tested": [
            "retry with exponential backoff",
            "retry with Retry-After header",
            "continue on error (skip pattern)",
            "fail on non-retryable errors",
            "outcome.error.kind condition matching",
            "outcome.error.retryable boolean check",
            "outcome.status check"
          ]
        }
    next:
      - step: end

  - step: end
    desc: Tests complete
    tool:
      kind: noop
