apiVersion: noetl.io/v2
kind: Playbook
metadata:
  name: test_pipeline_heavy_payload
  path: tests/pagination/pipeline/heavy
  description: 'Heavy payload task sequence test for load testing result storage and
    threading.


    Tests:

    - Large HTTP responses (configurable KB per item)

    - Result externalization to NATS KV/Object Store

    - _prev threading with large data

    - Memory-efficient task sequence execution

    '
workload:
  api_url: http://paginated-api.test-server.svc.cluster.local:5555
  payload_kb_per_item: 50
  page_size: 5
  max_pages: 3
  current_page: 1
  pages_processed: 0
  total_bytes_processed: 0
workflow:
- step: start
  desc: Initialize heavy payload test
  tool:
    kind: python
    code: "result = {\n  \"status\": \"initialized\",\n  \"test\": \"heavy_payload_task_sequence\"\
      ,\n  \"config\": {\n    \"payload_kb_per_item\": {{ payload_kb_per_item }},\n\
      \    \"page_size\": {{ page_size }},\n    \"estimated_kb_per_page\": {{ payload_kb_per_item\
      \ }} * {{ page_size }}\n  }\n}\n"
  set_ctx:
    current_page: '{{ workload.current_page }}'
    pages_processed: '{{ workload.pages_processed }}'
    total_bytes_processed: '{{ workload.total_bytes_processed }}'
  next:
    spec:
      mode: exclusive
    arcs:
    - step: fetch_heavy_page
- step: fetch_heavy_page
  desc: Task sequence for heavy payload processing
  tool:
  - name: fetch
    kind: http
    url: '{{ api_url }}/api/v1/heavy'
    method: GET
    params:
      page: '{{ ctx.current_page }}'
      pageSize: '{{ page_size }}'
      payload_kb: '{{ payload_kb_per_item }}'
    output_select:
      strategy: size_threshold
      threshold_kb: 100
    spec:
      policy:
        rules:
        - when: '{{ outcome.error.retryable }}'
          then:
            do: retry
            attempts: 3
            backoff: exponential
            delay: 2.0
        - when: '{{ outcome.status == ''error'' }}'
          then:
            do: fail
        - else:
            then:
              do: continue
  - name: process
    kind: python
    args:
      http_response: '{{ _prev }}'
      page_num: '{{ ctx.current_page }}'
    code: "import sys\n\nresponse_body = http_response.get('data', {})\nitems = response_body.get('data',\
      \ [])\npaging = response_body.get('paging', {})\nmeta = response_body.get('meta',\
      \ {})\n\ntotal_payload_size = sum(\n    len(item.get('payload', '')) for item\
      \ in items\n)\n\nsummaries = []\nfor item in items:\n    summaries.append({\n\
      \        'id': item['id'],\n        'name': item['name'],\n        'score':\
      \ item['score'],\n        'category': item.get('category', 'unknown'),\n   \
      \     'payload_size_kb': len(item.get('payload', '')) // 1024\n    })\n\nresult\
      \ = {\n    'page': page_num,\n    'items_count': len(items),\n    'total_payload_kb':\
      \ total_payload_size // 1024,\n    'has_more': paging.get('hasMore', False),\n\
      \    'summaries': summaries,\n    'meta': meta\n}\n"
    spec:
      policy:
        rules:
        - when: '{{ outcome.status == ''error'' }}'
          then:
            do: continue
        - else:
            then:
              do: continue
  - name: summarize
    kind: python
    args:
      processed: '{{ _prev }}'
    code: "result = {\n    'page': processed['page'],\n    'items_processed': processed['items_count'],\n\
      \    'payload_kb': processed['total_payload_kb'],\n    'has_more': processed['has_more'],\n\
      \    'status': 'processed'\n}\n"
  next:
    spec:
      mode: exclusive
    arcs:
    - step: update_progress
- step: update_progress
  desc: Update progress and check continuation
  tool:
    kind: python
    args:
      result: '{{ fetch_heavy_page }}'
      current_page: '{{ ctx.current_page }}'
      max_pages: '{{ max_pages }}'
      total_bytes: '{{ ctx.total_bytes_processed }}'
    code: "has_more = result.get('has_more', False) if isinstance(result, dict) else\
      \ False\npayload_kb = result.get('payload_kb', 0) if isinstance(result, dict)\
      \ else 0\n\nshould_continue = has_more and int(current_page) < int(max_pages)\n\
      \nresult = {\n  \"current_page\": current_page,\n  \"payload_kb_this_page\"\
      : payload_kb,\n  \"total_bytes_processed\": int(total_bytes) + (payload_kb *\
      \ 1024),\n  \"has_more\": has_more,\n  \"should_continue\": should_continue,\n\
      \  \"reason\": \"more pages available\" if should_continue else \"limit reached\
      \ or no more pages\"\n}\n"
    spec:
      policy:
        rules:
        - else:
            then:
              do: continue
              set_ctx:
                current_page: '{{ (ctx.current_page | int) + 1 }}'
                pages_processed: '{{ (ctx.pages_processed | int) + 1 }}'
                total_bytes_processed: '{{ update_progress.total_bytes_processed }}'
  next:
    spec:
      mode: exclusive
    arcs:
    - step: fetch_heavy_page
      when: '{{ update_progress.should_continue == true }}'
    - step: final_report
      when: '{{ update_progress.should_continue != true }}'
- step: final_report
  desc: Generate test summary
  tool:
    kind: python
    args:
      pages_processed: '{{ ctx.pages_processed }}'
      total_bytes: '{{ ctx.total_bytes_processed }}'
      payload_kb_per_item: '{{ payload_kb_per_item }}'
      page_size: '{{ page_size }}'
    code: "total_kb = int(total_bytes) // 1024\ntotal_mb = total_kb / 1024\n\nresult\
      \ = {\n  \"status\": \"ok\",\n  \"summary\": {\n    \"pages_processed\": int(pages_processed),\n\
      \    \"total_data_processed_kb\": total_kb,\n    \"total_data_processed_mb\"\
      : round(total_mb, 2),\n    \"avg_kb_per_page\": total_kb // max(1, int(pages_processed)),\n\
      \    \"config\": {\n      \"payload_kb_per_item\": int(payload_kb_per_item),\n\
      \      \"page_size\": int(page_size)\n    }\n  },\n  \"features_tested\": [\n\
      \    \"Heavy HTTP responses with configurable payload\",\n    \"Result externalization\
      \ via output_select\",\n    \"_prev threading with large data\",\n    \"spec.policy.rules\
      \ flow control\",\n    \"Memory-efficient data processing\"\n  ]\n}\n"
  next:
    spec:
      mode: exclusive
    arcs:
    - step: end
- step: end
  desc: Test complete
  tool:
    kind: noop
