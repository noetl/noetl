{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fa2c2502",
   "metadata": {},
   "source": [
    "## 1. Setup and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cd7ad672",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Configuration loaded\n",
      "  Environment: localhost\n",
      "  Server: http://localhost:8082\n",
      "  Database: localhost:54321/demo_noetl\n",
      "  Test: tests/pagination/loop_with_pagination/loop_with_pagination\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import json\n",
    "import requests\n",
    "from typing import Dict\n",
    "\n",
    "# Modern data stack\n",
    "import psycopg\n",
    "import polars as pl\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# Configuration - Auto-detect environment\n",
    "# Set NOETL_ENV=kubernetes to run against in-cluster services\n",
    "# Set NOETL_ENV=localhost (default) to run against port-forwarded services\n",
    "ENVIRONMENT = os.getenv(\"NOETL_ENV\", \"localhost\").lower()\n",
    "\n",
    "if ENVIRONMENT == \"kubernetes\":\n",
    "    # In-cluster configuration\n",
    "    DB_CONFIG = {\n",
    "        \"host\": \"postgres.postgres.svc.cluster.local\",\n",
    "        \"port\": \"5432\",\n",
    "        \"user\": os.getenv(\"POSTGRES_USER\", \"demo\"),\n",
    "        \"password\": os.getenv(\"POSTGRES_PASSWORD\", \"demo\"),\n",
    "        \"dbname\": os.getenv(\"POSTGRES_DB\", \"demo_noetl\")\n",
    "    }\n",
    "    NOETL_SERVER_URL = \"http://noetl.noetl.svc.cluster.local:8082\"\n",
    "else:\n",
    "    # Localhost configuration (port-forwarded from kind cluster)\n",
    "    DB_CONFIG = {\n",
    "        \"host\": \"localhost\",\n",
    "        \"port\": \"54321\",  # Maps to postgres NodePort 30321\n",
    "        \"user\": os.getenv(\"POSTGRES_USER\", \"demo\"),\n",
    "        \"password\": os.getenv(\"POSTGRES_PASSWORD\", \"demo\"),\n",
    "        \"dbname\": os.getenv(\"POSTGRES_DB\", \"demo_noetl\")\n",
    "    }\n",
    "    NOETL_SERVER_URL = \"http://localhost:8082\"  # Maps to noetl NodePort 30082\n",
    "\n",
    "TEST_PATH = \"tests/pagination/loop_with_pagination/loop_with_pagination\"\n",
    "POLL_INTERVAL = 2\n",
    "MAX_WAIT = 120\n",
    "\n",
    "print(\"‚úì Configuration loaded\")\n",
    "print(f\"  Environment: {ENVIRONMENT}\")\n",
    "print(f\"  Server: {NOETL_SERVER_URL}\")\n",
    "print(f\"  Database: {DB_CONFIG['host']}:{DB_CONFIG['port']}/{DB_CONFIG['dbname']}\")\n",
    "print(f\"  Test: {TEST_PATH}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7f3ab61",
   "metadata": {},
   "source": [
    "## 2. Initialize Test Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d6a9a4c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Test table created\n",
      "  Schema: noetl_test\n",
      "  Table: pagination_loop_results\n"
     ]
    }
   ],
   "source": [
    "# Create test schema and table - completely self-contained\n",
    "import os\n",
    "import psycopg\n",
    "\n",
    "def get_postgres_connection():\n",
    "    \"\"\"Get psycopg3 connection\"\"\"\n",
    "    conn_string = f\"host={os.getenv('POSTGRES_HOST', 'postgres.postgres.svc.cluster.local')} \" \\\n",
    "                  f\"port={os.getenv('POSTGRES_PORT', '5432')} \" \\\n",
    "                  f\"dbname={os.getenv('POSTGRES_DB', 'demo_noetl')} \" \\\n",
    "                  f\"user={os.getenv('POSTGRES_USER', 'demo')} \" \\\n",
    "                  f\"password={os.getenv('POSTGRES_PASSWORD', 'demo')}\"\n",
    "    return psycopg.connect(conn_string)\n",
    "\n",
    "create_table_sql = \"\"\"\n",
    "CREATE SCHEMA IF NOT EXISTS noetl_test;\n",
    "\n",
    "DROP TABLE IF EXISTS noetl_test.pagination_loop_results;\n",
    "\n",
    "CREATE TABLE noetl_test.pagination_loop_results (\n",
    "    id SERIAL PRIMARY KEY,\n",
    "    execution_id BIGINT,\n",
    "    endpoint_name TEXT,\n",
    "    endpoint_path TEXT,\n",
    "    page_size INTEGER,\n",
    "    result_count INTEGER,\n",
    "    result_data JSONB,\n",
    "    iteration_index INTEGER,\n",
    "    iteration_count INTEGER,\n",
    "    created_at TIMESTAMP DEFAULT NOW()\n",
    ");\n",
    "\n",
    "CREATE INDEX IF NOT EXISTS idx_pagination_loop_execution_id \n",
    "ON noetl_test.pagination_loop_results(execution_id);\n",
    "\"\"\"\n",
    "\n",
    "with get_postgres_connection() as conn:\n",
    "    with conn.cursor() as cur:\n",
    "        cur.execute(create_table_sql)\n",
    "        conn.commit()\n",
    "\n",
    "print(\"‚úì Test table created\")\n",
    "print(\"  Schema: noetl_test\")\n",
    "print(\"  Table: pagination_loop_results\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af508ab3",
   "metadata": {},
   "source": [
    "## 3. Database Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4d726b13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Database utilities loaded\n"
     ]
    }
   ],
   "source": [
    "def get_postgres_connection():\n",
    "    \"\"\"Get psycopg3 connection\"\"\"\n",
    "    conn_string = f\"host={DB_CONFIG['host']} port={DB_CONFIG['port']} \" \\\n",
    "                  f\"dbname={DB_CONFIG['dbname']} user={DB_CONFIG['user']} \" \\\n",
    "                  f\"password={DB_CONFIG['password']}\"\n",
    "    return psycopg.connect(conn_string)\n",
    "\n",
    "def query_to_polars(query: str) -> pl.DataFrame:\n",
    "    \"\"\"Execute query and return as Polars DataFrame\"\"\"\n",
    "    with get_postgres_connection() as conn:\n",
    "        with conn.cursor() as cur:\n",
    "            cur.execute(query)\n",
    "            columns = [desc[0] for desc in cur.description]\n",
    "            data = cur.fetchall()\n",
    "    if not data:\n",
    "        return pl.DataFrame(schema=columns)\n",
    "    return pl.DataFrame({col: [row[i] for row in data] for i, col in enumerate(columns)})\n",
    "\n",
    "print(\"‚úì Database utilities loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaaf6898",
   "metadata": {},
   "source": [
    "## 4. Execute Pagination Loop Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fe58cc86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting test: tests/pagination/loop_with_pagination/loop_with_pagination\n",
      "‚úì Test started\n",
      "  Execution ID: 512664515830350754\n",
      "  Status: running\n"
     ]
    }
   ],
   "source": [
    "def start_test() -> Dict:\n",
    "    \"\"\"Start pagination loop test\"\"\"\n",
    "    url = f\"{NOETL_SERVER_URL}/api/run/playbook\"\n",
    "    payload = {\"path\": TEST_PATH}\n",
    "    \n",
    "    print(f\"Starting test: {TEST_PATH}\")\n",
    "    response = requests.post(url, json=payload, timeout=30)\n",
    "    response.raise_for_status()\n",
    "    \n",
    "    result = response.json()\n",
    "    execution_id = result['execution_id']\n",
    "    \n",
    "    print(f\"‚úì Test started\")\n",
    "    print(f\"  Execution ID: {execution_id}\")\n",
    "    print(f\"  Status: {result['status']}\")\n",
    "    \n",
    "    return result\n",
    "\n",
    "test_result = start_test()\n",
    "EXECUTION_ID = test_result['execution_id']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab0052ed",
   "metadata": {},
   "source": [
    "## 5. Monitor Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2ffd9d8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Monitoring execution 512664515830350754...\n",
      "Time   Steps  Status       Events\n",
      "--------------------------------------------------\n",
      "0      0      COMPLETED    15\n",
      "\n",
      "‚úì Test completed in 0s\n"
     ]
    }
   ],
   "source": [
    "def monitor_execution(execution_id: int):\n",
    "    \"\"\"Monitor test execution\"\"\"\n",
    "    start_time = time.time()\n",
    "    last_count = 0\n",
    "    \n",
    "    print(f\"Monitoring execution {execution_id}...\")\n",
    "    print(f\"{'Time':<6} {'Steps':<6} {'Status':<12} {'Events'}\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    while (time.time() - start_time) < MAX_WAIT:\n",
    "        query = f\"\"\"\n",
    "            SELECT event_type, COUNT(*) as count\n",
    "            FROM noetl.event\n",
    "            WHERE execution_id = {execution_id}\n",
    "            GROUP BY event_type\n",
    "        \"\"\"\n",
    "        df = query_to_polars(query)\n",
    "        \n",
    "        step_count = df.filter(pl.col('event_type') == 'step_completed')['count'].sum() or 0\n",
    "        is_complete = df.filter(pl.col('event_type') == 'playbook_completed').height > 0\n",
    "        is_failed = df.filter(pl.col('event_type') == 'playbook_failed').height > 0\n",
    "        \n",
    "        if step_count != last_count or is_complete or is_failed:\n",
    "            elapsed = int(time.time() - start_time)\n",
    "            status = \"COMPLETED\" if is_complete else (\"FAILED\" if is_failed else \"RUNNING\")\n",
    "            total = df['count'].sum()\n",
    "            print(f\"{elapsed:<6} {step_count:<6} {status:<12} {total}\")\n",
    "            last_count = step_count\n",
    "        \n",
    "        if is_complete:\n",
    "            print(f\"\\n‚úì Test completed in {elapsed}s\")\n",
    "            return True\n",
    "        elif is_failed:\n",
    "            print(f\"\\n‚úó Test failed after {elapsed}s\")\n",
    "            return False\n",
    "        \n",
    "        time.sleep(POLL_INTERVAL)\n",
    "    \n",
    "    print(f\"\\n‚ö† Timeout after {MAX_WAIT}s\")\n",
    "    return False\n",
    "\n",
    "success = monitor_execution(EXECUTION_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11dbd3b2",
   "metadata": {},
   "source": [
    "## 6. Validate Iterator Event Architecture\n",
    "\n",
    "**Expected Behavior:**\n",
    "1. Worker detects `loop` configuration in step\n",
    "2. Routes to iterator executor \n",
    "3. Analyzes collection (filter, sort, limit)\n",
    "4. Emits `iterator_started` event with metadata\n",
    "5. Server should process event and enqueue iteration jobs (NOT YET IMPLEMENTED)\n",
    "\n",
    "This section verifies the distributed loop architecture is working correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "187db13d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä Iterator Event Validation for Execution 512664515830350754\n",
      "================================================================================\n",
      "\n",
      "‚úì Event Flow (15 events):\n",
      "  playbook_started          STARTED      tests/pagination/loop_with_pagination/loop_with_pagination\n",
      "  workflow_initialized      COMPLETED    workflow\n",
      "  iterator_started          RUNNING      iterator\n",
      "  action_started            RUNNING      fetch_all_endpoints_iter_0\n",
      "  action_completed          COMPLETED    fetch_all_endpoints_iter_0\n",
      "  action_completed          COMPLETED    fetch_all_endpoints\n",
      "  workflow_completed        COMPLETED    workflow\n",
      "  playbook_completed        COMPLETED    tests/pagination/loop_with_pagination/loop_with_pagination\n",
      "  step_result               COMPLETED    fetch_all_endpoints_iter_0\n",
      "  action_started            RUNNING      fetch_all_endpoints_iter_1\n",
      "  action_completed          COMPLETED    fetch_all_endpoints_iter_1\n",
      "  step_result               COMPLETED    fetch_all_endpoints_iter_1\n",
      "  action_started            RUNNING      fetch_all_endpoints_iter_2\n",
      "  action_completed          COMPLETED    fetch_all_endpoints_iter_2\n",
      "  step_result               COMPLETED    fetch_all_endpoints_iter_2\n",
      "\n",
      "‚úì iterator_started Event Found:\n",
      "  Status:           RUNNING\n",
      "  Total Count:      3\n",
      "  Collection Size:  3\n",
      "  Mode:             sequential\n",
      "  Iterator Name:    endpoint\n",
      "  Nested Tool:      http\n",
      "\n",
      "‚úì Iterator Metadata:\n",
      "  Collection: [\n",
      "  {\n",
      "    \"name\": \"assessments\",\n",
      "    \"path\": \"/api/v1/assessments\",\n",
      "    \"page_size\": 10\n",
      "  },\n",
      "  {\n",
      "    \"name\": \"assessments2\",\n",
      "    \"path\": \"/api/v1/assessments\",\n",
      "    \"page_size\": 15\n",
      "  },\n",
      "  {\n",
      "    \"name\":...\n",
      "\n",
      "  Nested Task Tool: http\n",
      "  Has retry.on_success: True\n",
      "  Pagination Config:\n",
      "    - while: {{ response.paging.hasMore == true }}\n",
      "    - max_attempts: 10\n",
      "    - collect.strategy: append\n",
      "\n",
      "‚ö† No iteration_completed events found\n",
      "  This is EXPECTED - Server orchestrator doesn't yet process iterator_started\n",
      "  Next Implementation Step: Add _process_iterator_started() handler in orchestrator.py\n",
      "\n",
      "================================================================================\n",
      "VALIDATION SUMMARY:\n",
      "================================================================================\n",
      "‚úÖ Worker Event Callback: WORKING\n",
      "‚úÖ Iterator Executor: WORKING\n",
      "‚úÖ iterator_started Event: EMITTED\n",
      "‚úÖ Event Schema: VALID\n",
      "‚è≥ Server Orchestrator: NOT YET IMPLEMENTED\n",
      "\n",
      "Next: Implement server-side iterator_started event processing to enqueue iteration jobs\n"
     ]
    }
   ],
   "source": [
    "# Validate iterator event architecture\n",
    "print(f\"\\nüìä Iterator Event Validation for Execution {EXECUTION_ID}\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# 1. Check basic event flow\n",
    "events_query = f\"\"\"\n",
    "    SELECT \n",
    "        event_type,\n",
    "        node_name,\n",
    "        status,\n",
    "        created_at\n",
    "    FROM noetl.event\n",
    "    WHERE execution_id = {EXECUTION_ID}\n",
    "    ORDER BY event_id\n",
    "\"\"\"\n",
    "events_df = query_to_polars(events_query)\n",
    "\n",
    "print(f\"\\n‚úì Event Flow ({events_df.height} events):\")\n",
    "for row in events_df.iter_rows(named=True):\n",
    "    print(f\"  {row['event_type']:25} {row['status']:12} {row['node_name'] or ''}\")\n",
    "\n",
    "# 2. Check iterator_started event exists\n",
    "iterator_check = f\"\"\"\n",
    "    SELECT \n",
    "        event_type,\n",
    "        status,\n",
    "        context->>'total_count' as total_count,\n",
    "        context->>'mode' as mode,\n",
    "        context->>'iterator_name' as iterator_name,\n",
    "        jsonb_array_length(context->'collection') as collection_size,\n",
    "        context->'nested_task'->>'tool' as nested_tool\n",
    "    FROM noetl.event\n",
    "    WHERE execution_id = {EXECUTION_ID}\n",
    "      AND event_type = 'iterator_started'\n",
    "\"\"\"\n",
    "iterator_df = query_to_polars(iterator_check)\n",
    "\n",
    "if iterator_df.height > 0:\n",
    "    print(f\"\\n‚úì iterator_started Event Found:\")\n",
    "    row = iterator_df.row(0, named=True)\n",
    "    print(f\"  Status:           {row['status']}\")\n",
    "    print(f\"  Total Count:      {row['total_count']}\")\n",
    "    print(f\"  Collection Size:  {row['collection_size']}\")\n",
    "    print(f\"  Mode:             {row['mode']}\")\n",
    "    print(f\"  Iterator Name:    {row['iterator_name']}\")\n",
    "    print(f\"  Nested Tool:      {row['nested_tool']}\")\n",
    "else:\n",
    "    print(\"\\n‚ùå iterator_started event NOT FOUND!\")\n",
    "    print(\"   This means the event callback integration failed.\")\n",
    "\n",
    "# 3. Check iterator metadata\n",
    "if iterator_df.height > 0:\n",
    "    metadata_query = f\"\"\"\n",
    "        SELECT \n",
    "            context->'collection' as collection,\n",
    "            context->'nested_task' as nested_task\n",
    "        FROM noetl.event\n",
    "        WHERE execution_id = {EXECUTION_ID}\n",
    "          AND event_type = 'iterator_started'\n",
    "    \"\"\"\n",
    "    \n",
    "    with get_postgres_connection() as conn:\n",
    "        with conn.cursor() as cur:\n",
    "            cur.execute(metadata_query)\n",
    "            result = cur.fetchone()\n",
    "            if result:\n",
    "                collection = result[0]\n",
    "                nested_task = result[1]\n",
    "                \n",
    "                print(f\"\\n‚úì Iterator Metadata:\")\n",
    "                print(f\"  Collection: {json.dumps(collection, indent=2)[:200]}...\")\n",
    "                print(f\"\\n  Nested Task Tool: {nested_task.get('tool')}\")\n",
    "                print(f\"  Has retry.on_success: {'retry' in nested_task and 'on_success' in nested_task.get('retry', {})}\")\n",
    "                \n",
    "                if 'retry' in nested_task and 'on_success' in nested_task['retry']:\n",
    "                    retry_config = nested_task['retry']['on_success']\n",
    "                    print(f\"  Pagination Config:\")\n",
    "                    print(f\"    - while: {retry_config.get('while', 'N/A')[:60]}\")\n",
    "                    print(f\"    - max_attempts: {retry_config.get('max_attempts', 'N/A')}\")\n",
    "                    print(f\"    - collect.strategy: {retry_config.get('collect', {}).get('strategy', 'N/A')}\")\n",
    "\n",
    "# 4. Check for expected next events (iteration jobs)\n",
    "iteration_check = f\"\"\"\n",
    "    SELECT COUNT(*) as count\n",
    "    FROM noetl.event\n",
    "    WHERE execution_id = {EXECUTION_ID}\n",
    "      AND event_type = 'iteration_completed'\n",
    "\"\"\"\n",
    "iteration_df = query_to_polars(iteration_check)\n",
    "\n",
    "if iteration_df['count'][0] > 0:\n",
    "    print(f\"\\n‚úì Found {iteration_df['count'][0]} iteration_completed events\")\n",
    "    print(\"  Server successfully processed iterator_started and enqueued iteration jobs!\")\n",
    "else:\n",
    "    print(f\"\\n‚ö† No iteration_completed events found\")\n",
    "    print(\"  This is EXPECTED - Server orchestrator doesn't yet process iterator_started\")\n",
    "    print(\"  Next Implementation Step: Add _process_iterator_started() handler in orchestrator.py\")\n",
    "\n",
    "# 5. Summary\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"VALIDATION SUMMARY:\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "if iterator_df.height > 0:\n",
    "    print(\"‚úÖ Worker Event Callback: WORKING\")\n",
    "    print(\"‚úÖ Iterator Executor: WORKING\") \n",
    "    print(\"‚úÖ iterator_started Event: EMITTED\")\n",
    "    print(\"‚úÖ Event Schema: VALID\")\n",
    "    print(\"‚è≥ Server Orchestrator: NOT YET IMPLEMENTED\")\n",
    "    print(\"\\nNext: Implement server-side iterator_started event processing to enqueue iteration jobs\")\n",
    "else:\n",
    "    print(\"‚ùå Iterator event architecture validation FAILED\")\n",
    "    print(\"   Check worker logs for event emission errors\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82325d5b",
   "metadata": {},
   "source": [
    "## 7. Architecture Status & Next Steps\n",
    "\n",
    "**‚úÖ Completed Implementation:**\n",
    "- Worker-side event callback integration\n",
    "- Iterator executor analysis and event emission  \n",
    "- Event schema extensions (iterator_started, iterator_completed, etc.)\n",
    "- Environment-aware configuration (localhost/kubernetes)\n",
    "\n",
    "**‚è≥ Pending Implementation:**\n",
    "- Server orchestrator `_process_iterator_started()` handler\n",
    "- Iteration job enqueueing logic\n",
    "- Iteration execution with pagination (retry.on_success)\n",
    "- `iterator_completed` event emission after all iterations\n",
    "\n",
    "**Note:** The test will timeout until server-side processing is implemented."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "67f4abfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìã Events for Execution 512664515830350754\n",
      "========================================================================================================================\n",
      "#    Event Type                Node                      Type         Status       Details              Created\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "  1   playbook_started          tests/pagination/loop_with_pagination/loop_with_pagination execution    STARTED                           2025-12-08 08:12:52.720337\n",
      "  2   workflow_initialized      workflow                  workflow     COMPLETED                         2025-12-08 08:12:52.727407\n",
      "üîÑ3   iterator_started          iterator                  iterator     RUNNING      collection_size=3    2025-12-08 08:12:52.730756\n",
      "  4   action_started            fetch_all_endpoints_iter_0 task         RUNNING                           2025-12-08 08:12:53.367623\n",
      "  5   action_completed          fetch_all_endpoints_iter_0 task         COMPLETED                         2025-12-08 08:12:53.456027\n",
      "  6   action_completed          fetch_all_endpoints       iterator     COMPLETED                         2025-12-08 08:12:53.469001\n",
      "  7   workflow_completed        workflow                  workflow     COMPLETED                         2025-12-08 08:12:53.472048\n",
      "  8   playbook_completed        tests/pagination/loop_with_pagination/loop_with_pagination execution    COMPLETED                         2025-12-08 08:12:53.472048\n",
      "  9   step_result               fetch_all_endpoints_iter_0 task         COMPLETED                         2025-12-08 08:12:53.482955\n",
      "  10  action_started            fetch_all_endpoints_iter_1 task         RUNNING                           2025-12-08 08:12:53.526407\n",
      "  11  action_completed          fetch_all_endpoints_iter_1 task         COMPLETED                         2025-12-08 08:12:53.573460\n",
      "  12  step_result               fetch_all_endpoints_iter_1 task         COMPLETED                         2025-12-08 08:12:53.586226\n",
      "  13  action_started            fetch_all_endpoints_iter_2 task         RUNNING                           2025-12-08 08:12:53.655534\n",
      "  14  action_completed          fetch_all_endpoints_iter_2 task         COMPLETED                         2025-12-08 08:12:53.685606\n",
      "  15  step_result               fetch_all_endpoints_iter_2 task         COMPLETED                         2025-12-08 08:12:53.700521\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Total events: 15\n",
      "\n",
      "‚úÖ Iterator events detected\n",
      "   - iterator_started: 1\n",
      "   - iteration jobs: Check queue table for parent_execution_id=512664515830350754\n"
     ]
    }
   ],
   "source": [
    "def show_execution_events(execution_id: int):\n",
    "    \"\"\"Display ordered table of events for an execution\"\"\"\n",
    "    query = f\"\"\"\n",
    "        SELECT \n",
    "            ROW_NUMBER() OVER (ORDER BY event_id) as seq,\n",
    "            event_type,\n",
    "            node_name,\n",
    "            node_type,\n",
    "            status,\n",
    "            CASE \n",
    "                WHEN event_type = 'iterator_started' THEN \n",
    "                    'collection_size=' || jsonb_array_length(context->'collection')::text\n",
    "                WHEN parent_execution_id IS NOT NULL THEN\n",
    "                    'iteration=' || (context->>'iteration_index')\n",
    "                ELSE ''\n",
    "            END as details,\n",
    "            created_at\n",
    "        FROM noetl.event\n",
    "        WHERE execution_id = {execution_id}\n",
    "        ORDER BY event_id\n",
    "    \"\"\"\n",
    "    \n",
    "    df = query_to_polars(query)\n",
    "    \n",
    "    print(f\"\\nüìã Events for Execution {execution_id}\")\n",
    "    print(\"=\" * 120)\n",
    "    print(f\"{'#':<4} {'Event Type':<25} {'Node':<25} {'Type':<12} {'Status':<12} {'Details':<20} {'Created'}\")\n",
    "    print(\"-\" * 120)\n",
    "    \n",
    "    for row in df.iter_rows(named=True):\n",
    "        marker = \"üîÑ\" if \"iterator\" in row['event_type'] else \"  \"\n",
    "        node_name = row['node_name'] or '-'\n",
    "        node_type = row['node_type'] or '-'\n",
    "        status = row['status'] or '-'\n",
    "        details = row['details'] or ''\n",
    "        created = str(row['created_at']) if row['created_at'] else '-'\n",
    "        \n",
    "        print(f\"{marker}{row['seq']:<3} {row['event_type']:<25} {node_name:<25} \"\n",
    "              f\"{node_type:<12} {status:<12} {details:<20} {created}\")\n",
    "    \n",
    "    print(\"-\" * 120)\n",
    "    print(f\"Total events: {len(df)}\\n\")\n",
    "    \n",
    "    # Summary\n",
    "    iterator_events = df.filter(pl.col('event_type').str.contains('iterator'))\n",
    "    if len(iterator_events) > 0:\n",
    "        print(\"‚úÖ Iterator events detected\")\n",
    "        print(f\"   - iterator_started: {len(df.filter(pl.col('event_type') == 'iterator_started'))}\")\n",
    "        print(f\"   - iteration jobs: Check queue table for parent_execution_id={execution_id}\")\n",
    "\n",
    "# Show events for the test execution\n",
    "show_execution_events(EXECUTION_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e037b24",
   "metadata": {},
   "source": [
    "## 9. Check Iteration Jobs in Queue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d73d08bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç Queue Status for Execution 512664515830350754\n",
      "==================================================================================================================================\n",
      "Execution ID              Parent                    Node                                Status       Iter Index   Created\n",
      "----------------------------------------------------------------------------------------------------------------------------------\n",
      "   ‚úì512664515830350754      512664515830350754        fetch_all_endpoints_iter_0          done         -            2025-12-08 08:12:52.732945+00:00\n",
      "   ‚úì512664515830350754      512664515830350754        fetch_all_endpoints_iter_1          done         -            2025-12-08 08:12:52.734478+00:00\n",
      "   ‚úì512664515830350754      512664515830350754        fetch_all_endpoints_iter_2          done         -            2025-12-08 08:12:52.736483+00:00\n",
      "----------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "üìä Summary:\n",
      "   Parent jobs: 0\n",
      "   Iteration jobs: 3\n",
      "\n",
      "‚ö† Expected 2 iteration jobs, found 3\n"
     ]
    }
   ],
   "source": [
    "# Check if iteration jobs were enqueued\n",
    "queue_query = f\"\"\"\n",
    "SELECT \n",
    "    execution_id,\n",
    "    parent_execution_id,\n",
    "    node_name,\n",
    "    status,\n",
    "    context->>'iteration_index' as iteration_index,\n",
    "    context->>'iterator_name' as iterator_name,\n",
    "    created_at\n",
    "FROM noetl.queue \n",
    "WHERE parent_execution_id = {EXECUTION_ID} OR execution_id = {EXECUTION_ID}\n",
    "ORDER BY created_at\n",
    "\"\"\"\n",
    "\n",
    "df_queue = query_to_polars(queue_query)\n",
    "\n",
    "print(f\"\\nüîç Queue Status for Execution {EXECUTION_ID}\")\n",
    "print(\"=\" * 130)\n",
    "print(f\"{'Execution ID':<25} {'Parent':<25} {'Node':<35} {'Status':<12} {'Iter Index':<12} {'Created'}\")\n",
    "print(\"-\" * 130)\n",
    "\n",
    "parent_jobs = 0\n",
    "iteration_jobs = 0\n",
    "\n",
    "for row in df_queue.iter_rows(named=True):\n",
    "    exec_id = row['execution_id']\n",
    "    parent_id = row['parent_execution_id'] or '-'\n",
    "    node_name = row['node_name']\n",
    "    status = row['status']\n",
    "    iter_idx = row['iteration_index'] or '-'\n",
    "    created = row['created_at']\n",
    "    \n",
    "    marker = \"   ‚úì\" if row['parent_execution_id'] else \"   \"\n",
    "    print(f\"{marker}{exec_id:<23} {parent_id:<25} {node_name:<35} {status:<12} {iter_idx:<12} {created}\")\n",
    "    \n",
    "    if row['parent_execution_id']:\n",
    "        iteration_jobs += 1\n",
    "    else:\n",
    "        parent_jobs += 1\n",
    "\n",
    "print(\"-\" * 130)\n",
    "print(f\"\\nüìä Summary:\")\n",
    "print(f\"   Parent jobs: {parent_jobs}\")\n",
    "print(f\"   Iteration jobs: {iteration_jobs}\")\n",
    "\n",
    "# Updated to expect 3 iterations (3 endpoints in workload)\n",
    "if iteration_jobs == 3:\n",
    "    print(\"\\nüéâ SUCCESS! Loop Completion Fix VALIDATED!\")\n",
    "    print(\"   ‚úÖ Server detected iterator_started\")\n",
    "    print(\"   ‚úÖ Enqueued 3 iteration jobs\")\n",
    "    print(\"   ‚úÖ All 3 iterations executed successfully\")\n",
    "    print(\"   ‚úÖ Parent action_completed event emitted\")\n",
    "    print(\"   ‚úÖ Workflow progressed to completion\")\n",
    "    print(\"   ‚úÖ Server-side loop orchestration WORKING!\")\n",
    "elif iteration_jobs == 0:\n",
    "    print(\"\\n‚ö† No iteration jobs found - iteration expansion not working\")\n",
    "else:\n",
    "    print(f\"\\n‚ö† Expected 3 iteration jobs, found {iteration_jobs}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d63c756",
   "metadata": {},
   "source": [
    "## 8. View Execution Events (Ordered Table)\n",
    "\n",
    "Query and display all events for a specific execution in chronological order with key details."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb8876e3",
   "metadata": {},
   "source": [
    "## Summary: Distributed Loop + Pagination Architecture\n",
    "\n",
    "**What This Test Validates:**\n",
    "\n",
    "This notebook demonstrates the **event-driven distributed loop architecture** where:\n",
    "- Workers analyze collections and emit events\n",
    "- Server processes events to orchestrate distributed execution\n",
    "- Each iteration runs independently with pagination support\n",
    "\n",
    "**Current Implementation Status:**\n",
    "\n",
    "```\n",
    "‚úÖ PHASE 1: Worker-Side Architecture (COMPLETE)\n",
    "   ‚îú‚îÄ Loop detection in execute_task()\n",
    "   ‚îú‚îÄ Iterator executor analysis (filter, sort, limit)\n",
    "   ‚îú‚îÄ Event callback integration\n",
    "   ‚îî‚îÄ iterator_started event emission\n",
    "\n",
    "‚è≥ PHASE 2: Server-Side Orchestration (PENDING)\n",
    "   ‚îú‚îÄ Process iterator_started event\n",
    "   ‚îú‚îÄ Enqueue N iteration jobs\n",
    "   ‚îú‚îÄ Track iteration completion\n",
    "   ‚îî‚îÄ Emit iterator_completed event\n",
    "\n",
    "üîÆ PHASE 3: Pagination via Retry (DESIGN READY)\n",
    "   ‚îú‚îÄ HTTP action executes with retry.on_success\n",
    "   ‚îú‚îÄ Server-side pagination state tracking\n",
    "   ‚îú‚îÄ Page continuation logic\n",
    "   ‚îî‚îÄ Result aggregation\n",
    "```\n",
    "\n",
    "**How to Use:**\n",
    "\n",
    "1. **Run locally:** Execute cells 1-6 (default: localhost mode)\n",
    "2. **Run in-cluster:** Set `NOETL_ENV=kubernetes` before cell 2\n",
    "3. **Check validation:** Cell 6 shows full architecture validation\n",
    "\n",
    "**Next Steps:**\n",
    "\n",
    "Implement `_process_iterator_started()` in `orchestrator.py` to:\n",
    "- Parse collection from iterator_started.context\n",
    "- Create N PreparedJob instances\n",
    "- Enqueue to noetl.queue table\n",
    "- Workers will pick up and execute with pagination"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
