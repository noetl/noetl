{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fa2c2502",
   "metadata": {},
   "source": [
    "## 1. Setup and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cd7ad672",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Configuration loaded\n",
      "  Environment: localhost\n",
      "  Server: http://localhost:8082\n",
      "  Database: localhost:54321/demo_noetl\n",
      "  Test: tests/pagination/loop_with_pagination/loop_with_pagination\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import json\n",
    "import requests\n",
    "from typing import Dict\n",
    "\n",
    "# Modern data stack\n",
    "import psycopg\n",
    "import polars as pl\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# Configuration - Auto-detect environment\n",
    "# Set NOETL_ENV=kubernetes to run against in-cluster services\n",
    "# Set NOETL_ENV=localhost (default) to run against port-forwarded services\n",
    "ENVIRONMENT = os.getenv(\"NOETL_ENV\", \"localhost\").lower()\n",
    "\n",
    "if ENVIRONMENT == \"kubernetes\":\n",
    "    # In-cluster configuration\n",
    "    DB_CONFIG = {\n",
    "        \"host\": \"postgres.postgres.svc.cluster.local\",\n",
    "        \"port\": \"5432\",\n",
    "        \"user\": os.getenv(\"POSTGRES_USER\", \"demo\"),\n",
    "        \"password\": os.getenv(\"POSTGRES_PASSWORD\", \"demo\"),\n",
    "        \"dbname\": os.getenv(\"POSTGRES_DB\", \"demo_noetl\")\n",
    "    }\n",
    "    NOETL_SERVER_URL = \"http://noetl.noetl.svc.cluster.local:8082\"\n",
    "else:\n",
    "    # Localhost configuration (port-forwarded from kind cluster)\n",
    "    DB_CONFIG = {\n",
    "        \"host\": \"localhost\",\n",
    "        \"port\": \"54321\",  # Maps to postgres NodePort 30321\n",
    "        \"user\": os.getenv(\"POSTGRES_USER\", \"demo\"),\n",
    "        \"password\": os.getenv(\"POSTGRES_PASSWORD\", \"demo\"),\n",
    "        \"dbname\": os.getenv(\"POSTGRES_DB\", \"demo_noetl\")\n",
    "    }\n",
    "    NOETL_SERVER_URL = \"http://localhost:8082\"  # Maps to noetl NodePort 30082\n",
    "\n",
    "TEST_PATH = \"tests/pagination/loop_with_pagination/loop_with_pagination\"\n",
    "POLL_INTERVAL = 2\n",
    "MAX_WAIT = 120\n",
    "\n",
    "print(\"‚úì Configuration loaded\")\n",
    "print(f\"  Environment: {ENVIRONMENT}\")\n",
    "print(f\"  Server: {NOETL_SERVER_URL}\")\n",
    "print(f\"  Database: {DB_CONFIG['host']}:{DB_CONFIG['port']}/{DB_CONFIG['dbname']}\")\n",
    "print(f\"  Test: {TEST_PATH}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7f3ab61",
   "metadata": {},
   "source": [
    "## 2. Initialize Test Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d6a9a4c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Test table created\n",
      "  Schema: noetl_test\n",
      "  Table: pagination_loop_results\n"
     ]
    }
   ],
   "source": [
    "# Create test schema and table - completely self-contained\n",
    "import os\n",
    "import psycopg\n",
    "\n",
    "def get_postgres_connection():\n",
    "    \"\"\"Get psycopg3 connection\"\"\"\n",
    "    conn_string = f\"host={os.getenv('POSTGRES_HOST', 'postgres.postgres.svc.cluster.local')} \" \\\n",
    "                  f\"port={os.getenv('POSTGRES_PORT', '5432')} \" \\\n",
    "                  f\"dbname={os.getenv('POSTGRES_DB', 'demo_noetl')} \" \\\n",
    "                  f\"user={os.getenv('POSTGRES_USER', 'demo')} \" \\\n",
    "                  f\"password={os.getenv('POSTGRES_PASSWORD', 'demo')}\"\n",
    "    return psycopg.connect(conn_string)\n",
    "\n",
    "create_table_sql = \"\"\"\n",
    "CREATE SCHEMA IF NOT EXISTS noetl_test;\n",
    "\n",
    "DROP TABLE IF EXISTS noetl_test.pagination_loop_results;\n",
    "\n",
    "CREATE TABLE noetl_test.pagination_loop_results (\n",
    "    id SERIAL PRIMARY KEY,\n",
    "    execution_id BIGINT,\n",
    "    endpoint_name TEXT,\n",
    "    endpoint_path TEXT,\n",
    "    page_size INTEGER,\n",
    "    result_count INTEGER,\n",
    "    result_data JSONB,\n",
    "    iteration_index INTEGER,\n",
    "    iteration_count INTEGER,\n",
    "    created_at TIMESTAMP DEFAULT NOW()\n",
    ");\n",
    "\n",
    "CREATE INDEX IF NOT EXISTS idx_pagination_loop_execution_id \n",
    "ON noetl_test.pagination_loop_results(execution_id);\n",
    "\"\"\"\n",
    "\n",
    "with get_postgres_connection() as conn:\n",
    "    with conn.cursor() as cur:\n",
    "        cur.execute(create_table_sql)\n",
    "        conn.commit()\n",
    "\n",
    "print(\"‚úì Test table created\")\n",
    "print(\"  Schema: noetl_test\")\n",
    "print(\"  Table: pagination_loop_results\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af508ab3",
   "metadata": {},
   "source": [
    "## 3. Database Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4d726b13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Database utilities loaded\n"
     ]
    }
   ],
   "source": [
    "def get_postgres_connection():\n",
    "    \"\"\"Get psycopg3 connection\"\"\"\n",
    "    conn_string = f\"host={DB_CONFIG['host']} port={DB_CONFIG['port']} \" \\\n",
    "                  f\"dbname={DB_CONFIG['dbname']} user={DB_CONFIG['user']} \" \\\n",
    "                  f\"password={DB_CONFIG['password']}\"\n",
    "    return psycopg.connect(conn_string)\n",
    "\n",
    "def query_to_polars(query: str) -> pl.DataFrame:\n",
    "    \"\"\"Execute query and return as Polars DataFrame\"\"\"\n",
    "    with get_postgres_connection() as conn:\n",
    "        with conn.cursor() as cur:\n",
    "            cur.execute(query)\n",
    "            columns = [desc[0] for desc in cur.description]\n",
    "            data = cur.fetchall()\n",
    "    if not data:\n",
    "        return pl.DataFrame(schema=columns)\n",
    "    return pl.DataFrame({col: [row[i] for row in data] for i, col in enumerate(columns)})\n",
    "\n",
    "print(\"‚úì Database utilities loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaaf6898",
   "metadata": {},
   "source": [
    "## 4. Execute Pagination Loop Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fe58cc86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting test: tests/pagination/loop_with_pagination/loop_with_pagination\n",
      "‚úì Test started\n",
      "  Execution ID: 511672404708425883\n",
      "  Status: running\n"
     ]
    }
   ],
   "source": [
    "def start_test() -> Dict:\n",
    "    \"\"\"Start pagination loop test\"\"\"\n",
    "    url = f\"{NOETL_SERVER_URL}/api/run/playbook\"\n",
    "    payload = {\"path\": TEST_PATH}\n",
    "    \n",
    "    print(f\"Starting test: {TEST_PATH}\")\n",
    "    response = requests.post(url, json=payload, timeout=30)\n",
    "    response.raise_for_status()\n",
    "    \n",
    "    result = response.json()\n",
    "    execution_id = result['execution_id']\n",
    "    \n",
    "    print(f\"‚úì Test started\")\n",
    "    print(f\"  Execution ID: {execution_id}\")\n",
    "    print(f\"  Status: {result['status']}\")\n",
    "    \n",
    "    return result\n",
    "\n",
    "test_result = start_test()\n",
    "EXECUTION_ID = test_result['execution_id']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab0052ed",
   "metadata": {},
   "source": [
    "## 5. Monitor Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2ffd9d8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Monitoring execution 511672404708425883...\n",
      "Time   Steps  Status       Events\n",
      "--------------------------------------------------\n",
      "\n",
      "‚ö† Timeout after 120s\n",
      "\n",
      "‚ö† Timeout after 120s\n"
     ]
    }
   ],
   "source": [
    "def monitor_execution(execution_id: int):\n",
    "    \"\"\"Monitor test execution\"\"\"\n",
    "    start_time = time.time()\n",
    "    last_count = 0\n",
    "    \n",
    "    print(f\"Monitoring execution {execution_id}...\")\n",
    "    print(f\"{'Time':<6} {'Steps':<6} {'Status':<12} {'Events'}\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    while (time.time() - start_time) < MAX_WAIT:\n",
    "        query = f\"\"\"\n",
    "            SELECT event_type, COUNT(*) as count\n",
    "            FROM noetl.event\n",
    "            WHERE execution_id = {execution_id}\n",
    "            GROUP BY event_type\n",
    "        \"\"\"\n",
    "        df = query_to_polars(query)\n",
    "        \n",
    "        step_count = df.filter(pl.col('event_type') == 'step_completed')['count'].sum() or 0\n",
    "        is_complete = df.filter(pl.col('event_type') == 'playbook_completed').height > 0\n",
    "        is_failed = df.filter(pl.col('event_type') == 'playbook_failed').height > 0\n",
    "        \n",
    "        if step_count != last_count or is_complete or is_failed:\n",
    "            elapsed = int(time.time() - start_time)\n",
    "            status = \"COMPLETED\" if is_complete else (\"FAILED\" if is_failed else \"RUNNING\")\n",
    "            total = df['count'].sum()\n",
    "            print(f\"{elapsed:<6} {step_count:<6} {status:<12} {total}\")\n",
    "            last_count = step_count\n",
    "        \n",
    "        if is_complete:\n",
    "            print(f\"\\n‚úì Test completed in {elapsed}s\")\n",
    "            return True\n",
    "        elif is_failed:\n",
    "            print(f\"\\n‚úó Test failed after {elapsed}s\")\n",
    "            return False\n",
    "        \n",
    "        time.sleep(POLL_INTERVAL)\n",
    "    \n",
    "    print(f\"\\n‚ö† Timeout after {MAX_WAIT}s\")\n",
    "    return False\n",
    "\n",
    "success = monitor_execution(EXECUTION_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11dbd3b2",
   "metadata": {},
   "source": [
    "## 6. Validate Iterator Event Architecture\n",
    "\n",
    "**Expected Behavior:**\n",
    "1. Worker detects `loop` configuration in step\n",
    "2. Routes to iterator executor \n",
    "3. Analyzes collection (filter, sort, limit)\n",
    "4. Emits `iterator_started` event with metadata\n",
    "5. Server should process event and enqueue iteration jobs (NOT YET IMPLEMENTED)\n",
    "\n",
    "This section verifies the distributed loop architecture is working correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "187db13d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä Iterator Event Validation for Execution 511672404708425883\n",
      "================================================================================\n",
      "\n",
      "‚úì Event Flow (7 events):\n",
      "  playbook_started          STARTED      tests/pagination/loop_with_pagination/loop_with_pagination\n",
      "  workflow_initialized      COMPLETED    workflow\n",
      "  step_started              RUNNING      fetch_all_endpoints\n",
      "  action_started            RUNNING      fetch_all_endpoints\n",
      "  iterator_started          RUNNING      iterator\n",
      "  action_completed          COMPLETED    fetch_all_endpoints\n",
      "  step_result               COMPLETED    fetch_all_endpoints\n",
      "\n",
      "‚úì iterator_started Event Found:\n",
      "  Status:           RUNNING\n",
      "  Total Count:      2\n",
      "  Collection Size:  2\n",
      "  Mode:             sequential\n",
      "  Iterator Name:    endpoint\n",
      "  Nested Tool:      http\n",
      "\n",
      "‚úì Iterator Metadata:\n",
      "  Collection: [\n",
      "  {\n",
      "    \"name\": \"assessments\",\n",
      "    \"path\": \"/api/v1/assessments\",\n",
      "    \"page_size\": 10\n",
      "  },\n",
      "  {\n",
      "    \"name\": \"users\",\n",
      "    \"path\": \"/api/v1/users\",\n",
      "    \"page_size\": 15\n",
      "  }\n",
      "]...\n",
      "\n",
      "  Nested Task Tool: http\n",
      "  Has retry.on_success: True\n",
      "  Pagination Config:\n",
      "    - while: {{ response.paging.hasMore == true }}\n",
      "    - max_attempts: 10\n",
      "    - collect.strategy: append\n",
      "\n",
      "‚ö† No iteration_completed events found\n",
      "  This is EXPECTED - Server orchestrator doesn't yet process iterator_started\n",
      "  Next Implementation Step: Add _process_iterator_started() handler in orchestrator.py\n",
      "\n",
      "================================================================================\n",
      "VALIDATION SUMMARY:\n",
      "================================================================================\n",
      "‚úÖ Worker Event Callback: WORKING\n",
      "‚úÖ Iterator Executor: WORKING\n",
      "‚úÖ iterator_started Event: EMITTED\n",
      "‚úÖ Event Schema: VALID\n",
      "‚è≥ Server Orchestrator: NOT YET IMPLEMENTED\n",
      "\n",
      "Next: Implement server-side iterator_started event processing to enqueue iteration jobs\n"
     ]
    }
   ],
   "source": [
    "# Validate iterator event architecture\n",
    "print(f\"\\nüìä Iterator Event Validation for Execution {EXECUTION_ID}\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# 1. Check basic event flow\n",
    "events_query = f\"\"\"\n",
    "    SELECT \n",
    "        event_type,\n",
    "        node_name,\n",
    "        status,\n",
    "        created_at\n",
    "    FROM noetl.event\n",
    "    WHERE execution_id = {EXECUTION_ID}\n",
    "    ORDER BY event_id\n",
    "\"\"\"\n",
    "events_df = query_to_polars(events_query)\n",
    "\n",
    "print(f\"\\n‚úì Event Flow ({events_df.height} events):\")\n",
    "for row in events_df.iter_rows(named=True):\n",
    "    print(f\"  {row['event_type']:25} {row['status']:12} {row['node_name'] or ''}\")\n",
    "\n",
    "# 2. Check iterator_started event exists\n",
    "iterator_check = f\"\"\"\n",
    "    SELECT \n",
    "        event_type,\n",
    "        status,\n",
    "        context->>'total_count' as total_count,\n",
    "        context->>'mode' as mode,\n",
    "        context->>'iterator_name' as iterator_name,\n",
    "        jsonb_array_length(context->'collection') as collection_size,\n",
    "        context->'nested_task'->>'tool' as nested_tool\n",
    "    FROM noetl.event\n",
    "    WHERE execution_id = {EXECUTION_ID}\n",
    "      AND event_type = 'iterator_started'\n",
    "\"\"\"\n",
    "iterator_df = query_to_polars(iterator_check)\n",
    "\n",
    "if iterator_df.height > 0:\n",
    "    print(f\"\\n‚úì iterator_started Event Found:\")\n",
    "    row = iterator_df.row(0, named=True)\n",
    "    print(f\"  Status:           {row['status']}\")\n",
    "    print(f\"  Total Count:      {row['total_count']}\")\n",
    "    print(f\"  Collection Size:  {row['collection_size']}\")\n",
    "    print(f\"  Mode:             {row['mode']}\")\n",
    "    print(f\"  Iterator Name:    {row['iterator_name']}\")\n",
    "    print(f\"  Nested Tool:      {row['nested_tool']}\")\n",
    "else:\n",
    "    print(\"\\n‚ùå iterator_started event NOT FOUND!\")\n",
    "    print(\"   This means the event callback integration failed.\")\n",
    "\n",
    "# 3. Check iterator metadata\n",
    "if iterator_df.height > 0:\n",
    "    metadata_query = f\"\"\"\n",
    "        SELECT \n",
    "            context->'collection' as collection,\n",
    "            context->'nested_task' as nested_task\n",
    "        FROM noetl.event\n",
    "        WHERE execution_id = {EXECUTION_ID}\n",
    "          AND event_type = 'iterator_started'\n",
    "    \"\"\"\n",
    "    \n",
    "    with get_postgres_connection() as conn:\n",
    "        with conn.cursor() as cur:\n",
    "            cur.execute(metadata_query)\n",
    "            result = cur.fetchone()\n",
    "            if result:\n",
    "                collection = result[0]\n",
    "                nested_task = result[1]\n",
    "                \n",
    "                print(f\"\\n‚úì Iterator Metadata:\")\n",
    "                print(f\"  Collection: {json.dumps(collection, indent=2)[:200]}...\")\n",
    "                print(f\"\\n  Nested Task Tool: {nested_task.get('tool')}\")\n",
    "                print(f\"  Has retry.on_success: {'retry' in nested_task and 'on_success' in nested_task.get('retry', {})}\")\n",
    "                \n",
    "                if 'retry' in nested_task and 'on_success' in nested_task['retry']:\n",
    "                    retry_config = nested_task['retry']['on_success']\n",
    "                    print(f\"  Pagination Config:\")\n",
    "                    print(f\"    - while: {retry_config.get('while', 'N/A')[:60]}\")\n",
    "                    print(f\"    - max_attempts: {retry_config.get('max_attempts', 'N/A')}\")\n",
    "                    print(f\"    - collect.strategy: {retry_config.get('collect', {}).get('strategy', 'N/A')}\")\n",
    "\n",
    "# 4. Check for expected next events (iteration jobs)\n",
    "iteration_check = f\"\"\"\n",
    "    SELECT COUNT(*) as count\n",
    "    FROM noetl.event\n",
    "    WHERE execution_id = {EXECUTION_ID}\n",
    "      AND event_type = 'iteration_completed'\n",
    "\"\"\"\n",
    "iteration_df = query_to_polars(iteration_check)\n",
    "\n",
    "if iteration_df['count'][0] > 0:\n",
    "    print(f\"\\n‚úì Found {iteration_df['count'][0]} iteration_completed events\")\n",
    "    print(\"  Server successfully processed iterator_started and enqueued iteration jobs!\")\n",
    "else:\n",
    "    print(f\"\\n‚ö† No iteration_completed events found\")\n",
    "    print(\"  This is EXPECTED - Server orchestrator doesn't yet process iterator_started\")\n",
    "    print(\"  Next Implementation Step: Add _process_iterator_started() handler in orchestrator.py\")\n",
    "\n",
    "# 5. Summary\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"VALIDATION SUMMARY:\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "if iterator_df.height > 0:\n",
    "    print(\"‚úÖ Worker Event Callback: WORKING\")\n",
    "    print(\"‚úÖ Iterator Executor: WORKING\") \n",
    "    print(\"‚úÖ iterator_started Event: EMITTED\")\n",
    "    print(\"‚úÖ Event Schema: VALID\")\n",
    "    print(\"‚è≥ Server Orchestrator: NOT YET IMPLEMENTED\")\n",
    "    print(\"\\nNext: Implement server-side iterator_started event processing to enqueue iteration jobs\")\n",
    "else:\n",
    "    print(\"‚ùå Iterator event architecture validation FAILED\")\n",
    "    print(\"   Check worker logs for event emission errors\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82325d5b",
   "metadata": {},
   "source": [
    "## 7. Architecture Status & Next Steps\n",
    "\n",
    "**‚úÖ Completed Implementation:**\n",
    "- Worker-side event callback integration\n",
    "- Iterator executor analysis and event emission  \n",
    "- Event schema extensions (iterator_started, iterator_completed, etc.)\n",
    "- Environment-aware configuration (localhost/kubernetes)\n",
    "\n",
    "**‚è≥ Pending Implementation:**\n",
    "- Server orchestrator `_process_iterator_started()` handler\n",
    "- Iteration job enqueueing logic\n",
    "- Iteration execution with pagination (retry.on_success)\n",
    "- `iterator_completed` event emission after all iterations\n",
    "\n",
    "**Note:** The test will timeout until server-side processing is implemented."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb8876e3",
   "metadata": {},
   "source": [
    "## Summary: Distributed Loop + Pagination Architecture\n",
    "\n",
    "**What This Test Validates:**\n",
    "\n",
    "This notebook demonstrates the **event-driven distributed loop architecture** where:\n",
    "- Workers analyze collections and emit events\n",
    "- Server processes events to orchestrate distributed execution\n",
    "- Each iteration runs independently with pagination support\n",
    "\n",
    "**Current Implementation Status:**\n",
    "\n",
    "```\n",
    "‚úÖ PHASE 1: Worker-Side Architecture (COMPLETE)\n",
    "   ‚îú‚îÄ Loop detection in execute_task()\n",
    "   ‚îú‚îÄ Iterator executor analysis (filter, sort, limit)\n",
    "   ‚îú‚îÄ Event callback integration\n",
    "   ‚îî‚îÄ iterator_started event emission\n",
    "\n",
    "‚è≥ PHASE 2: Server-Side Orchestration (PENDING)\n",
    "   ‚îú‚îÄ Process iterator_started event\n",
    "   ‚îú‚îÄ Enqueue N iteration jobs\n",
    "   ‚îú‚îÄ Track iteration completion\n",
    "   ‚îî‚îÄ Emit iterator_completed event\n",
    "\n",
    "üîÆ PHASE 3: Pagination via Retry (DESIGN READY)\n",
    "   ‚îú‚îÄ HTTP action executes with retry.on_success\n",
    "   ‚îú‚îÄ Server-side pagination state tracking\n",
    "   ‚îú‚îÄ Page continuation logic\n",
    "   ‚îî‚îÄ Result aggregation\n",
    "```\n",
    "\n",
    "**How to Use:**\n",
    "\n",
    "1. **Run locally:** Execute cells 1-6 (default: localhost mode)\n",
    "2. **Run in-cluster:** Set `NOETL_ENV=kubernetes` before cell 2\n",
    "3. **Check validation:** Cell 6 shows full architecture validation\n",
    "\n",
    "**Next Steps:**\n",
    "\n",
    "Implement `_process_iterator_started()` in `orchestrator.py` to:\n",
    "- Parse collection from iterator_started.context\n",
    "- Create N PreparedJob instances\n",
    "- Enqueue to noetl.queue table\n",
    "- Workers will pick up and execute with pagination"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aab29868",
   "metadata": {},
   "source": [
    "## Debug: Check Server Logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b13bb971",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Server pod: noetl-server-bc75cf667-m7bph\n",
      "\n",
      "Found 0 relevant log lines:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check server logs for orchestrator errors\n",
    "import subprocess\n",
    "\n",
    "execution_id = 511672404708425883\n",
    "\n",
    "# Get server pod name\n",
    "result = subprocess.run(\n",
    "    [\"kubectl\", \"get\", \"pods\", \"-n\", \"noetl\", \"-l\", \"app=noetl-server\", \"-o\", \"jsonpath={.items[0].metadata.name}\"],\n",
    "    capture_output=True,\n",
    "    text=True\n",
    ")\n",
    "server_pod = result.stdout.strip()\n",
    "print(f\"Server pod: {server_pod}\\n\")\n",
    "\n",
    "# Check logs around the execution time\n",
    "result = subprocess.run(\n",
    "    [\"kubectl\", \"logs\", \"-n\", \"noetl\", server_pod, \"--tail=200\"],\n",
    "    capture_output=True,\n",
    "    text=True\n",
    ")\n",
    "\n",
    "# Filter for ORCHESTRATOR messages and errors\n",
    "lines = result.stdout.split('\\n')\n",
    "relevant_lines = [\n",
    "    line for line in lines \n",
    "    if 'ORCHESTRATOR' in line or 'ERROR' in line or 'KeyError' in line or str(execution_id) in line\n",
    "]\n",
    "\n",
    "print(f\"Found {len(relevant_lines)} relevant log lines:\\n\")\n",
    "for line in relevant_lines[-30:]:  # Last 30 relevant lines\n",
    "    print(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d6f0fce",
   "metadata": {},
   "source": [
    "## Check Queue Table for Iteration Jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "671a2759",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Queue entries for execution 511672404708425883:\n",
      "Total jobs: 1\n",
      "\n",
      "Execution ID              Parent                    Node                           Status          Created\n",
      "----------------------------------------------------------------------------------------------------------------------------------\n",
      "511672404708425883        None                      fetch_all_endpoints            done            2025-12-06 23:21:43.880866+00:00\n"
     ]
    }
   ],
   "source": [
    "# Check queue table for iteration jobs\n",
    "execution_id = 511672404708425883\n",
    "\n",
    "with psycopg.connect(**{k: v for k, v in DB_CONFIG.items()}) as conn:\n",
    "    with conn.cursor() as cur:\n",
    "        # Check for iteration jobs in queue\n",
    "        cur.execute(\"\"\"\n",
    "            SELECT \n",
    "                execution_id,\n",
    "                parent_execution_id,\n",
    "                node_name,\n",
    "                status,\n",
    "                created_at\n",
    "            FROM noetl.queue\n",
    "            WHERE parent_execution_id = %s OR execution_id = %s\n",
    "            ORDER BY created_at\n",
    "        \"\"\", (execution_id, execution_id))\n",
    "        \n",
    "        jobs = cur.fetchall()\n",
    "        \n",
    "        print(f\"Queue entries for execution {execution_id}:\")\n",
    "        print(f\"Total jobs: {len(jobs)}\\n\")\n",
    "        \n",
    "        if jobs:\n",
    "            print(f\"{'Execution ID':<25} {'Parent':<25} {'Node':<30} {'Status':<15} {'Created'}\")\n",
    "            print(\"-\" * 130)\n",
    "            for job in jobs:\n",
    "                exec_id, parent_id, node, status, created = job\n",
    "                print(f\"{exec_id:<25} {parent_id or 'None':<25} {node:<30} {status:<15} {created}\")\n",
    "        else:\n",
    "            print(\"‚ö† No jobs found in queue!\")\n",
    "            print(\"\\nThis means the orchestrator did NOT enqueue iteration jobs.\")\n",
    "            print(\"Let's check if the iterator_started event was processed at all...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eedd7068",
   "metadata": {},
   "source": [
    "## Check If Orchestrator is Processing iterator_started"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "acafaa8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching 501 log lines for orchestrator activity...\n",
      "\n",
      "Found 0 relevant lines:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get ALL server logs and search for any orchestrator activity\n",
    "import subprocess\n",
    "\n",
    "result = subprocess.run(\n",
    "    [\"kubectl\", \"get\", \"pods\", \"-n\", \"noetl\", \"-l\", \"app=noetl-server\", \"-o\", \"jsonpath={.items[0].metadata.name}\"],\n",
    "    capture_output=True,\n",
    "    text=True\n",
    ")\n",
    "server_pod = result.stdout.strip()\n",
    "\n",
    "result = subprocess.run(\n",
    "    [\"kubectl\", \"logs\", \"-n\", \"noetl\", server_pod, \"--tail=500\"],\n",
    "    capture_output=True,\n",
    "    text=True\n",
    ")\n",
    "\n",
    "lines = result.stdout.split('\\n')\n",
    "\n",
    "# Look for any of these patterns\n",
    "patterns = ['ORCHESTRATOR', 'iterator_started', 'Enqueueing', '_process_iterator', 'evaluate_execution']\n",
    "\n",
    "print(f\"Searching {len(lines)} log lines for orchestrator activity...\\n\")\n",
    "\n",
    "matches = []\n",
    "for i, line in enumerate(lines):\n",
    "    for pattern in patterns:\n",
    "        if pattern in line:\n",
    "            matches.append((i, line))\n",
    "            break\n",
    "\n",
    "print(f\"Found {len(matches)} relevant lines:\\n\")\n",
    "for idx, line in matches[-20:]:  # Last 20 matches\n",
    "    print(f\"[{idx:4d}] {line}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "329f9469",
   "metadata": {},
   "source": [
    "## Check Postgres NOTIFY/LISTEN Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "94537274",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Triggers on noetl.event table: 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check if NOTIFY triggers are configured for iterator_started events\n",
    "with psycopg.connect(**{k: v for k, v in DB_CONFIG.items()}) as conn:\n",
    "    with conn.cursor() as cur:\n",
    "        # Check trigger function\n",
    "        cur.execute(\"\"\"\n",
    "            SELECT \n",
    "                trigger_name,\n",
    "                event_manipulation,\n",
    "                action_statement\n",
    "            FROM information_schema.triggers\n",
    "            WHERE trigger_schema = 'noetl'\n",
    "            AND event_object_table = 'event'\n",
    "        \"\"\")\n",
    "        \n",
    "        triggers = cur.fetchall()\n",
    "        print(f\"Triggers on noetl.event table: {len(triggers)}\\n\")\n",
    "        \n",
    "        for trig in triggers:\n",
    "            name, event, action = trig\n",
    "            print(f\"Trigger: {name}\")\n",
    "            print(f\"  Event: {event}\")\n",
    "            print(f\"  Action: {action[:200]}...\")\n",
    "            print()\n",
    "        \n",
    "        # Check the trigger function definition\n",
    "        cur.execute(\"\"\"\n",
    "            SELECT pg_get_functiondef(oid)\n",
    "            FROM pg_proc\n",
    "            WHERE proname = 'notify_event_channel'\n",
    "            AND pronamespace = (SELECT oid FROM pg_namespace WHERE nspname = 'noetl')\n",
    "        \"\"\")\n",
    "        \n",
    "        func_def = cur.fetchone()\n",
    "        if func_def:\n",
    "            print(\"\\nTrigger Function Definition:\")\n",
    "            print(func_def[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a26746ba",
   "metadata": {},
   "source": [
    "## Check If evaluate_execution Was Called For iterator_started"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "496398e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found iterator_started event: 511672435494617249\n",
      "\n",
      "Manually triggering orchestrator...\n",
      "Response status: 405\n",
      "‚úó Error: {\"detail\":\"Method Not Allowed\"}\n"
     ]
    }
   ],
   "source": [
    "# Test if orchestrator can be triggered manually for the iterator_started event\n",
    "execution_id = 511672404708425883\n",
    "\n",
    "# Get the iterator_started event\n",
    "with psycopg.connect(**{k: v for k, v in DB_CONFIG.items()}) as conn:\n",
    "    with conn.cursor() as cur:\n",
    "        cur.execute(\"\"\"\n",
    "            SELECT event_id, event_type\n",
    "            FROM noetl.event\n",
    "            WHERE execution_id = %s\n",
    "            AND event_type = 'iterator_started'\n",
    "        \"\"\", (execution_id,))\n",
    "        \n",
    "        event = cur.fetchone()\n",
    "        \n",
    "        if event:\n",
    "            event_id, event_type = event\n",
    "            print(f\"Found iterator_started event: {event_id}\")\n",
    "            print(f\"\\nManually triggering orchestrator...\")\n",
    "            \n",
    "            # Call the orchestration endpoint directly\n",
    "            response = requests.post(\n",
    "                f\"{NOETL_SERVER_URL}/api/orchestrate\",\n",
    "                json={\n",
    "                    \"execution_id\": str(execution_id),\n",
    "                    \"trigger_event_type\": event_type,\n",
    "                    \"trigger_event_id\": str(event_id)\n",
    "                }\n",
    "            )\n",
    "            \n",
    "            print(f\"Response status: {response.status_code}\")\n",
    "            if response.status_code == 200:\n",
    "                print(f\"‚úì Orchestrator triggered successfully\")\n",
    "                print(f\"Response: {response.json()}\")\n",
    "            else:\n",
    "                print(f\"‚úó Error: {response.text}\")\n",
    "        else:\n",
    "            print(\"No iterator_started event found!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da45bb48",
   "metadata": {},
   "source": [
    "## Solution: Check Orchestrator Code Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f913da9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Events for execution 511672404708425883:\n",
      "Event Type                Status          Created                        Event ID\n",
      "----------------------------------------------------------------------------------------------------\n",
      "playbook_started          STARTED         2025-12-06 23:21:43.861318     511672404817477788\n",
      "workflow_initialized      COMPLETED       2025-12-06 23:21:43.874872     511672404934918301\n",
      "step_started              RUNNING         2025-12-06 23:21:43.884671     511672405010415775\n",
      "action_started            RUNNING         2025-12-06 23:21:47.461532     511672435016466592\n",
      "iterator_started          RUNNING         2025-12-06 23:21:47.519055     511672435494617249 ‚Üê SHOULD TRIGGER ORCHESTRATOR\n",
      "action_completed          COMPLETED       2025-12-06 23:21:47.530429     511672435595280546\n",
      "step_result               COMPLETED       2025-12-06 23:21:47.542893     511672435704332451\n",
      "\n",
      "üîç Root Cause Analysis:\n",
      "========================\n",
      "The iterator_started event exists, but there are NO orchestrator logs.\n",
      "This means one of two things:\n",
      "1. The emit_event endpoint is NOT calling evaluate_execution\n",
      "2. The evaluate_execution function is silently failing/returning early\n",
      "\n",
      "Let's check the server code to see which one...\n"
     ]
    }
   ],
   "source": [
    "# The issue: evaluate_execution has special handling for iterator_started\n",
    "# but it appears it's not being called. Let me check the flow:\n",
    "# 1. Worker emits iterator_started via POST /api/events\n",
    "# 2. emit_event_legacy calls emit_event  \n",
    "# 3. emit_event calls evaluate_execution with trigger_event_type=\"iterator_started\"\n",
    "# 4. evaluate_execution should check for iterator_started and call _process_iterator_started\n",
    "\n",
    "# BUT: There are NO logs showing \"ORCHESTRATOR: Evaluating\" which means evaluate_execution is NOT being called\n",
    "# Let's verify the event was actually emitted by checking if it's in the event table\n",
    "\n",
    "execution_id = 511672404708425883\n",
    "\n",
    "with psycopg.connect(**{k: v for k, v in DB_CONFIG.items()}) as conn:\n",
    "    with conn.cursor() as cur:\n",
    "        # Get all events for this execution\n",
    "        cur.execute(\"\"\"\n",
    "            SELECT \n",
    "                event_type,\n",
    "                status,\n",
    "                created_at,\n",
    "                event_id\n",
    "            FROM noetl.event\n",
    "            WHERE execution_id = %s\n",
    "            ORDER BY created_at\n",
    "        \"\"\", (execution_id,))\n",
    "        \n",
    "        events = cur.fetchall()\n",
    "        \n",
    "        print(f\"Events for execution {execution_id}:\")\n",
    "        print(f\"{'Event Type':<25} {'Status':<15} {'Created':<30} {'Event ID'}\")\n",
    "        print(\"-\" * 100)\n",
    "        for event_type, status, created, event_id in events:\n",
    "            marker = \" ‚Üê SHOULD TRIGGER ORCHESTRATOR\" if event_type == \"iterator_started\" else \"\"\n",
    "            print(f\"{event_type:<25} {status:<15} {str(created):<30} {event_id}{marker}\")\n",
    "        \n",
    "        print(\"\\nüîç Root Cause Analysis:\")\n",
    "        print(\"========================\")\n",
    "        print(\"The iterator_started event exists, but there are NO orchestrator logs.\")\n",
    "        print(\"This means one of two things:\")\n",
    "        print(\"1. The emit_event endpoint is NOT calling evaluate_execution\")\n",
    "        print(\"2. The evaluate_execution function is silently failing/returning early\")\n",
    "        print(\"\\nLet's check the server code to see which one...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5265d832",
   "metadata": {},
   "source": [
    "## Manual Debug: Emit Test Event and Watch Logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ff1cb3dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Emitting test event...\n",
      "Response: 500\n",
      "Error: {\"detail\":\"null value in column \\\"catalog_id\\\" of relation \\\"event\\\" violates not-null constraint\\nDETAIL:  Failing row contains (999999999999999999, null, 511675646569873572, null, null, 2025-12-06 23:28:10.311218, iterator_started, null, null, null, RUNNING, null, {\\\"test\\\": \\\"manual emit\\\"}, null, null, null, null, null, null, null, null, null, null, null).\"}\n",
      "\n",
      "üìã Last 50 log lines (filtered for test execution):\n",
      "     Message: EMIT EVENT: execution_id=999999999999999999, type=iterator_started\n",
      "     Message: Failed to resolve catalog_id for execution 999999999999999999: No catalog_id found for execution 999999999999999999\n",
      "     Message: Error emitting event for execution_id=999999999999999999, event_type=iterator_started: null value in column \"catalog_id\" of relation \"event\" violates not-null constraint\n",
      "             DETAIL:  Failing row contains (999999999999999999, null, 511675646569873572, null, null, 2025-12-06 23:28:10.311218, iterator_started, null, null, null, RUNNING, null, {\"test\": \"manual emit\"}, null, null, null, null, null, null, null, null, null, null, null).\n",
      "DETAIL:  Failing row contains (999999999999999999, null, 511675646569873572, null, null, 2025-12-06 23:28:10.311218, iterator_started, null, null, null, RUNNING, null, {\"test\": \"manual emit\"}, null, null, null, null, null, null, null, null, null, null, null).\n",
      "               \"execution_id\": \"999999999999999999\",\n",
      "               \"detail\": \"null value in column \\\"catalog_id\\\" of relation \\\"event\\\" violates not-null constraint\\nDETAIL:  Failing row contains (999999999999999999, null, 511675646569873572, null, null, 2025-12-06 23:28:10.311218, iterator_started, null, null, null, RUNNING, null, {\\\"test\\\": \\\"manual emit\\\"}, null, null, null, null, null, null, null, null, null, null, null).\"\n"
     ]
    }
   ],
   "source": [
    "# Emit a test event and check if evaluate_execution is called\n",
    "import time\n",
    "import subprocess\n",
    "\n",
    "test_exec_id = 999999999999999999  # Test execution ID\n",
    "\n",
    "print(\"Emitting test event...\")\n",
    "response = requests.post(\n",
    "    f\"{NOETL_SERVER_URL}/api/event/emit\",\n",
    "    json={\n",
    "        \"execution_id\": str(test_exec_id),\n",
    "        \"event_type\": \"iterator_started\",\n",
    "        \"status\": \"RUNNING\",\n",
    "        \"context\": {\"test\": \"manual emit\"}\n",
    "    }\n",
    ")\n",
    "\n",
    "print(f\"Response: {response.status_code}\")\n",
    "if response.status_code == 200:\n",
    "    print(f\"Event emitted: {response.json()}\")\n",
    "else:\n",
    "    print(f\"Error: {response.text}\")\n",
    "\n",
    "# Wait a moment for log flush\n",
    "time.sleep(2)\n",
    "\n",
    "# Check logs\n",
    "result = subprocess.run(\n",
    "    [\"kubectl\", \"get\", \"pods\", \"-n\", \"noetl\", \"-l\", \"app=noetl-server\", \"-o\", \"jsonpath={.items[0].metadata.name}\"],\n",
    "    capture_output=True,\n",
    "    text=True\n",
    ")\n",
    "server_pod = result.stdout.strip()\n",
    "\n",
    "result = subprocess.run(\n",
    "    [\"kubectl\", \"logs\", \"-n\", \"noetl\", server_pod, \"--tail=50\"],\n",
    "    capture_output=True,\n",
    "    text=True\n",
    ")\n",
    "\n",
    "lines = result.stdout.split('\\n')\n",
    "print(f\"\\nüìã Last 50 log lines (filtered for test execution):\")\n",
    "for line in lines:\n",
    "    if str(test_exec_id) in line or 'ORCHESTRATOR' in line or 'EMIT EVENT' in line:\n",
    "        print(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de3d6544",
   "metadata": {},
   "source": [
    "## Check Server Logs From Real Execution Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "beff0a45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching logs for execution 511672404708425883...\n",
      "\n",
      "Found 66 relevant lines:\n",
      "\n",
      "2025-12-06T23:21:47.469639261Z      Message: ORCHESTRATOR: Dispatching initial step for execution 511672404708425883\n",
      "2025-12-06T23:21:47.469643511Z      Message: Dispatching first step for execution 511672404708425883\n",
      "2025-12-06T23:21:47.469647803Z      Message: ORCHESTRATOR: Evaluation complete for execution 511672404708425883\n",
      "2025-12-06T23:21:47.469879428Z                \"execution_id\": \"511672404708425883\",\n",
      "2025-12-06T23:21:47.469990678Z                    \"execution_id\": 511672404708425883\n",
      "2025-12-06T23:21:47.470191970Z                    \"execution_id\": 511672404708425883\n",
      "2025-12-06T23:21:47.470231470Z                \"execution_id\": \"511672404708425883\",\n",
      "2025-12-06T23:21:47.517976053Z      Message: EMIT EVENT: execution_id=511672404708425883, type=iterator_started\n",
      "2025-12-06T23:21:47.519119261Z      Message: Resolved missing catalog_id=511594959275819078 from execution_id=511672404708425883\n",
      "2025-12-06T23:21:47.520527095Z      Message: Event emitted: event_id=511672435494617249, execution_id=511672404708425883, type=iterator_started, status=RUNNING\n",
      "2025-12-06T23:21:47.520574595Z      Message: ORCHESTRATOR: Evaluating execution_id=511672404708425883, trigger=iterator_started, event_id=511672435494617249\n",
      "2025-12-06T23:21:47.520690678Z      Message: ORCHESTRATOR: Detected iterator_started, enqueueing iterations for execution 511672404708425883\n",
      "2025-12-06T23:21:47.522030553Z      Message: ORCHESTRATOR: Error evaluating execution 511672404708425883\n",
      "2025-12-06T23:21:47.522227720Z                \"event_type\": \"iterator_started\",\n",
      "2025-12-06T23:21:47.522229553Z                \"execution_id\": \"511672404708425883\",\n",
      "2025-12-06T23:21:47.522349428Z                \"execution_id\": \"511672404708425883\",\n",
      "2025-12-06T23:21:47.522350845Z                \"event_type\": \"iterator_started\",\n",
      "2025-12-06T23:21:47.529964970Z      Message: EMIT EVENT: execution_id=511672404708425883, type=action_completed\n",
      "2025-12-06T23:21:47.531909345Z      Message: Event emitted: event_id=511672435595280546, execution_id=511672404708425883, type=action_completed, status=COMPLETED\n",
      "2025-12-06T23:21:47.531942845Z      Message: ORCHESTRATOR: Evaluating execution_id=511672404708425883, trigger=action_completed, event_id=511672435595280546\n",
      "2025-12-06T23:21:47.533431511Z      Message: ORCHESTRATOR: Execution 511672404708425883 state=in_progress\n",
      "2025-12-06T23:21:47.534434428Z      Message: ORCHESTRATOR: Error evaluating execution 511672404708425883\n",
      "2025-12-06T23:21:47.534627095Z                \"execution_id\": \"511672404708425883\",\n",
      "2025-12-06T23:21:47.534647511Z                  \"execution_id\": 511672404708425883,\n",
      "2025-12-06T23:21:47.534699553Z                    \"iterator_started\": true,\n",
      "2025-12-06T23:21:47.534762136Z                \"execution_id\": \"511672404708425883\",\n",
      "2025-12-06T23:21:47.542386386Z      Message: EMIT EVENT: execution_id=511672404708425883, type=step_result\n",
      "2025-12-06T23:21:47.544172720Z      Message: Event emitted: event_id=511672435704332451, execution_id=511672404708425883, type=step_result, status=COMPLETED\n",
      "2025-12-06T23:21:47.544178678Z      Message: ORCHESTRATOR: Evaluating execution_id=511672404708425883, trigger=step_result, event_id=511672435704332451\n",
      "2025-12-06T23:21:47.545377178Z      Message: ORCHESTRATOR: Execution 511672404708425883 state=in_progress\n",
      "2025-12-06T23:21:47.546077511Z      Message: ORCHESTRATOR: Error evaluating execution 511672404708425883\n",
      "2025-12-06T23:21:47.546255595Z                \"execution_id\": \"511672404708425883\",\n",
      "2025-12-06T23:21:47.546264595Z                  \"iterator_started\": true,\n",
      "2025-12-06T23:21:47.546303345Z                \"execution_id\": \"511672404708425883\",\n",
      "2025-12-06T23:21:47.554548303Z      Message: QUEUE_COMPLETION_DEBUG: Job 511672404976861342 completed for execution 511672404708425883\n",
      "2025-12-06T23:21:47.554702636Z      Message: ORCHESTRATOR: Evaluating execution_id=511672404708425883, trigger=None, event_id=None\n",
      "2025-12-06T23:21:47.556197261Z      Message: ORCHESTRATOR: Execution 511672404708425883 state=in_progress\n",
      "2025-12-06T23:21:47.556202220Z      Message: ORCHESTRATOR: No transition processing needed for None\n",
      "2025-12-06T23:21:47.556209095Z      Message: ORCHESTRATOR: Evaluation complete for execution 511672404708425883\n",
      "2025-12-06T23:26:24.646143667Z                \"execution_id\": \"511672404708425883\",\n"
     ]
    }
   ],
   "source": [
    "# The iterator_started event was emitted at 2025-12-06 23:21:47.519055\n",
    "# Let's check ALL server logs from around that time\n",
    "\n",
    "execution_id = 511672404708425883\n",
    "\n",
    "result = subprocess.run(\n",
    "    [\"kubectl\", \"get\", \"pods\", \"-n\", \"noetl\", \"-l\", \"app=noetl-server\", \"-o\", \"jsonpath={.items[0].metadata.name}\"],\n",
    "    capture_output=True,\n",
    "    text=True\n",
    ")\n",
    "server_pod = result.stdout.strip()\n",
    "\n",
    "# Get logs with timestamps - look for logs around 23:21:47\n",
    "result = subprocess.run(\n",
    "    [\"kubectl\", \"logs\", \"-n\", \"noetl\", server_pod, \"--timestamps\", \"--since=10m\"],\n",
    "    capture_output=True,\n",
    "    text=True\n",
    ")\n",
    "\n",
    "lines = result.stdout.split('\\n')\n",
    "\n",
    "# Filter for logs related to our execution or iterator/orchestrator\n",
    "print(f\"Searching logs for execution {execution_id}...\\n\")\n",
    "\n",
    "relevant = []\n",
    "for line in lines:\n",
    "    if str(execution_id) in line:\n",
    "        relevant.append(line)\n",
    "    elif any(word in line for word in ['iterator_started', 'ORCHESTRATOR', 'EMIT EVENT']):\n",
    "        # Check if timestamp is around 23:21\n",
    "        if '23:21:' in line or '23:22:' in line:\n",
    "            relevant.append(line)\n",
    "\n",
    "print(f\"Found {len(relevant)} relevant lines:\\n\")\n",
    "for line in relevant[-40:]:  # Last 40 relevant lines\n",
    "    print(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bee69ba0",
   "metadata": {},
   "source": [
    "## Get Full Error Traceback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "94281688",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking for error traceback around iterator_started processing...\n",
      "\n",
      "Error context:\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Get full logs with tracebacks around the iterator_started error\n",
    "\n",
    "result = subprocess.run(\n",
    "    [\"kubectl\", \"get\", \"pods\", \"-n\", \"noetl\", \"-l\", \"app=noetl-server\", \"-o\", \"jsonpath={.items[0].metadata.name}\"],\n",
    "    capture_output=True,\n",
    "    text=True\n",
    ")\n",
    "server_pod = result.stdout.strip()\n",
    "\n",
    "# Get logs with JSON formatting to see full messages\n",
    "result = subprocess.run(\n",
    "    [\"kubectl\", \"logs\", \"-n\", \"noetl\", server_pod, \"--timestamps\", \"--since=10m\"],\n",
    "    capture_output=True,\n",
    "    text=True\n",
    ")\n",
    "\n",
    "lines = result.stdout.split('\\n')\n",
    "\n",
    "# Find the error around iterator_started\n",
    "print(\"Looking for error traceback around iterator_started processing...\\n\")\n",
    "\n",
    "in_error_block = False\n",
    "error_lines = []\n",
    "for i, line in enumerate(lines):\n",
    "    if '511672435494617249' in line and 'Detected iterator_started' in line:\n",
    "        # Start capturing from here\n",
    "        in_error_block = True\n",
    "        error_lines.append(line)\n",
    "    elif in_error_block:\n",
    "        error_lines.append(line)\n",
    "        # Stop after we see the error and a few more lines\n",
    "        if len(error_lines) > 50:\n",
    "            break\n",
    "\n",
    "print(\"Error context:\")\n",
    "print(\"=\" * 100)\n",
    "for line in error_lines[:50]:\n",
    "    print(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b59cdc5",
   "metadata": {},
   "source": [
    "## Run New Test Execution With Fixed Orchestrator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b589de30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Launching test execution with fixed orchestrator...\n",
      "\n",
      "‚úì Execution started: 511676708500537509\n",
      "  Status: running\n",
      "\n",
      "Waiting for orchestrator to process iterator_started...\n",
      "\n",
      "üìã Queue entries (expecting 1 parent + 2 iterations = 3 total):\n",
      "   Found: 1 jobs\n",
      "\n",
      "Execution ID              Parent                    Node                                     Status\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "511676708500537509        -                         fetch_all_endpoints                      done\n",
      "\n",
      "‚ö† Expected 3 jobs (1 parent + 2 iterations), got 1\n"
     ]
    }
   ],
   "source": [
    "# Run a fresh test execution now that the fixed orchestrator is deployed\n",
    "print(\"üöÄ Launching test execution with fixed orchestrator...\\n\")\n",
    "\n",
    "response = requests.post(\n",
    "    f\"{NOETL_SERVER_URL}/api/run/playbook\",\n",
    "    json={\n",
    "        \"path\": TEST_PATH,\n",
    "        \"workload\": {}\n",
    "    }\n",
    ")\n",
    "\n",
    "if response.status_code == 200:\n",
    "    result = response.json()\n",
    "    new_exec_id = result['execution_id']\n",
    "    print(f\"‚úì Execution started: {new_exec_id}\")\n",
    "    print(f\"  Status: {result.get('status')}\\n\")\n",
    "    \n",
    "    # Wait a moment for processing\n",
    "    print(\"Waiting for orchestrator to process iterator_started...\")\n",
    "    time.sleep(5)\n",
    "    \n",
    "    # Check queue for iteration jobs\n",
    "    with psycopg.connect(**{k: v for k, v in DB_CONFIG.items()}) as conn:\n",
    "        with conn.cursor() as cur:\n",
    "            cur.execute(\"\"\"\n",
    "                SELECT \n",
    "                    execution_id,\n",
    "                    parent_execution_id,\n",
    "                    node_name,\n",
    "                    status\n",
    "                FROM noetl.queue\n",
    "                WHERE parent_execution_id = %s OR execution_id = %s\n",
    "                ORDER BY created_at\n",
    "            \"\"\", (new_exec_id, new_exec_id))\n",
    "            \n",
    "            jobs = cur.fetchall()\n",
    "            \n",
    "            print(f\"\\nüìã Queue entries (expecting 1 parent + 2 iterations = 3 total):\")\n",
    "            print(f\"   Found: {len(jobs)} jobs\\n\")\n",
    "            \n",
    "            if len(jobs) > 0:\n",
    "                print(f\"{'Execution ID':<25} {'Parent':<25} {'Node':<40} {'Status'}\")\n",
    "                print(\"-\" * 120)\n",
    "                for exec_id, parent_id, node, status in jobs:\n",
    "                    print(f\"{exec_id:<25} {parent_id or '-':<25} {node:<40} {status}\")\n",
    "                    \n",
    "                if len(jobs) >= 3:\n",
    "                    print(\"\\nüéâ SUCCESS! Iteration jobs were enqueued!\")\n",
    "                    print(\"   Phase 2 orchestration is working!\")\n",
    "                else:\n",
    "                    print(f\"\\n‚ö† Expected 3 jobs (1 parent + 2 iterations), got {len(jobs)}\")\n",
    "            else:\n",
    "                print(\"‚ö† No jobs found - checking server logs for errors...\")\n",
    "else:\n",
    "    print(f\"‚úó Failed to start execution: {response.status_code}\")\n",
    "    print(f\"  Error: {response.text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19046fdc",
   "metadata": {},
   "source": [
    "## Final Test After Pod Restart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "14a47e61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Final test with freshly restarted pod...\n",
      "\n",
      "‚úì Execution started: 511677392524411054\n",
      "\n",
      "Waiting 5 seconds...\n",
      "\n",
      "üìã Queue Status:\n",
      "   Total jobs: 1\n",
      "\n",
      "Execution ID              Parent                    Node                                          Status\n",
      "----------------------------------------------------------------------------------------------------------------------------------\n",
      "511677392524411054        -                         fetch_all_endpoints                           done\n",
      "\n",
      "   Parent job: 1\n",
      "   Iteration jobs: 0\n"
     ]
    }
   ],
   "source": [
    "# Final test after forcing pod restart\n",
    "print(\"üöÄ Final test with freshly restarted pod...\\n\")\n",
    "\n",
    "response = requests.post(\n",
    "    f\"{NOETL_SERVER_URL}/api/run/playbook\",\n",
    "    json={\n",
    "        \"path\": TEST_PATH\n",
    "    }\n",
    ")\n",
    "\n",
    "if response.status_code == 200:\n",
    "    result = response.json()\n",
    "    final_exec_id = result['execution_id']\n",
    "    print(f\"‚úì Execution started: {final_exec_id}\\n\")\n",
    "    \n",
    "    # Wait for processing\n",
    "    print(\"Waiting 5 seconds...\")\n",
    "    time.sleep(5)\n",
    "    \n",
    "    # Check queue\n",
    "    with psycopg.connect(**{k: v for k, v in DB_CONFIG.items()}) as conn:\n",
    "        with conn.cursor() as cur:\n",
    "            cur.execute(\"\"\"\n",
    "                SELECT \n",
    "                    execution_id,\n",
    "                    parent_execution_id,\n",
    "                    node_name,\n",
    "                    status\n",
    "                FROM noetl.queue\n",
    "                WHERE parent_execution_id = %s OR execution_id = %s\n",
    "                ORDER BY created_at\n",
    "            \"\"\", (final_exec_id, final_exec_id))\n",
    "            \n",
    "            jobs = cur.fetchall()\n",
    "            \n",
    "            print(f\"\\nüìã Queue Status:\")\n",
    "            print(f\"   Total jobs: {len(jobs)}\\n\")\n",
    "            \n",
    "            if len(jobs) > 0:\n",
    "                print(f\"{'Execution ID':<25} {'Parent':<25} {'Node':<45} {'Status'}\")\n",
    "                print(\"-\" * 130)\n",
    "                for exec_id, parent_id, node, status in jobs:\n",
    "                    marker = \" ‚úì\" if parent_id else \"\"\n",
    "                    print(f\"{exec_id:<25} {parent_id or '-':<25} {node:<45} {status}{marker}\")\n",
    "                    \n",
    "                iteration_count = sum(1 for _, parent_id, _, _ in jobs if parent_id)\n",
    "                print(f\"\\n   Parent job: 1\")\n",
    "                print(f\"   Iteration jobs: {iteration_count}\")\n",
    "                \n",
    "                if iteration_count == 2:\n",
    "                    print(\"\\nüéâüéâüéâ SUCCESS! Phase 2 is working! üéâüéâüéâ\")\n",
    "                    print(\"   - Server detected iterator_started\")\n",
    "                    print(\"   - Enqueued 2 iteration jobs\")\n",
    "                    print(\"   - Workers can now execute iterations with pagination\")\n",
    "else:\n",
    "    print(f\"‚úó Error: {response.status_code} - {response.text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6f725f3",
   "metadata": {},
   "source": [
    "## Complete Deployment and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1e6a9f0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading image into kind...\n",
      "‚úì Image loaded\n",
      "\n",
      "Restarting deployments...\n",
      "deployment.apps/noetl-server restarted\n",
      "deployment.apps/noetl-worker restarted\n",
      "Waiting for rollout...\n",
      "NAME                            READY   STATUS        RESTARTS   AGE\n",
      "noetl-server-5bddfb74ff-cpds5   1/1     Running       0          10s\n",
      "noetl-worker-6d8cd96b68-v4gwv   1/1     Running       0          10s\n",
      "noetl-worker-8697858789-66kz8   1/1     Terminating   0          11s\n",
      "\n",
      "\n",
      "‚úì Deployment complete! Ready to test.\n"
     ]
    }
   ],
   "source": [
    "# Complete image load and deployment\n",
    "import subprocess\n",
    "import time\n",
    "\n",
    "print(\"Loading image into kind...\")\n",
    "result = subprocess.run(\n",
    "    [\"kind\", \"load\", \"docker-image\", \"local/noetl:2025-12-06-15-33\", \"--name\", \"noetl\"],\n",
    "    capture_output=True,\n",
    "    text=True,\n",
    "    timeout=120\n",
    ")\n",
    "\n",
    "if result.returncode == 0:\n",
    "    print(\"‚úì Image loaded\\n\")\n",
    "    \n",
    "    print(\"Restarting deployments...\")\n",
    "    subprocess.run([\"kubectl\", \"rollout\", \"restart\", \"deployment\", \"-n\", \"noetl\", \"noetl-server\", \"noetl-worker\"])\n",
    "    \n",
    "    print(\"Waiting for rollout...\")\n",
    "    time.sleep(10)\n",
    "    \n",
    "    result = subprocess.run(\n",
    "        [\"kubectl\", \"get\", \"pods\", \"-n\", \"noetl\"],\n",
    "        capture_output=True,\n",
    "        text=True\n",
    "    )\n",
    "    print(result.stdout)\n",
    "    \n",
    "    print(\"\\n‚úì Deployment complete! Ready to test.\")\n",
    "else:\n",
    "    print(f\"‚úó Image load failed: {result.stderr}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f40559a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching test execution...\n",
      "‚úì Test started: 511679072586432695\n",
      "\n",
      "Queue entries: 1\n",
      "Execution ID              Parent                    Node                                     Status\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "511679072586432695        None                      fetch_all_endpoints                      leased\n",
      "\n",
      "‚ö† No iteration jobs found yet. Checking logs...\n"
     ]
    }
   ],
   "source": [
    "# Run final test with all fixes deployed\n",
    "print(\"Launching test execution...\")\n",
    "response = requests.post(\n",
    "    f\"{NOETL_SERVER_URL}/api/run/playbook\",\n",
    "    json={\n",
    "        \"path\": TEST_PATH\n",
    "    }\n",
    ")\n",
    "\n",
    "if response.status_code == 200:\n",
    "    result = response.json()\n",
    "    exec_id = result['execution_id']\n",
    "    print(f\"‚úì Test started: {exec_id}\\n\")\n",
    "    \n",
    "    # Wait a moment for processing\n",
    "    time.sleep(3)\n",
    "    \n",
    "    # Check queue for iteration jobs\n",
    "    with psycopg.connect(**{k: v for k, v in DB_CONFIG.items()}) as conn:\n",
    "        with conn.cursor() as cur:\n",
    "            cur.execute(\"\"\"\n",
    "                SELECT execution_id, parent_execution_id, node_name, status\n",
    "                FROM noetl.queue\n",
    "                WHERE execution_id = %s OR parent_execution_id = %s\n",
    "                ORDER BY created_at\n",
    "            \"\"\", (exec_id, exec_id))\n",
    "            \n",
    "            jobs = cur.fetchall()\n",
    "            \n",
    "            print(f\"Queue entries: {len(jobs)}\")\n",
    "            print(f\"{'Execution ID':<25} {'Parent':<25} {'Node':<40} {'Status'}\")\n",
    "            print(\"-\" * 120)\n",
    "            for job in jobs:\n",
    "                job_id, parent, node, status = job\n",
    "                marker = \" ‚Üê ITERATION JOB!\" if parent == exec_id else \"\"\n",
    "                print(f\"{job_id:<25} {parent or 'None':<25} {node:<40} {status}{marker}\")\n",
    "            \n",
    "            if len(jobs) > 1:\n",
    "                print(f\"\\nüéâ SUCCESS! Found {len(jobs)-1} iteration jobs enqueued!\")\n",
    "                print(\"Phase 2 is WORKING!\")\n",
    "            else:\n",
    "                print(\"\\n‚ö† No iteration jobs found yet. Checking logs...\")\n",
    "else:\n",
    "    print(f\"‚úó Failed to start: {response.status_code} - {response.text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "df1bb6c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching for execution 511679072586432695 or iterator_started...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check logs for THIS execution\n",
    "exec_id = 511679072586432695\n",
    "\n",
    "result = subprocess.run(\n",
    "    [\"kubectl\", \"get\", \"pods\", \"-n\", \"noetl\", \"-l\", \"app=noetl-server\", \"-o\", \"jsonpath={.items[0].metadata.name}\"],\n",
    "    capture_output=True,\n",
    "    text=True\n",
    ")\n",
    "server_pod = result.stdout.strip()\n",
    "\n",
    "result = subprocess.run(\n",
    "    [\"kubectl\", \"logs\", \"-n\", \"noetl\", server_pod, \"--tail=100\"],\n",
    "    capture_output=True,\n",
    "    text=True\n",
    ")\n",
    "\n",
    "lines = result.stdout.split('\\n')\n",
    "\n",
    "print(f\"Searching for execution {exec_id} or iterator_started...\\n\")\n",
    "for line in lines:\n",
    "    if str(exec_id) in line or ('iterator_started' in line and '23:' in line):\n",
    "        print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b76fcdd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for worker to complete...\n",
      "\n",
      "Events for execution 511679072586432695:\n",
      "  playbook_started          STARTED         2025-12-06 23:34:58.731446\n",
      "  workflow_initialized      COMPLETED       2025-12-06 23:34:58.744419\n",
      "  step_started              RUNNING         2025-12-06 23:34:58.754355\n",
      "\n",
      "‚è≥ Still waiting for iterator_started event...\n"
     ]
    }
   ],
   "source": [
    "# Wait for worker to process and emit iterator_started\n",
    "exec_id = 511679072586432695\n",
    "\n",
    "print(\"Waiting for worker to complete...\")\n",
    "time.sleep(5)\n",
    "\n",
    "# Check events\n",
    "with psycopg.connect(**{k: v for k, v in DB_CONFIG.items()}) as conn:\n",
    "    with conn.cursor() as cur:\n",
    "        cur.execute(\"\"\"\n",
    "            SELECT event_type, status, created_at\n",
    "            FROM noetl.event\n",
    "            WHERE execution_id = %s\n",
    "            ORDER BY created_at\n",
    "        \"\"\", (exec_id,))\n",
    "        \n",
    "        events = cur.fetchall()\n",
    "        \n",
    "        print(f\"\\nEvents for execution {exec_id}:\")\n",
    "        for event_type, status, created in events:\n",
    "            print(f\"  {event_type:<25} {status:<15} {created}\")\n",
    "        \n",
    "        # Check for iterator_started\n",
    "        has_iterator_started = any(e[0] == 'iterator_started' for e in events)\n",
    "        \n",
    "        if has_iterator_started:\n",
    "            print(\"\\n‚úì iterator_started event emitted!\")\n",
    "            print(\"Waiting 2 more seconds for orchestrator...\")\n",
    "            time.sleep(2)\n",
    "            \n",
    "            # Check queue again\n",
    "            cur.execute(\"\"\"\n",
    "                SELECT COUNT(*) \n",
    "                FROM noetl.queue\n",
    "                WHERE parent_execution_id = %s\n",
    "            \"\"\", (exec_id,))\n",
    "            \n",
    "            count = cur.fetchone()[0]\n",
    "            print(f\"Iteration jobs in queue: {count}\")\n",
    "        else:\n",
    "            print(\"\\n‚è≥ Still waiting for iterator_started event...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7ae64160",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting... (2s)\n",
      "‚úì iterator_started found after 4 seconds!\n",
      "\n",
      "‚ö† No iteration jobs found. Checking logs for errors...\n",
      "               \"execution_id\": \"511679072586432695\",\n",
      "     Message: QUEUE_COMPLETION_DEBUG: Job 511679072829702330 completed for execution 511679072586432695\n",
      "     Message: ORCHESTRATOR: Evaluating execution_id=511679072586432695, trigger=None, event_id=None\n",
      "     Message: ORCHESTRATOR: Execution 511679072586432695 state=in_progress\n",
      "     Message: ORCHESTRATOR: Evaluation complete for execution 511679072586432695\n"
     ]
    }
   ],
   "source": [
    "# Wait longer for worker\n",
    "exec_id = 511679072586432695\n",
    "\n",
    "found = False\n",
    "for i in range(10):\n",
    "    time.sleep(2)\n",
    "    \n",
    "    with psycopg.connect(**{k: v for k, v in DB_CONFIG.items()}) as conn:\n",
    "        with conn.cursor() as cur:\n",
    "            cur.execute(\"\"\"\n",
    "                SELECT event_type\n",
    "                FROM noetl.event\n",
    "                WHERE execution_id = %s\n",
    "                AND event_type = 'iterator_started'\n",
    "            \"\"\", (exec_id,))\n",
    "            \n",
    "            if cur.fetchone():\n",
    "                found = True\n",
    "                print(f\"‚úì iterator_started found after {(i+1)*2} seconds!\")\n",
    "                \n",
    "                # Wait for orchestrator\n",
    "                time.sleep(2)\n",
    "                \n",
    "                # Check queue\n",
    "                cur.execute(\"\"\"\n",
    "                    SELECT execution_id, node_name\n",
    "                    FROM noetl.queue\n",
    "                    WHERE parent_execution_id = %s\n",
    "                \"\"\", (exec_id,))\n",
    "                \n",
    "                iter_jobs = cur.fetchall()\n",
    "                \n",
    "                if iter_jobs:\n",
    "                    print(f\"\\nüéâ SUCCESS! Found {len(iter_jobs)} iteration jobs:\")\n",
    "                    for job_id, node in iter_jobs:\n",
    "                        print(f\"  - {job_id}: {node}\")\n",
    "                    print(\"\\nPhase 2 is WORKING! ‚úÖ\")\n",
    "                else:\n",
    "                    print(\"\\n‚ö† No iteration jobs found. Checking logs for errors...\")\n",
    "                    \n",
    "                    result = subprocess.run(\n",
    "                        [\"kubectl\", \"logs\", \"-n\", \"noetl\", \"-l\", \"app=noetl-server\", \"--tail=50\"],\n",
    "                        capture_output=True,\n",
    "                        text=True\n",
    "                    )\n",
    "                    \n",
    "                    for line in result.stdout.split('\\n'):\n",
    "                        if 'ERROR' in line or 'Traceback' in line or str(exec_id) in line:\n",
    "                            print(line)\n",
    "                \n",
    "                break\n",
    "    \n",
    "    if not found:\n",
    "        print(f\"Waiting... ({(i+1)*2}s)\")\n",
    "\n",
    "if not found:\n",
    "    print(\"\\n‚è∏ Timeout waiting for iterator_started\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d04e5784",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All logs mentioning execution 511679072586432695:\n",
      "\n",
      "     Message: EMIT EVENT: execution_id=511679072586432695, type=step_result\n",
      "     Message: Event emitted: event_id=511679633775919295, execution_id=511679072586432695, type=step_result, status=COMPLETED\n",
      "     Message: ORCHESTRATOR: Evaluating execution_id=511679072586432695, trigger=step_result, event_id=511679633775919295\n",
      "     Message: ORCHESTRATOR: Execution 511679072586432695 state=in_progress\n",
      "     Message: ORCHESTRATOR: Error evaluating execution 511679072586432695\n",
      "               \"execution_id\": \"511679072586432695\",\n",
      "               \"execution_id\": \"511679072586432695\",\n",
      "     Message: QUEUE_COMPLETION_DEBUG: Job 511679072829702330 completed for execution 511679072586432695\n",
      "     Message: ORCHESTRATOR: Evaluating execution_id=511679072586432695, trigger=None, event_id=None\n",
      "     Message: ORCHESTRATOR: Execution 511679072586432695 state=in_progress\n",
      "     Message: ORCHESTRATOR: Evaluation complete for execution 511679072586432695\n"
     ]
    }
   ],
   "source": [
    "# Get FULL logs for this execution to see what happened\n",
    "exec_id = 511679072586432695\n",
    "\n",
    "result = subprocess.run(\n",
    "    [\"kubectl\", \"logs\", \"-n\", \"noetl\", \"-l\", \"app=noetl-server\", \"--tail=200\"],\n",
    "    capture_output=True,\n",
    "    text=True\n",
    ")\n",
    "\n",
    "lines = result.stdout.split('\\n')\n",
    "\n",
    "print(f\"All logs mentioning execution {exec_id}:\\n\")\n",
    "for line in lines:\n",
    "    if str(exec_id) in line:\n",
    "        print(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "500673d3",
   "metadata": {},
   "source": [
    "## Deploy Fixed Image and Test Phase 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "33a8873d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updating deployments to use: local/noetl:2025-12-06-15-38\n",
      "\n",
      "noetl-server: deployment.apps/noetl-server image updated\n",
      "noetl-worker: deployment.apps/noetl-worker image updated\n",
      "\n",
      "Waiting for rollout...\n",
      "NAME                            READY   STATUS    RESTARTS   AGE\n",
      "noetl-server-7445bc4584-plkh8   1/1     Running   0          15s\n",
      "noetl-worker-687565c5c7-h9pqj   1/1     Running   0          15s\n",
      "\n",
      "\n",
      "‚úÖ Deployment complete! Running test...\n",
      "============================================================\n",
      "‚úì Test execution: 511682789486362816\n",
      "\n",
      "Waiting... (2s)\n",
      "‚úì iterator_started emitted (4s)\n",
      "‚ö† No iteration jobs yet, checking logs...\n",
      "                 \"execution_id\": \"511682789486362816\",\n",
      "       Message: QUEUE_COMPLETION_DEBUG: Job 511682789855461571 completed for execution 511682789486362816\n",
      "       Message: ORCHESTRATOR: Evaluating execution_id=511682789486362816, trigger=None, event_id=None\n",
      "       Message: ORCHESTRATOR: Execution 511682789486362816 state=in_progress\n",
      "       Message: ORCHESTRATOR: Evaluation complete for execution 511682789486362816\n"
     ]
    }
   ],
   "source": [
    "# Update deployment with latest image (2025-12-06-15-35) and test\n",
    "import subprocess\n",
    "import time\n",
    "\n",
    "# Get latest image tag\n",
    "with open('/Users/akuksin/projects/noetl/noetl/.noetl_last_build_tag.txt') as f:\n",
    "    image_tag = f.read().strip()\n",
    "\n",
    "print(f\"Updating deployments to use: local/noetl:{image_tag}\\n\")\n",
    "\n",
    "# Update deployments\n",
    "for deployment, container in [('noetl-server', 'noetl-server'), ('noetl-worker', 'worker')]:\n",
    "    result = subprocess.run(\n",
    "        ['kubectl', 'set', 'image', f'deployment/{deployment}',\n",
    "         f'{container}=local/noetl:{image_tag}', '-n', 'noetl'],\n",
    "        capture_output=True,\n",
    "        text=True\n",
    "    )\n",
    "    print(f\"{deployment}: {result.stdout.strip() or result.stderr.strip()}\")\n",
    "\n",
    "# Wait for rollout\n",
    "print(\"\\nWaiting for rollout...\")\n",
    "time.sleep(15)\n",
    "\n",
    "result = subprocess.run(\n",
    "    ['kubectl', 'get', 'pods', '-n', 'noetl'],\n",
    "    capture_output=True,\n",
    "    text=True\n",
    ")\n",
    "print(result.stdout)\n",
    "\n",
    "print(\"\\n‚úÖ Deployment complete! Running test...\\n\" + \"=\"*60)\n",
    "\n",
    "# Run test\n",
    "response = requests.post(f\"{NOETL_SERVER_URL}/api/run/playbook\", json={\"path\": TEST_PATH})\n",
    "\n",
    "if response.status_code == 200:\n",
    "    test_exec_id = response.json()['execution_id']\n",
    "    print(f\"‚úì Test execution: {test_exec_id}\\n\")\n",
    "    \n",
    "    # Wait and poll for iterator_started + iteration jobs\n",
    "    for i in range(15):\n",
    "        time.sleep(2)\n",
    "        \n",
    "        with psycopg.connect(**{k: v for k, v in DB_CONFIG.items()}) as conn:\n",
    "            with conn.cursor() as cur:\n",
    "                # Check for iterator_started\n",
    "                cur.execute(\"SELECT 1 FROM noetl.event WHERE execution_id = %s AND event_type = 'iterator_started'\", (test_exec_id,))\n",
    "                if cur.fetchone():\n",
    "                    print(f\"‚úì iterator_started emitted ({(i+1)*2}s)\")\n",
    "                    \n",
    "                    time.sleep(1)\n",
    "                    \n",
    "                    # Check for iteration jobs\n",
    "                    cur.execute(\"SELECT execution_id, node_name FROM noetl.queue WHERE parent_execution_id = %s\", (test_exec_id,))\n",
    "                    jobs = cur.fetchall()\n",
    "                    \n",
    "                    if jobs:\n",
    "                        print(f\"\\nüéâüéâüéâ PHASE 2 SUCCESS! üéâüéâüéâ\\n\")\n",
    "                        print(f\"Found {len(jobs)} iteration jobs enqueued:\")\n",
    "                        for job_id, node in jobs:\n",
    "                            print(f\"  ‚Ä¢ {node}\")\n",
    "                        print(\"\\n‚úÖ Server orchestration working!\")\n",
    "                        print(\"‚úÖ Iteration jobs properly enqueued!\")\n",
    "                        break\n",
    "                    else:\n",
    "                        print(\"‚ö† No iteration jobs yet, checking logs...\")\n",
    "                        result = subprocess.run(\n",
    "                            ['kubectl', 'logs', '-n', 'noetl', '-l', 'app=noetl-server', '--tail=30'],\n",
    "                            capture_output=True, text=True\n",
    "                        )\n",
    "                        for line in result.stdout.split('\\n'):\n",
    "                            if 'ERROR' in line or str(test_exec_id) in line:\n",
    "                                print(f\"  {line}\")\n",
    "                        break\n",
    "                        \n",
    "        print(f\"Waiting... ({(i+1)*2}s)\")\n",
    "else:\n",
    "    print(f\"‚úó Failed: {response.status_code} - {response.text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9a4c9bcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Test execution: 511697834110877954\n",
      "\n",
      "Waiting... (2s)\n",
      "‚úì iterator_started emitted (4s)\n",
      "‚ö† No iteration jobs yet, checking logs...\n",
      "                 \"execution_id\": \"511697834110877954\",\n",
      "       Message: Step started event emission TODO - execution_id=511697834110877954\n",
      "       Message: Step 'validate_results' failed in execution 511697834110877954: Expected 2 endpoint iterations, got 1\n",
      "       Message: TODO: Emit step_failed and playbook_failed events for execution 511697834110877954\n"
     ]
    }
   ],
   "source": [
    "# FINAL TEST: Phase 2 validation with fixed 'result' column\n",
    "import time\n",
    "\n",
    "response = requests.post(f\"{NOETL_SERVER_URL}/api/run/playbook\", json={\"path\": TEST_PATH})\n",
    "\n",
    "if response.status_code == 200:\n",
    "    test_exec_id = response.json()['execution_id']\n",
    "    print(f\"‚úì Test execution: {test_exec_id}\\n\")\n",
    "    \n",
    "    # Wait and poll for iterator_started + iteration jobs\n",
    "    for i in range(15):\n",
    "        time.sleep(2)\n",
    "        \n",
    "        with psycopg.connect(**{k: v for k, v in DB_CONFIG.items()}) as conn:\n",
    "            with conn.cursor() as cur:\n",
    "                # Check for iterator_started\n",
    "                cur.execute(\"SELECT 1 FROM noetl.event WHERE execution_id = %s AND event_type = 'iterator_started'\", (test_exec_id,))\n",
    "                if cur.fetchone():\n",
    "                    print(f\"‚úì iterator_started emitted ({(i+1)*2}s)\")\n",
    "                    \n",
    "                    time.sleep(1)\n",
    "                    \n",
    "                    # Check for iteration jobs\n",
    "                    cur.execute(\"SELECT execution_id, node_name FROM noetl.queue WHERE parent_execution_id = %s\", (test_exec_id,))\n",
    "                    jobs = cur.fetchall()\n",
    "                    \n",
    "                    if jobs:\n",
    "                        print(f\"\\nüéâüéâüéâ PHASE 2 SUCCESS! üéâüéâüéâ\\n\")\n",
    "                        print(f\"Found {len(jobs)} iteration jobs enqueued:\")\n",
    "                        for job_id, node in jobs:\n",
    "                            print(f\"  ‚Ä¢ execution_id={job_id}, node={node}\")\n",
    "                        print(\"\\n‚úÖ Server orchestration working!\")\n",
    "                        print(\"‚úÖ Iteration jobs properly enqueued!\")\n",
    "                        print(\"‚úÖ ALL cursor bugs fixed!\")\n",
    "                        break\n",
    "                    else:\n",
    "                        print(\"‚ö† No iteration jobs yet, checking logs...\")\n",
    "                        result = subprocess.run(\n",
    "                            ['kubectl', 'logs', '-n', 'noetl', '-l', 'app=noetl-server', '--tail=30'],\n",
    "                            capture_output=True, text=True\n",
    "                        )\n",
    "                        for line in result.stdout.split('\\n'):\n",
    "                            if 'ERROR' in line or str(test_exec_id) in line:\n",
    "                                print(f\"  {line}\")\n",
    "                        break\n",
    "                        \n",
    "        print(f\"Waiting... ({(i+1)*2}s)\")\n",
    "else:\n",
    "    print(f\"‚úó Failed: {response.status_code} - {response.text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "743cf914",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1 events with iterator_started flag:\n",
      "shape: (1, 6)\n",
      "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
      "‚îÇ event_id              ‚îÜ execution_id         ‚îÜ event_type  ‚îÜ node_type ‚îÜ status    ‚îÜ result      ‚îÇ\n",
      "‚îÇ ---                   ‚îÜ ---                  ‚îÜ ---         ‚îÜ ---       ‚îÜ ---       ‚îÜ ---         ‚îÇ\n",
      "‚îÇ i64                   ‚îÜ i64                  ‚îÜ str         ‚îÜ str       ‚îÜ str       ‚îÜ str         ‚îÇ\n",
      "‚ïû‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï°\n",
      "‚îÇ 511687671522001131    ‚îÜ 511687636918993120   ‚îÜ step_result ‚îÜ iterator  ‚îÜ COMPLETED ‚îÜ {\"message\": ‚îÇ\n",
      "‚îÇ                       ‚îÜ                      ‚îÜ             ‚îÜ           ‚îÜ           ‚îÜ \"Iterator   ‚îÇ\n",
      "‚îÇ                       ‚îÜ                      ‚îÜ             ‚îÜ           ‚îÜ           ‚îÜ analysis‚Ä¶   ‚îÇ\n",
      "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n"
     ]
    }
   ],
   "source": [
    "# Check what event type has iterator_started in result\n",
    "import polars as pl\n",
    "\n",
    "with psycopg.connect(**{k: v for k, v in DB_CONFIG.items()}) as conn:\n",
    "    query = \"\"\"\n",
    "    SELECT event_id, execution_id, event_type, node_type, status, result::text\n",
    "    FROM noetl.event\n",
    "    WHERE execution_id = 511687636918993120\n",
    "    AND result::text LIKE '%iterator_started%true%'\n",
    "    ORDER BY created_at\n",
    "    \"\"\"\n",
    "    events_df = pl.read_database(query, connection=conn)\n",
    "    \n",
    "print(f\"Found {len(events_df)} events with iterator_started flag:\")\n",
    "print(events_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fa3e99ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "event_id: 511687671522001131\n",
      "event_type: step_result\n",
      "node_type: iterator\n",
      "node_name: fetch_all_endpoints\n",
      "\n",
      "result: {\n",
      "  \"message\": \"Iterator analysis complete, server will execute iterations\",\n",
      "  \"iterator_started\": true,\n",
      "  \"total_iterations\": 2\n",
      "}\n",
      "\n",
      "context: None\n"
     ]
    }
   ],
   "source": [
    "# Check event details for iterator step_result\n",
    "import json\n",
    "\n",
    "with psycopg.connect(**{k: v for k, v in DB_CONFIG.items()}) as conn:\n",
    "    with conn.cursor(row_factory=psycopg.rows.dict_row) as cur:\n",
    "        cur.execute(\"\"\"\n",
    "            SELECT event_id, event_type, node_type, node_name, result, context\n",
    "            FROM noetl.event\n",
    "            WHERE execution_id = 511687636918993120\n",
    "            AND event_type = 'step_result'\n",
    "            AND node_type = 'iterator'\n",
    "            ORDER BY created_at\n",
    "        \"\"\")\n",
    "        row = cur.fetchone()\n",
    "        \n",
    "if row:\n",
    "    print(f\"event_id: {row['event_id']}\")\n",
    "    print(f\"event_type: {row['event_type']}\")\n",
    "    print(f\"node_type: {row['node_type']}\")\n",
    "    print(f\"node_name: {row['node_name']}\")\n",
    "    print(f\"\\nresult: {json.dumps(row['result'], indent=2)}\")\n",
    "    print(f\"\\ncontext: {json.dumps(row['context'], indent=2) if row['context'] else 'None'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "670c3338",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total events for execution 511691852421005553: 14\n",
      "\n",
      "1. event_type=playbook_started, node_type=execution, node_name=tests/pagination/loop_with_pagination/loop_with_pagination, status=STARTED\n",
      "\n",
      "2. event_type=workflow_initialized, node_type=workflow, node_name=workflow, status=COMPLETED\n",
      "\n",
      "3. event_type=step_started, node_type=http, node_name=fetch_all_endpoints, status=RUNNING\n",
      "\n",
      "4. event_type=action_started, node_type=iterator, node_name=fetch_all_endpoints, status=RUNNING\n",
      "   Result preview: NULL\n",
      "\n",
      "5. event_type=iterator_started, node_type=iterator, node_name=iterator, status=RUNNING\n",
      "   Result preview: NULL\n",
      "\n",
      "6. event_type=action_completed, node_type=iterator, node_name=fetch_all_endpoints, status=COMPLETED\n",
      "   Result preview: NULL\n",
      "\n",
      "7. event_type=step_completed, node_type=http, node_name=fetch_all_endpoints, status=COMPLETED\n",
      "\n",
      "8. event_type=step_started, node_type=python, node_name=validate_results, status=RUNNING\n",
      "\n",
      "9. event_type=step_result, node_type=iterator, node_name=fetch_all_endpoints, status=COMPLETED\n",
      "   Result preview: {\n",
      "    \"message\": \"Iterator analysis complete, server will execute iterations\",\n",
      "    \"iterator_started\": true,\n",
      "    \"total_iterations\": 2\n",
      "}\n",
      "\n",
      "10. event_type=action_started, node_type=task, node_name=validate_results, status=RUNNING\n",
      "\n",
      "11. event_type=action_failed, node_type=task, node_name=validate_results, status=FAILED\n",
      "\n",
      "12. event_type=playbook_failed, node_type=execution, node_name=tests/pagination/loop_with_pagination/loop_with_pagination, status=FAILED\n",
      "\n",
      "13. event_type=workflow_failed, node_type=workflow, node_name=workflow, status=FAILED\n",
      "\n",
      "14. event_type=step_failed, node_type=step, node_name=validate_results, status=FAILED\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check ALL events for latest test execution to see full event flow\n",
    "exec_id = 511691852421005553\n",
    "\n",
    "with psycopg.connect(**{k: v for k, v in DB_CONFIG.items()}) as conn:\n",
    "    with conn.cursor(row_factory=psycopg.rows.dict_row) as cur:\n",
    "        cur.execute(\"\"\"\n",
    "            SELECT event_id, event_type, node_type, node_name, status, \n",
    "                   CASE WHEN result IS NOT NULL THEN jsonb_pretty(result::jsonb) ELSE 'NULL' END as result_preview\n",
    "            FROM noetl.event\n",
    "            WHERE execution_id = %s\n",
    "            ORDER BY created_at\n",
    "        \"\"\", (exec_id,))\n",
    "        events = cur.fetchall()\n",
    "\n",
    "print(f\"Total events for execution {exec_id}: {len(events)}\\n\")\n",
    "for i, evt in enumerate(events, 1):\n",
    "    print(f\"{i}. event_type={evt['event_type']}, node_type={evt['node_type']}, node_name={evt['node_name']}, status={evt['status']}\")\n",
    "    if 'iterator' in str(evt['node_type']) or 'loop' in str(evt['result_preview']).lower():\n",
    "        print(f\"   Result preview: {evt['result_preview'][:200]}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5ff8d850",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iterator_started event found!\n",
      "event_id: 511691889599316215\n",
      "result: None\n",
      "context: {\n",
      "  \"mode\": \"sequential\",\n",
      "  \"enumerate\": false,\n",
      "  \"chunk_size\": null,\n",
      "  \"collection\": [\n",
      "    {\n",
      "      \"name\": \"assessments\",\n",
      "      \"path\": \"/api/v1/assessments\",\n",
      "      \"page_size\": 10\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"users\",\n",
      "      \"path\": \"/api/v1/users\",\n",
      "      \"page_size\": 15\n",
      "    }\n",
      "  ],\n",
      "  \"concurrency\": 1,\n",
      "  \"nested_task\": {\n",
      "    \"url\": \"{{ workload.api_url }}{{ endpoint.path }}\",\n",
      "    \"args\": {},\n",
      "    \"name\": null,\n",
      "    \"sink\": null,\n",
      "    \"tool\": \"http\",\n",
      "    \"retry\": {\n",
      "      \"on_success\": {\n",
      "        \"while\": \"{{ response.paging.hasMore == true }}\",\n",
      "        \"collect\": {\n",
      "          \"into\": \"pages\",\n",
      "          \"path\": \"data\",\n",
      "          \"strategy\": \"append\"\n",
      "        },\n",
      "        \"next_call\": {\n",
      "          \"params\": {\n",
      "            \"page\": \"{{ (response.paging.page | int) + 1 }}\",\n",
      "            \"pageSize\": \"{{ response.paging.pageSize }}\"\n",
      "          }\n",
      "        },\n",
      "        \"max_attempts\": 10\n",
      "      }\n",
      "    },\n",
      "    \"method\": \"GET\",\n",
      "    \"params\": {\n",
      "      \"page\": 1,\n",
      "      \"pageSize\": \"{{ endpoint.page_size }}\"\n",
      "    }\n",
      "  },\n",
      "  \"total_count\": 2,\n",
      "  \"iterator_name\": \"endpoint\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Check iterator_started event details (event #5)\n",
    "with psycopg.connect(**{k: v for k, v in DB_CONFIG.items()}) as conn:\n",
    "    with conn.cursor(row_factory=psycopg.rows.dict_row) as cur:\n",
    "        cur.execute(\"\"\"\n",
    "            SELECT event_id, event_type, node_type, result, context\n",
    "            FROM noetl.event\n",
    "            WHERE execution_id = %s\n",
    "            AND event_type = 'iterator_started'\n",
    "            ORDER BY created_at\n",
    "        \"\"\", (exec_id,))\n",
    "        evt = cur.fetchone()\n",
    "\n",
    "if evt:\n",
    "    print(f\"iterator_started event found!\")\n",
    "    print(f\"event_id: {evt['event_id']}\")\n",
    "    print(f\"result: {evt['result']}\")\n",
    "    print(f\"context: {json.dumps(evt['context'], indent=2) if evt['context'] else 'NULL'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0f856426",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Queue jobs for execution 511697834110877954:\n",
      "\n",
      "Total iteration jobs: 0\n"
     ]
    }
   ],
   "source": [
    "# Check queue table for iteration jobs\n",
    "exec_id = 511697834110877954\n",
    "\n",
    "queue_query = f\"\"\"\n",
    "SELECT execution_id, node_name, parent_execution_id, catalog_id, \n",
    "       context->>'iteration_index' as iteration_index,\n",
    "       context->>'iterator_name' as iterator_name,\n",
    "       created_at\n",
    "FROM noetl.queue \n",
    "WHERE parent_execution_id = {exec_id}\n",
    "ORDER BY created_at\n",
    "\"\"\"\n",
    "\n",
    "df = query_to_polars(queue_query)\n",
    "print(f\"Queue jobs for execution {exec_id}:\")\n",
    "for row in df.iter_rows(named=True):\n",
    "    print(f\"  Job: execution={row['execution_id']}, node={row['node_name']}, \"\n",
    "          f\"iteration_index={row['iteration_index']}, iterator={row['iterator_name']}, \"\n",
    "          f\"created={row['created_at']}\")\n",
    "print(f\"\\nTotal iteration jobs: {len(df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9fee7d9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Events for execution 511697834110877954:\n",
      "  1. playbook_started: node_type=execution, node=tests/pagination/loop_with_pagination/loop_with_pagination, result=False, context=True\n",
      "  2. workflow_initialized: node_type=workflow, node=workflow, result=False, context=True\n",
      "  3. step_started: node_type=http, node=fetch_all_endpoints, result=False, context=True\n",
      "  4. action_started: node_type=iterator, node=fetch_all_endpoints, result=False, context=True\n",
      "  5. iterator_started: node_type=iterator, node=iterator, result=False, context=True\n",
      "  6. action_completed: node_type=iterator, node=fetch_all_endpoints, result=False, context=True\n",
      "  7. step_completed: node_type=http, node=fetch_all_endpoints, result=False, context=False\n",
      "  8. step_started: node_type=python, node=validate_results, result=False, context=True\n",
      "  9. step_result: node_type=iterator, node=fetch_all_endpoints, result=True, context=False\n",
      "  10. action_started: node_type=task, node=validate_results, result=False, context=True\n",
      "  11. action_failed: node_type=task, node=validate_results, result=True, context=True\n",
      "  12. step_failed: node_type=step, node=validate_results, result=False, context=False\n",
      "  13. workflow_failed: node_type=workflow, node=workflow, result=False, context=False\n",
      "  14. playbook_failed: node_type=execution, node=tests/pagination/loop_with_pagination/loop_with_pagination, result=False, context=False\n",
      "\n",
      "Total events: 14\n"
     ]
    }
   ],
   "source": [
    "# Check events for this execution\n",
    "exec_id = 511697834110877954\n",
    "\n",
    "events_query = f\"\"\"\n",
    "SELECT event_id, event_type, node_type, node_name, \n",
    "       result IS NOT NULL as has_result,\n",
    "       context IS NOT NULL as has_context\n",
    "FROM noetl.event \n",
    "WHERE execution_id = {exec_id}\n",
    "ORDER BY event_id\n",
    "\"\"\"\n",
    "\n",
    "df = query_to_polars(events_query)\n",
    "print(f\"Events for execution {exec_id}:\")\n",
    "for idx, row in enumerate(df.iter_rows(named=True), 1):\n",
    "    print(f\"  {idx}. {row['event_type']}: node_type={row['node_type']}, \"\n",
    "          f\"node={row['node_name']}, result={row['has_result']}, context={row['has_context']}\")\n",
    "print(f\"\\nTotal events: {len(df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "17995214",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß™ Testing Phase 2: Iterator job enqueueing with pending check\n",
      "============================================================\n",
      "Starting test: tests/pagination/loop_with_pagination/loop_with_pagination\n",
      "‚úì Test started\n",
      "  Execution ID: 511703850881909011\n",
      "  Status: running\n",
      "‚úì Test execution: 511703850881909011\n",
      "‚ö† No iterator_started yet, waiting...\n",
      "‚úó No iteration jobs found!\n",
      "‚úì PASS: validate_results NOT enqueued yet (waiting for iterations)\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Test Phase 2 fix - orchestrator should wait for iterations to complete\n",
    "print(\"üß™ Testing Phase 2: Iterator job enqueueing with pending check\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Start new test execution\n",
    "test_response = start_test()\n",
    "exec_id = test_response['execution_id']\n",
    "print(f\"‚úì Test execution: {exec_id}\")\n",
    "\n",
    "# Wait for iterator_started event\n",
    "time.sleep(2)\n",
    "events_query = f\"SELECT COUNT(*) as count FROM noetl.event WHERE execution_id = {exec_id} AND event_type = 'iterator_started'\"\n",
    "df = query_to_polars(events_query)\n",
    "if df['count'][0] > 0:\n",
    "    print(f\"‚úì iterator_started emitted ({time.time() - test_response['start_time']:.0f}s)\")\n",
    "else:\n",
    "    print(f\"‚ö† No iterator_started yet, waiting...\")\n",
    "\n",
    "# Check for iteration jobs in queue\n",
    "time.sleep(2)\n",
    "queue_query = f\"\"\"\n",
    "SELECT execution_id, node_name, status,\n",
    "       context->>'iteration_index' as iteration_index,\n",
    "       context->>'iterator_name' as iterator_name\n",
    "FROM noetl.queue \n",
    "WHERE parent_execution_id = {exec_id}\n",
    "ORDER BY created_at\n",
    "\"\"\"\n",
    "df = query_to_polars(queue_query)\n",
    "if len(df) > 0:\n",
    "    print(f\"‚úì {len(df)} iteration jobs enqueued!\")\n",
    "    for row in df.iter_rows(named=True):\n",
    "        print(f\"  - Iteration {row['iteration_index']}: {row['iterator_name']}, status={row['status']}\")\n",
    "else:\n",
    "    print(\"‚úó No iteration jobs found!\")\n",
    "\n",
    "# Check if validate_results was prematurely enqueued\n",
    "premature_query = f\"\"\"\n",
    "SELECT node_name, status FROM noetl.queue \n",
    "WHERE execution_id = {exec_id} AND node_name = 'validate_results'\n",
    "\"\"\"\n",
    "df2 = query_to_polars(premature_query)\n",
    "if len(df2) > 0:\n",
    "    print(f\"‚úó FAIL: validate_results was enqueued prematurely (before iterations complete)!\")\n",
    "else:\n",
    "    print(\"‚úì PASS: validate_results NOT enqueued yet (waiting for iterations)\")\n",
    "\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d68a4af8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Events for execution 511703850881909011:\n",
      "  1. playbook_started: node_type=execution, node=tests/pagination/loop_with_pagination/loop_with_pagination, time=2025-12-07 00:24:12.536006\n",
      "  2. workflow_initialized: node_type=workflow, node=workflow, time=2025-12-07 00:24:12.547591\n",
      "  3. step_started: node_type=http, node=fetch_all_endpoints, time=2025-12-07 00:24:12.559650\n",
      "  4. action_started: node_type=iterator, node=fetch_all_endpoints, time=2025-12-07 00:24:16.911846\n",
      "  5. iterator_started: node_type=iterator, node=iterator, time=2025-12-07 00:24:16.936297\n",
      "  6. action_completed: node_type=iterator, node=fetch_all_endpoints, time=2025-12-07 00:24:16.951445\n",
      "  7. step_completed: node_type=http, node=fetch_all_endpoints, time=2025-12-07 00:24:16.963362\n",
      "  8. step_started: node_type=python, node=validate_results, time=2025-12-07 00:24:16.968061\n",
      "  9. step_result: node_type=iterator, node=fetch_all_endpoints, time=2025-12-07 00:24:16.980677\n",
      "  10. action_started: node_type=task, node=validate_results, time=2025-12-07 00:24:17.040706\n",
      "  11. action_failed: node_type=task, node=validate_results, time=2025-12-07 00:24:17.056237\n",
      "  12. step_failed: node_type=step, node=validate_results, time=2025-12-07 00:24:17.060825\n",
      "  13. workflow_failed: node_type=workflow, node=workflow, time=2025-12-07 00:24:17.060825\n",
      "  14. playbook_failed: node_type=execution, node=tests/pagination/loop_with_pagination/loop_with_pagination, time=2025-12-07 00:24:17.060825\n",
      "\n",
      "Total events: 14\n"
     ]
    }
   ],
   "source": [
    "# Check if iterator_started event was emitted for latest test\n",
    "exec_id = 511703850881909011\n",
    "\n",
    "events_query = f\"\"\"\n",
    "SELECT event_id, event_type, node_type, node_name, created_at\n",
    "FROM noetl.event \n",
    "WHERE execution_id = {exec_id}\n",
    "ORDER BY created_at\n",
    "\"\"\"\n",
    "\n",
    "df = query_to_polars(events_query)\n",
    "print(f\"Events for execution {exec_id}:\")\n",
    "for idx, row in enumerate(df.iter_rows(named=True), 1):\n",
    "    print(f\"  {idx}. {row['event_type']}: node_type={row['node_type']}, node={row['node_name']}, time={row['created_at']}\")\n",
    "print(f\"\\nTotal events: {len(df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d194f571",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéØ FINAL TEST: Pure server-side loop execution (Phase 2)\n",
      "======================================================================\n",
      "Starting test: tests/pagination/loop_with_pagination/loop_with_pagination\n"
     ]
    },
    {
     "ename": "HTTPError",
     "evalue": "400 Client Error: Bad Request for url: http://localhost:8082/api/run/playbook",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mHTTPError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[46]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33müéØ FINAL TEST: Pure server-side loop execution (Phase 2)\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      3\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m=\u001b[39m\u001b[33m\"\u001b[39m*\u001b[32m70\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m test_response = \u001b[43mstart_test\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      6\u001b[39m exec_id = test_response[\u001b[33m'\u001b[39m\u001b[33mexecution_id\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m      7\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m‚úì Test execution: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexec_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 8\u001b[39m, in \u001b[36mstart_test\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m      6\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mStarting test: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mTEST_PATH\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m      7\u001b[39m response = requests.post(url, json=payload, timeout=\u001b[32m30\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m \u001b[43mresponse\u001b[49m\u001b[43m.\u001b[49m\u001b[43mraise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     10\u001b[39m result = response.json()\n\u001b[32m     11\u001b[39m execution_id = result[\u001b[33m'\u001b[39m\u001b[33mexecution_id\u001b[39m\u001b[33m'\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/noetl/noetl/.venv/lib/python3.12/site-packages/requests/models.py:1026\u001b[39m, in \u001b[36mResponse.raise_for_status\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1021\u001b[39m     http_error_msg = (\n\u001b[32m   1022\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.status_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m Server Error: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mreason\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m for url: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.url\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m   1023\u001b[39m     )\n\u001b[32m   1025\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m http_error_msg:\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(http_error_msg, response=\u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[31mHTTPError\u001b[39m: 400 Client Error: Bad Request for url: http://localhost:8082/api/run/playbook"
     ]
    }
   ],
   "source": [
    "# ‚úÖ FINAL TEST: Pure server-side loop execution\n",
    "print(\"üéØ FINAL TEST: Pure server-side loop execution (Phase 2)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "test_response = start_test()\n",
    "exec_id = test_response['execution_id']\n",
    "print(f\"‚úì Test execution: {exec_id}\\n\")\n",
    "\n",
    "# Wait for orchestrator to process\n",
    "time.sleep(5)\n",
    "\n",
    "# Check events\n",
    "events_query = f\"\"\"\n",
    "SELECT event_type, node_type, node_name\n",
    "FROM noetl.event \n",
    "WHERE execution_id = {exec_id}\n",
    "ORDER BY created_at\n",
    "\"\"\"\n",
    "df_events = query_to_polars(events_query)\n",
    "print(f\"üìã Events: {len(df_events)}\")\n",
    "for idx, row in enumerate(df_events.iter_rows(named=True), 1):\n",
    "    marker = \"üîÑ\" if \"iterator\" in row['event_type'] else \"  \"\n",
    "    print(f\"{marker} {idx}. {row['event_type']}: {row['node_type']}/{row['node_name']}\")\n",
    "\n",
    "# Check iteration jobs\n",
    "queue_query = f\"\"\"\n",
    "SELECT execution_id, node_name, status,\n",
    "       context->>'iteration_index' as idx,\n",
    "       context->>'iterator_name' as iter\n",
    "FROM noetl.queue \n",
    "WHERE parent_execution_id = {exec_id}\n",
    "ORDER BY created_at\n",
    "\"\"\"\n",
    "df_queue = query_to_polars(queue_query)\n",
    "print(f\"\\nüì¶ Iteration Jobs: {len(df_queue)}\")\n",
    "for row in df_queue.iter_rows(named=True):\n",
    "    print(f\"   ‚úì #{row['idx']}: {row['iter']}, status={row['status']}\")\n",
    "\n",
    "# Check premature next step\n",
    "premature_query = f\"SELECT 1 FROM noetl.queue WHERE execution_id = {exec_id} AND node_name = 'validate_results'\"\n",
    "df_premature = query_to_polars(premature_query)\n",
    "\n",
    "print(f\"\\nüéØ Result:\")\n",
    "if len(df_queue) == 2:\n",
    "    print(\"   ‚úÖ SUCCESS: 2 iteration jobs enqueued!\")\n",
    "else:\n",
    "    print(f\"   ‚ùå FAIL: Expected 2 jobs, got {len(df_queue)}\")\n",
    "\n",
    "if len(df_premature) == 0:\n",
    "    print(\"   ‚úÖ PASS: Next step not enqueued prematurely\")\n",
    "else:\n",
    "    print(\"   ‚ùå FAIL: Next step enqueued before iterations complete\")\n",
    "\n",
    "print(\"=\"*70)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
