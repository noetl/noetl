{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fa2c2502",
   "metadata": {},
   "source": [
    "## 1. Setup and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd7ad672",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import json\n",
    "import requests\n",
    "from typing import Dict\n",
    "\n",
    "# Modern data stack\n",
    "import psycopg\n",
    "import polars as pl\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# Configuration\n",
    "DB_CONFIG = {\n",
    "    \"host\": os.getenv(\"POSTGRES_HOST\", \"postgres.postgres.svc.cluster.local\"),\n",
    "    \"port\": os.getenv(\"POSTGRES_PORT\", \"5432\"),\n",
    "    \"user\": os.getenv(\"POSTGRES_USER\", \"demo\"),\n",
    "    \"password\": os.getenv(\"POSTGRES_PASSWORD\", \"demo\"),\n",
    "    \"dbname\": os.getenv(\"POSTGRES_DB\", \"demo_noetl\")\n",
    "}\n",
    "\n",
    "NOETL_SERVER_URL = os.getenv(\n",
    "    \"NOETL_SERVER_URL\", \n",
    "    \"http://noetl.noetl.svc.cluster.local:8082\"\n",
    ")\n",
    "\n",
    "TEST_PATH = \"tests/pagination/loop_with_pagination\"\n",
    "POLL_INTERVAL = 2\n",
    "MAX_WAIT = 120\n",
    "\n",
    "print(\"âœ“ Configuration loaded\")\n",
    "print(f\"  Server: {NOETL_SERVER_URL}\")\n",
    "print(f\"  Database: {DB_CONFIG['host']}:{DB_CONFIG['port']}/{DB_CONFIG['dbname']}\")\n",
    "print(f\"  Test: {TEST_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7f3ab61",
   "metadata": {},
   "source": [
    "## 2. Initialize Test Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6a9a4c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create test schema and table - completely self-contained\n",
    "import os\n",
    "import psycopg\n",
    "\n",
    "def get_postgres_connection():\n",
    "    \"\"\"Get psycopg3 connection\"\"\"\n",
    "    conn_string = f\"host={os.getenv('POSTGRES_HOST', 'postgres.postgres.svc.cluster.local')} \" \\\n",
    "                  f\"port={os.getenv('POSTGRES_PORT', '5432')} \" \\\n",
    "                  f\"dbname={os.getenv('POSTGRES_DB', 'demo_noetl')} \" \\\n",
    "                  f\"user={os.getenv('POSTGRES_USER', 'demo')} \" \\\n",
    "                  f\"password={os.getenv('POSTGRES_PASSWORD', 'demo')}\"\n",
    "    return psycopg.connect(conn_string)\n",
    "\n",
    "create_table_sql = \"\"\"\n",
    "CREATE SCHEMA IF NOT EXISTS noetl_test;\n",
    "\n",
    "DROP TABLE IF EXISTS noetl_test.pagination_loop_results;\n",
    "\n",
    "CREATE TABLE noetl_test.pagination_loop_results (\n",
    "    id SERIAL PRIMARY KEY,\n",
    "    execution_id BIGINT,\n",
    "    endpoint_name TEXT,\n",
    "    endpoint_path TEXT,\n",
    "    page_size INTEGER,\n",
    "    result_count INTEGER,\n",
    "    result_data JSONB,\n",
    "    iteration_index INTEGER,\n",
    "    iteration_count INTEGER,\n",
    "    created_at TIMESTAMP DEFAULT NOW()\n",
    ");\n",
    "\n",
    "CREATE INDEX IF NOT EXISTS idx_pagination_loop_execution_id \n",
    "ON noetl_test.pagination_loop_results(execution_id);\n",
    "\"\"\"\n",
    "\n",
    "with get_postgres_connection() as conn:\n",
    "    with conn.cursor() as cur:\n",
    "        cur.execute(create_table_sql)\n",
    "        conn.commit()\n",
    "\n",
    "print(\"âœ“ Test table created\")\n",
    "print(\"  Schema: noetl_test\")\n",
    "print(\"  Table: pagination_loop_results\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af508ab3",
   "metadata": {},
   "source": [
    "## 3. Database Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d726b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_postgres_connection():\n",
    "    \"\"\"Get psycopg3 connection\"\"\"\n",
    "    conn_string = f\"host={DB_CONFIG['host']} port={DB_CONFIG['port']} \" \\\n",
    "                  f\"dbname={DB_CONFIG['dbname']} user={DB_CONFIG['user']} \" \\\n",
    "                  f\"password={DB_CONFIG['password']}\"\n",
    "    return psycopg.connect(conn_string)\n",
    "\n",
    "def query_to_polars(query: str) -> pl.DataFrame:\n",
    "    \"\"\"Execute query and return as Polars DataFrame\"\"\"\n",
    "    with get_postgres_connection() as conn:\n",
    "        with conn.cursor() as cur:\n",
    "            cur.execute(query)\n",
    "            columns = [desc[0] for desc in cur.description]\n",
    "            data = cur.fetchall()\n",
    "    if not data:\n",
    "        return pl.DataFrame(schema=columns)\n",
    "    return pl.DataFrame({col: [row[i] for row in data] for i, col in enumerate(columns)})\n",
    "\n",
    "print(\"âœ“ Database utilities loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaaf6898",
   "metadata": {},
   "source": [
    "## 4. Execute Pagination Loop Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe58cc86",
   "metadata": {},
   "outputs": [],
   "source": [
    "def start_test() -> Dict:\n",
    "    \"\"\"Start pagination loop test\"\"\"\n",
    "    url = f\"{NOETL_SERVER_URL}/api/run/playbook\"\n",
    "    payload = {\"path\": TEST_PATH}\n",
    "    \n",
    "    print(f\"Starting test: {TEST_PATH}\")\n",
    "    response = requests.post(url, json=payload, timeout=30)\n",
    "    response.raise_for_status()\n",
    "    \n",
    "    result = response.json()\n",
    "    execution_id = result['execution_id']\n",
    "    \n",
    "    print(f\"âœ“ Test started\")\n",
    "    print(f\"  Execution ID: {execution_id}\")\n",
    "    print(f\"  Status: {result['status']}\")\n",
    "    \n",
    "    return result\n",
    "\n",
    "test_result = start_test()\n",
    "EXECUTION_ID = test_result['execution_id']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab0052ed",
   "metadata": {},
   "source": [
    "## 5. Monitor Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ffd9d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def monitor_execution(execution_id: int):\n",
    "    \"\"\"Monitor test execution\"\"\"\n",
    "    start_time = time.time()\n",
    "    last_count = 0\n",
    "    \n",
    "    print(f\"Monitoring execution {execution_id}...\")\n",
    "    print(f\"{'Time':<6} {'Steps':<6} {'Status':<12} {'Events'}\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    while (time.time() - start_time) < MAX_WAIT:\n",
    "        query = f\"\"\"\n",
    "            SELECT event_type, COUNT(*) as count\n",
    "            FROM noetl.event\n",
    "            WHERE execution_id = {execution_id}\n",
    "            GROUP BY event_type\n",
    "        \"\"\"\n",
    "        df = query_to_polars(query)\n",
    "        \n",
    "        step_count = df.filter(pl.col('event_type') == 'step_completed')['count'].sum() or 0\n",
    "        is_complete = df.filter(pl.col('event_type') == 'playbook_completed').height > 0\n",
    "        is_failed = df.filter(pl.col('event_type') == 'playbook_failed').height > 0\n",
    "        \n",
    "        if step_count != last_count or is_complete or is_failed:\n",
    "            elapsed = int(time.time() - start_time)\n",
    "            status = \"COMPLETED\" if is_complete else (\"FAILED\" if is_failed else \"RUNNING\")\n",
    "            total = df['count'].sum()\n",
    "            print(f\"{elapsed:<6} {step_count:<6} {status:<12} {total}\")\n",
    "            last_count = step_count\n",
    "        \n",
    "        if is_complete:\n",
    "            print(f\"\\nâœ“ Test completed in {elapsed}s\")\n",
    "            return True\n",
    "        elif is_failed:\n",
    "            print(f\"\\nâœ— Test failed after {elapsed}s\")\n",
    "            return False\n",
    "        \n",
    "        time.sleep(POLL_INTERVAL)\n",
    "    \n",
    "    print(f\"\\nâš  Timeout after {MAX_WAIT}s\")\n",
    "    return False\n",
    "\n",
    "success = monitor_execution(EXECUTION_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11dbd3b2",
   "metadata": {},
   "source": [
    "## 6. Debug: Check Execution Events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "187db13d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check execution events for errors\n",
    "events_query = f\"\"\"\n",
    "    SELECT \n",
    "        event_type,\n",
    "        node_name,\n",
    "        status,\n",
    "        message,\n",
    "        created_at\n",
    "    FROM noetl.event\n",
    "    WHERE execution_id = {EXECUTION_ID}\n",
    "    ORDER BY created_at\n",
    "\"\"\"\n",
    "\n",
    "events_df = query_to_polars(events_query)\n",
    "\n",
    "print(f\"\\nðŸ“‹ Execution Events for {EXECUTION_ID}:\")\n",
    "print(\"=\" * 80)\n",
    "print(events_df)\n",
    "\n",
    "# Check for failures\n",
    "failed_events = events_df.filter(\n",
    "    (pl.col('status') == 'failed') | \n",
    "    (pl.col('event_type').str.contains('failed'))\n",
    ")\n",
    "\n",
    "if failed_events.height > 0:\n",
    "    print(\"\\nâŒ Failed Events:\")\n",
    "    print(failed_events)\n",
    "    \n",
    "    # Show error messages\n",
    "    for row in failed_events.iter_rows(named=True):\n",
    "        print(f\"\\nNode: {row['node_name']}\")\n",
    "        print(f\"Error: {row['message']}\")\n",
    "else:\n",
    "    print(\"\\nâœ“ No failed events found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82325d5b",
   "metadata": {},
   "source": [
    "## 7. Analyze Pagination Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2abe6058",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get saved pagination results\n",
    "pagination_query = f\"\"\"\n",
    "    SELECT \n",
    "        endpoint_name,\n",
    "        endpoint_path,\n",
    "        page_size,\n",
    "        result_count,\n",
    "        iteration_index,\n",
    "        iteration_count,\n",
    "        created_at\n",
    "    FROM noetl_test.pagination_loop_results\n",
    "    WHERE execution_id = {EXECUTION_ID}\n",
    "    ORDER BY iteration_index\n",
    "\"\"\"\n",
    "\n",
    "try:\n",
    "    pagination_df = query_to_polars(pagination_query)\n",
    "    \n",
    "    print(\"\\nðŸ“Š Pagination Results:\")\n",
    "    print(pagination_df)\n",
    "    \n",
    "    print(f\"\\nðŸ“ˆ Summary:\")\n",
    "    print(f\"  Total endpoints: {pagination_df.height}\")\n",
    "    print(f\"  Total items fetched: {pagination_df['result_count'].sum()}\")\n",
    "    print(f\"  Endpoints: {', '.join(pagination_df['endpoint_name'].to_list())}\")\n",
    "except Exception as e:\n",
    "    if \"does not exist\" in str(e):\n",
    "        print(\"âš ï¸  Table 'noetl_test.pagination_loop_results' does not exist\")\n",
    "        print(\"   Run cell 3 (Initialize Test Table) first!\")\n",
    "    else:\n",
    "        raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52d04930",
   "metadata": {},
   "source": [
    "## 8. Validate Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7540045",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"VALIDATION REPORT\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "validation = {'passed': True, 'issues': []}\n",
    "\n",
    "# Check 1: Two endpoints tested\n",
    "if pagination_df.height == 2:\n",
    "    print(\"\\nâœ“ Check 1: Tested 2 endpoints\")\n",
    "else:\n",
    "    print(f\"\\nâœ— Check 1: Expected 2 endpoints, got {pagination_df.height}\")\n",
    "    validation['passed'] = False\n",
    "    validation['issues'].append(f\"Endpoint count mismatch: {pagination_df.height}\")\n",
    "\n",
    "# Check 2: Assessments endpoint\n",
    "assessments = pagination_df.filter(pl.col('endpoint_name') == 'assessments')\n",
    "if assessments.height > 0:\n",
    "    count = assessments['result_count'][0]\n",
    "    if count == 35:\n",
    "        print(f\"âœ“ Check 2: Assessments fetched {count} items\")\n",
    "    else:\n",
    "        print(f\"âœ— Check 2: Expected 35 assessments, got {count}\")\n",
    "        validation['passed'] = False\n",
    "        validation['issues'].append(f\"Assessments count: {count}\")\n",
    "else:\n",
    "    print(\"âœ— Check 2: Assessments endpoint not found\")\n",
    "    validation['passed'] = False\n",
    "    validation['issues'].append(\"Missing assessments endpoint\")\n",
    "\n",
    "# Check 3: Users endpoint\n",
    "users = pagination_df.filter(pl.col('endpoint_name') == 'users')\n",
    "if users.height > 0:\n",
    "    count = users['result_count'][0]\n",
    "    if count == 35:\n",
    "        print(f\"âœ“ Check 3: Users fetched {count} items\")\n",
    "    else:\n",
    "        print(f\"âœ— Check 3: Expected 35 users, got {count}\")\n",
    "        validation['passed'] = False\n",
    "        validation['issues'].append(f\"Users count: {count}\")\n",
    "else:\n",
    "    print(\"âœ— Check 3: Users endpoint not found\")\n",
    "    validation['passed'] = False\n",
    "    validation['issues'].append(\"Missing users endpoint\")\n",
    "\n",
    "# Check 4: Total items\n",
    "total = pagination_df['result_count'].sum()\n",
    "if total == 70:\n",
    "    print(f\"âœ“ Check 4: Total items fetched: {total}\")\n",
    "else:\n",
    "    print(f\"âœ— Check 4: Expected 70 total items, got {total}\")\n",
    "    validation['passed'] = False\n",
    "    validation['issues'].append(f\"Total count: {total}\")\n",
    "\n",
    "# Check 5: Iteration indices\n",
    "indices = pagination_df['iteration_index'].to_list()\n",
    "if indices == [0, 1]:\n",
    "    print(f\"âœ“ Check 5: Iteration indices correct: {indices}\")\n",
    "else:\n",
    "    print(f\"âœ— Check 5: Expected [0, 1], got {indices}\")\n",
    "    validation['passed'] = False\n",
    "    validation['issues'].append(f\"Iteration indices: {indices}\")\n",
    "\n",
    "# Final status\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "if validation['passed']:\n",
    "    print(\"ðŸŽ‰ ALL CHECKS PASSED\")\n",
    "else:\n",
    "    print(\"âŒ VALIDATION FAILED\")\n",
    "    print(\"\\nIssues:\")\n",
    "    for issue in validation['issues']:\n",
    "        print(f\"  - {issue}\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d99cd1c7",
   "metadata": {},
   "source": [
    "## 9. Visualize Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d08af60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bar chart: Items per endpoint\n",
    "if pagination_df.height > 0:\n",
    "    fig = px.bar(\n",
    "        pagination_df.to_pandas(),\n",
    "        x='endpoint_name',\n",
    "        y='result_count',\n",
    "        title=f'Items Fetched per Endpoint - Execution {EXECUTION_ID}',\n",
    "        labels={'endpoint_name': 'Endpoint', 'result_count': 'Items Count'},\n",
    "        text='result_count'\n",
    "    )\n",
    "    fig.update_traces(textposition='outside')\n",
    "    fig.add_hline(y=35, line_dash=\"dash\", annotation_text=\"Expected: 35\")\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1477c2d",
   "metadata": {},
   "source": [
    "## 10. Event Timeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d600294",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get execution events\n",
    "events_query = f\"\"\"\n",
    "    SELECT \n",
    "        created_at,\n",
    "        event_type,\n",
    "        node_name,\n",
    "        status\n",
    "    FROM noetl.event\n",
    "    WHERE execution_id = {EXECUTION_ID}\n",
    "    ORDER BY created_at\n",
    "\"\"\"\n",
    "\n",
    "events_df = query_to_polars(events_query).to_pandas()\n",
    "\n",
    "if len(events_df) > 0:\n",
    "    fig = px.scatter(\n",
    "        events_df,\n",
    "        x='created_at',\n",
    "        y='event_type',\n",
    "        color='status',\n",
    "        hover_data=['node_name'],\n",
    "        title=f'Event Timeline - Execution {EXECUTION_ID}',\n",
    "        labels={'created_at': 'Time', 'event_type': 'Event Type'}\n",
    "    )\n",
    "    fig.update_layout(height=600)\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b726d116",
   "metadata": {},
   "source": [
    "## 11. Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4d3635d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: Clean up test data\n",
    "cleanup = input(\"Clean up test data? (y/n): \")\n",
    "\n",
    "if cleanup.lower() == 'y':\n",
    "    with get_postgres_connection() as conn:\n",
    "        with conn.cursor() as cur:\n",
    "            cur.execute(f\"\"\"\n",
    "                DELETE FROM noetl_test.pagination_loop_results\n",
    "                WHERE execution_id = {EXECUTION_ID}\n",
    "            \"\"\")\n",
    "            conn.commit()\n",
    "    print(f\"âœ“ Cleaned up test data for execution {EXECUTION_ID}\")\n",
    "else:\n",
    "    print(\"Test data preserved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8db743c2",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Summary\n",
    "\n",
    "This notebook validates the `test_loop_with_pagination` playbook:\n",
    "- âœ… Executes pagination loop test\n",
    "- âœ… Monitors real-time progress\n",
    "- âœ… Validates result counts (2 endpoints Ã— 35 items)\n",
    "- âœ… Analyzes saved pagination data\n",
    "- âœ… Visualizes performance metrics\n",
    "\n",
    "**Key Metrics:**\n",
    "- Expected Endpoints: 2 (assessments, users)\n",
    "- Expected Items per Endpoint: 35\n",
    "- Expected Total Items: 70\n",
    "- Expected Database Records: 2"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
