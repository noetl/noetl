apiVersion: noetl.io/v2
kind: Playbook
metadata:
  name: test_pagination_pipeline_v2
  path: tests/pagination/pipeline_v2
  description: |
    Task sequence pagination test demonstrating tool.eval flow control.

    Uses labeled tasks in tool: pipeline with tool.eval: for per-task flow control:
    - _prev threads data between tasks (like Clojure's ->)
    - tool.eval: provides per-task error handling
    - Retry, jump, fail, break, continue control actions
    - outcome object for accessing execution results

workload:
  api_url: "http://paginated-api.test-server.svc.cluster.local:5555"
  db_host: "postgres.postgres.svc.cluster.local"
  db_port: 5432
  db_name: "noetl"
  db_user: "noetl"
  db_password: "noetl"

vars:
  current_page: 1
  page_size: 10
  total_fetched: 0
  all_pages_done: false

workflow:
  - step: start
    desc: Initialize pagination test with tool.eval flow control
    tool:
      kind: python
      code: |
        result = {
          "status": "initialized",
          "message": "Starting pagination test with tool.eval flow control"
        }
    next:
      - step: create_test_table

  - step: create_test_table
    desc: Create test table for storing fetched data
    tool:
      kind: postgres
      credential: test_postgres
      query: |
        DROP TABLE IF EXISTS pagination_test_v2_results;
        CREATE TABLE pagination_test_v2_results (
          id SERIAL PRIMARY KEY,
          assessment_id INTEGER NOT NULL,
          assessment_name VARCHAR(255),
          score INTEGER,
          transformed_at TIMESTAMP DEFAULT NOW(),
          page_number INTEGER,
          batch_id VARCHAR(36)
        );
    next:
      - step: fetch_transform_store

  - step: fetch_transform_store
    desc: |
      Task sequence: fetch page -> transform data -> store to DB
      Demonstrates tool.eval flow control per task
    tool:
      - fetch:
          kind: http
          url: "{{ workload.api_url }}/api/v1/assessments"
          method: GET
          params:
            page: "{{ vars.current_page }}"
            pageSize: "{{ vars.page_size }}"
          eval:
            - expr: "{{ outcome.error.kind == 'rate_limit' }}"
              do: retry
              attempts: 10
              delay: 5.0
            - expr: "{{ outcome.error.retryable }}"
              do: retry
              attempts: 5
              backoff: exponential
              delay: 1.0
            - expr: "{{ outcome.status == 'error' }}"
              do: fail
            - else:
                do: continue

      - transform:
          kind: python
          args:
            http_response: "{{ _prev }}"
            page_num: "{{ vars.current_page }}"
            execution_id: "{{ execution_id }}"
          code: |
            import json
            from datetime import datetime

            response_body = http_response.get('data', {})
            items = response_body.get('data', [])
            paging = response_body.get('paging', {})

            transformed = []
            for item in items:
                transformed.append({
                    'assessment_id': item['id'],
                    'assessment_name': item['name'].upper(),
                    'score': item['score'] * 10,
                    'page_number': page_num,
                    'batch_id': execution_id[:8]
                })

            result = {
                'items': transformed,
                'count': len(transformed),
                'has_more': paging.get('hasMore', False),
                'current_page': paging.get('page', page_num),
                'total': paging.get('total', 0)
            }
          eval:
            - expr: "{{ outcome.status == 'error' }}"
              do: continue
            - else:
                do: continue

      - store:
          kind: python
          args:
            data: "{{ _prev }}"
            db_host: "{{ workload.db_host }}"
            db_port: "{{ workload.db_port }}"
            db_name: "{{ workload.db_name }}"
            db_user: "{{ workload.db_user }}"
            db_password: "{{ workload.db_password }}"
          libs:
            - psycopg2-binary
          code: |
            import psycopg2

            conn = psycopg2.connect(
                host=db_host,
                port=db_port,
                dbname=db_name,
                user=db_user,
                password=db_password
            )

            cursor = conn.cursor()

            inserted = 0
            for item in data['items']:
                cursor.execute('''
                    INSERT INTO pagination_test_v2_results
                    (assessment_id, assessment_name, score, page_number, batch_id)
                    VALUES (%s, %s, %s, %s, %s)
                ''', (
                    item['assessment_id'],
                    item['assessment_name'],
                    item['score'],
                    item['page_number'],
                    item['batch_id']
                ))
                inserted += 1

            conn.commit()
            cursor.close()
            conn.close()

            result = {
                'stored': inserted,
                'has_more': data['has_more'],
                'current_page': data['current_page'],
                'total': data['total']
            }
          eval:
            - expr: "{{ outcome.error.retryable }}"
              do: retry
              attempts: 3
              backoff: linear
              delay: 2.0
            - expr: "{{ outcome.status == 'error' }}"
              do: fail
            - else:
                do: continue
    next:
      - step: check_pagination

  - step: check_pagination
    desc: Check if more pages to fetch
    tool:
      kind: python
      args:
        pipeline_result: "{{ fetch_transform_store }}"
        current_page: "{{ vars.current_page }}"
        total_fetched: "{{ vars.total_fetched }}"
      code: |
        has_more = pipeline_result.get('has_more', False) if isinstance(pipeline_result, dict) else False

        result = {
          "has_more": has_more,
          "current_page": current_page,
          "total_fetched": total_fetched,
          "action": "continue" if has_more else "complete"
        }
    vars:
      current_page: "{{ (vars.current_page | int) + 1 }}"
    next:
      - step: fetch_transform_store
        when: "{{ check_pagination.has_more == true }}"
      - step: validate_results
        when: "{{ check_pagination.has_more != true }}"

  - step: validate_results
    desc: Validate all data was fetched and stored correctly
    tool:
      kind: postgres
      credential: test_postgres
      query: |
        SELECT
          COUNT(*) as total_records,
          COUNT(DISTINCT page_number) as total_pages,
          MIN(assessment_id) as min_id,
          MAX(assessment_id) as max_id,
          AVG(score) as avg_score
        FROM pagination_test_v2_results
    next:
      - step: final_report

  - step: final_report
    desc: Generate final test report
    tool:
      kind: python
      args:
        validation: "{{ validate_results }}"
        pages_processed: "{{ vars.current_page }}"
        total_fetched: "{{ vars.total_fetched }}"
      code: |
        if isinstance(validation, list) and len(validation) > 0:
            stats = validation[0]
        else:
            stats = validation or {}

        total_records = stats.get('total_records', 0)
        total_pages = stats.get('total_pages', 0)
        min_id = stats.get('min_id', 0)
        max_id = stats.get('max_id', 0)
        avg_score = stats.get('avg_score', 0)

        expected_items = 35
        success = total_records == expected_items

        result = {
          "status": "success" if success else "failed",
          "summary": {
            "total_records_stored": total_records,
            "expected_records": expected_items,
            "pages_processed": total_pages,
            "id_range": f"{min_id} - {max_id}",
            "avg_score": round(float(avg_score), 2) if avg_score else 0
          },
          "features_tested": [
            "Labeled tasks in tool: pipeline",
            "tool.eval: per-task flow control",
            "_prev data threading between tasks",
            "outcome object for result/error inspection",
            "Retry with exponential backoff",
            "Control actions: continue, retry, fail"
          ]
        }

        if not success:
            result["error"] = f"Expected {expected_items} records, got {total_records}"
    next:
      - step: end

  - step: end
    desc: Test complete
    tool:
      kind: noop
