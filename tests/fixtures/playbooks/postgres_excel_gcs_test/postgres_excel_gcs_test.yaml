apiVersion: noetl.io/v2
kind: Playbook
metadata:
  name: postgres_excel_gcs_test
  path: tests/postgres_excel_gcs
  description: Test postgres tables -> CSV via DuckDB to GCS -> Excel to GCS

workload:
  pg_auth: pg_local
  gcs_credential: gcs_hmac_local
  gcs_service_account: gcs_service_account
  gcs_bucket: noetl-demo-output
  output_filename: test_export_{{ execution_id }}

workflow:
  - step: start
    desc: Create and populate 3 persistent tables with dummy data
    tool:
      kind: postgres
      auth: "{{ workload.pg_auth }}"
      command: |
        CREATE SCHEMA IF NOT EXISTS test_export;
        DROP TABLE IF EXISTS test_export.employees CASCADE;
        DROP TABLE IF EXISTS test_export.products CASCADE;
        DROP TABLE IF EXISTS test_export.orders CASCADE;
        
        CREATE TABLE test_export.employees (emp_id INT, emp_name VARCHAR(100), department VARCHAR(50));
        INSERT INTO test_export.employees VALUES (1, 'Alice Johnson', 'Engineering'), (2, 'Bob Smith', 'Sales'), (3, 'Carol Williams', 'Marketing');
        
        CREATE TABLE test_export.products (product_id INT, product_name VARCHAR(100), price DECIMAL(10,2));
        INSERT INTO test_export.products VALUES (101, 'Laptop', 999.99), (102, 'Mouse', 29.99), (103, 'Keyboard', 79.99);
        
        CREATE TABLE test_export.orders (order_id INT, customer_name VARCHAR(100), order_date DATE);
        INSERT INTO test_export.orders VALUES (1001, 'John Doe', '2025-01-15'), (1002, 'Jane Smith', '2025-01-16'), (1003, 'Mike Brown', '2025-01-17');
        
        SELECT 'Tables created' as status;
    next:
      - step: export_csv_to_gcs

  - step: export_csv_to_gcs
    desc: Export tables directly to GCS via DuckDB
    tool:
      kind: duckdb
      auth:
        pg_db:
          source: credential
          tool: postgres
          key: "{{ workload.pg_auth }}"
        gcs_secret:
          source: credential
          tool: hmac
          key: "{{ workload.gcs_credential }}"
          scope: gs://{{ workload.gcs_bucket }}
      commands: |
        INSTALL postgres; LOAD postgres;
        INSTALL httpfs; LOAD httpfs;
        ATTACH '' AS pg_db (TYPE postgres, SECRET pg_db);
        
        COPY (SELECT * FROM pg_db.test_export.employees ORDER BY emp_id) TO 'gs://{{ workload.gcs_bucket }}/exports/{{ workload.output_filename }}_employees.csv' (FORMAT CSV, HEADER TRUE);
        COPY (SELECT * FROM pg_db.test_export.products ORDER BY product_id) TO 'gs://{{ workload.gcs_bucket }}/exports/{{ workload.output_filename }}_products.csv' (FORMAT CSV, HEADER TRUE);
        COPY (SELECT * FROM pg_db.test_export.orders ORDER BY order_id) TO 'gs://{{ workload.gcs_bucket }}/exports/{{ workload.output_filename }}_orders.csv' (FORMAT CSV, HEADER TRUE);
        
        SELECT 'CSV files exported to GCS' AS status;
    next:
      - step: create_excel_locally

  - step: create_excel_locally
    desc: Create Excel from postgres tables using DuckDB and upload to GCS
    tool:
      kind: duckdb
      auth:
        pg_db:
          source: credential
          tool: postgres
          key: "{{ workload.pg_auth }}"
      to_excel:
        - query: "SELECT * FROM pg_db.test_export.employees ORDER BY emp_id"
          sheet: "Employees"
        - query: "SELECT * FROM pg_db.test_export.products ORDER BY product_id"
          sheet: "Products"
        - query: "SELECT * FROM pg_db.test_export.orders ORDER BY order_id"
          sheet: "Orders"
      output: "/tmp/test_export_{{ execution_id }}.xlsx"
      commands: |
        SELECT 'Excel file created' AS status;
    case:
      - when: "{{ event.name == 'step.exit' }}"
        then:
          sink:
            tool:
              kind: gcs
              auth:
                source: credential
                tool: service_account
                key: "{{ workload.gcs_service_account }}"
              source_path: "/tmp/test_export_{{ execution_id }}.xlsx"
              destination_uri: "gs://{{ workload.gcs_bucket }}/exports/test_export_{{ execution_id }}.xlsx"
          next:
            - step: cleanup

  - step: cleanup
    desc: Cleanup test tables
    tool:
      kind: postgres
      auth: "{{ workload.pg_auth }}"
      command: |
        DROP TABLE IF EXISTS test_export.employees CASCADE;
        DROP TABLE IF EXISTS test_export.products CASCADE;
        DROP TABLE IF EXISTS test_export.orders CASCADE;
        DROP SCHEMA IF EXISTS test_export CASCADE;
        SELECT 'Cleanup completed' as status;
    next:
      - step: end

  - step: end
    desc: Test completed
    tool:
      kind: python
      code: |
        def main():
            return {'status': 'completed', 'message': 'CSV and Excel uploaded to GCS', 'csv_count': 3, 'excel_count': 1}
