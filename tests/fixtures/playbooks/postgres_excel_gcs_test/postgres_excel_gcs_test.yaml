apiVersion: noetl.io/v2
kind: Playbook
metadata:
  name: postgres_excel_gcs_test
  path: tests/postgres_excel_gcs
  description: UPDATED VERSION Test postgres temp tables -> Excel multi-sheet -> GCS upload

workload:
  pg_auth: pg_local
  gcs_auth: gcs_service_account
  gcs_bucket: noetl-demo-output
  output_filename: test_export

keychain:
  - name: gcs_token
    kind: service_account
    provider: gcp
    scope: global
    auth: "{{ workload.gcs_auth }}"

workflow:
  - step: start
    desc: Create and populate 3 temp tables with dummy data
    tool:
      kind: postgres
      auth: "{{ workload.pg_auth }}"
      command: |
        -- Create temp table 1: employees
        CREATE TEMP TABLE employees (
          emp_id INT,
          emp_name VARCHAR(100),
          department VARCHAR(50)
        );
        
        INSERT INTO employees VALUES 
          (1, 'Alice Johnson', 'Engineering'),
          (2, 'Bob Smith', 'Sales'),
          (3, 'Carol Williams', 'Marketing');
        
        -- Create temp table 2: products
        CREATE TEMP TABLE products (
          product_id INT,
          product_name VARCHAR(100),
          price DECIMAL(10,2)
        );
        
        INSERT INTO products VALUES 
          (101, 'Laptop', 999.99),
          (102, 'Mouse', 29.99),
          (103, 'Keyboard', 79.99);
        
        -- Create temp table 3: orders
        CREATE TEMP TABLE orders (
          order_id INT,
          customer_name VARCHAR(100),
          order_date DATE
        );
        
        INSERT INTO orders VALUES 
          (1001, 'John Doe', '2025-01-15'),
          (1002, 'Jane Smith', '2025-01-16'),
          (1003, 'Mike Brown', '2025-01-17');
        
        SELECT 'Tables created successfully' as status;
    next:
      - step: export_to_csv_gcs

  - step: export_to_csv_gcs
    desc: Export temp tables to CSV files in GCS using DuckDB
    tool:
      kind: duckdb
      auth:
        pg_db:
          tool: postgres
          credential: "{{ workload.pg_auth }}"
      command: |
        -- Load extensions
        INSTALL postgres;
        LOAD postgres;
        INSTALL httpfs;
        LOAD httpfs;
        
        -- Attach postgres database
        ATTACH '' AS pg_db (TYPE postgres, SECRET pg_db);
        
        -- Set GCS credentials for httpfs
        SET secret (
          TYPE GCS,
          KEY_ID '{{ keychain.gcs_token }}'
        );
        
        -- Export each table to CSV in GCS
        COPY (SELECT * FROM pg_db.employees ORDER BY emp_id) 
        TO 'gs://{{ workload.gcs_bucket }}/temp/{{ workload.output_filename }}_employees.csv' 
        (HEADER, DELIMITER ',');
        
        COPY (SELECT * FROM pg_db.products ORDER BY product_id) 
        TO 'gs://{{ workload.gcs_bucket }}/temp/{{ workload.output_filename }}_products.csv' 
        (HEADER, DELIMITER ',');
        
        COPY (SELECT * FROM pg_db.orders ORDER BY order_id) 
        TO 'gs://{{ workload.gcs_bucket }}/temp/{{ workload.output_filename }}_orders.csv' 
        (HEADER, DELIMITER ',');
        
        SELECT 'Exported 3 CSV files to GCS' as status;
    next:
      - step: create_excel_from_gcs_csv

  - step: create_excel_from_gcs_csv
    desc: Download CSVs from GCS and create multi-sheet Excel
    tool:
      kind: python
      code: |
        def main(gcs_bucket, output_filename):
            """
            Download CSV files from GCS, create multi-sheet Excel, upload result.
            Uses GCS client for downloads/uploads and xlsxwriter for Excel creation.
            """
            from google.cloud import storage
            import xlsxwriter
            import csv
            import os
            
            # Initialize GCS client
            storage_client = storage.Client()
            bucket = storage_client.bucket(gcs_bucket)
            
            # Define CSV files and sheet names
            files = [
                (f'temp/{output_filename}_employees.csv', 'Employees'),
                (f'temp/{output_filename}_products.csv', 'Products'),
                (f'temp/{output_filename}_orders.csv', 'Orders')
            ]
            
            output_path = f'/tmp/{output_filename}.xlsx'
            workbook = xlsxwriter.Workbook(output_path)
            
            # Create header format
            header_format = workbook.add_format({
                'bold': True,
                'bg_color': '#D9E1F2',
                'border': 1,
                'align': 'center'
            })
            
            # Process each CSV file
            for gcs_path, sheet_name in files:
                # Download CSV from GCS to temp file
                local_csv = f'/tmp/{os.path.basename(gcs_path)}'
                blob = bucket.blob(gcs_path)
                blob.download_to_filename(local_csv)
                
                # Read CSV and write to Excel sheet
                worksheet = workbook.add_worksheet(sheet_name)
                
                with open(local_csv, 'r') as f:
                    reader = csv.reader(f)
                    for row_idx, row in enumerate(reader):
                        for col_idx, value in enumerate(row):
                            if row_idx == 0:
                                # Header row
                                worksheet.write(row_idx, col_idx, value, header_format)
                                worksheet.set_column(col_idx, col_idx, 20)
                            else:
                                # Data rows
                                worksheet.write(row_idx, col_idx, value)
                
                # Clean up local CSV
                os.remove(local_csv)
                
                # Clean up GCS temp CSV
                blob.delete()
            
            workbook.close()
            
            # Upload Excel to GCS
            excel_blob = bucket.blob(f'exports/{output_filename}.xlsx')
            excel_blob.upload_from_filename(output_path)
            
            file_size = os.path.getsize(output_path)
            
            # Clean up local Excel
            os.remove(output_path)
            
            return {
                'status': 'success',
                'gcs_path': f'gs://{gcs_bucket}/exports/{output_filename}.xlsx',
                'sheets_created': len(files),
                'file_size_bytes': file_size
            }
    args:
      gcs_bucket: "{{ workload.gcs_bucket }}"
      output_filename: "{{ workload.output_filename }}"
    next:
      - step: end

  - step: end
    desc: Test completed
    tool:
      kind: python
      code: |
        def main():
            return {
                'status': 'completed',
                'message': 'Successfully created Excel from postgres tables and uploaded to GCS'
            }
