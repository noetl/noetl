# Test Fixtures: Playbooks

This directory hosts the fast integration playbooks used by our automated tests. The YAML files live in `tests/fixtures/playbooks/`, but every fixture keeps its original `metadata.path` so it still registers in NoETL under the `examples/test/...` namespace. Use the table below to map catalog paths to on-disk files.

## Fixture inventory

| metadata.path | fixture file | notes |
| ------------- | ------------ | ----- |
| tests/simple_test | simple_test.yaml | Minimal start/end smoke check.
| tests/loop_http_test | loop_http_test.yaml | Async HTTP iterator that aggregates city metrics.
| tests/loop_http_test_sequential | loop_http_test_sequential.yaml | Sequential variant of the HTTP loop.
| tests/postgres_save_simple | postgres_save_simple.yaml | Writes a greeting row into `public.postgres_save_demo`.
| tests/postgres_save_simple2 | postgres_save_simple2.yaml | Alternate save flow that reuses the same table.
| tests/test_postgres_storage | test_postgres_storage.yaml | Populates `weather_alert_summary` with mock alert data.
| tests/http_duckdb_postgres | http_duckdb_postgres.yaml | HTTP fetch -> DuckDB transformation -> Postgres + GCS export.
| tests/city_http_to_pg | city_http_to_pg.yaml | Simple weather ingestion that lands rows in Postgres.
| tests/loop_controller_http_save | loop_controller_http_save.yaml | Loop controller showcasing per-iteration HTTP saves.
| tests/loop_controller_numbers | loop_controller_numbers.yaml | Synthetic numeric loop used by iterator unit tests.
| tests/unified_auth_example | unified_auth_example.yaml | Demonstrates unified auth payload mapping.
| tests/unified_auth_demo | auth_credentials_secret_example.yaml | Legacy unified auth example kept for backward compatibility.

Supporting credential payloads now live in `tests/fixtures/credentials/` alongside a template you can copy for new secrets.

## Prerequisites

- Python environment with NoETL installed (dev):
  - `make create-venv && make install-dev`
- Running Postgres instance (defaults below match `docker-compose` and local dev):
  - host: `localhost`
  - port: `30543`
  - user: `demo`
  - password: `demo`
  - database: `demo_noetl`
- Local `.env` populated (the repo defaults align with the Postgres settings above).

## Start server and workers

- One command: `make noetl-start`
- Manual sequence:
  - `make start-server`
  - `make start-workers`

Check status with `make server-status`.

## Register fixtures and credentials

- Prefer the helper targets: `make register-test-playbooks HOST=localhost PORT=8082` and `make register-test-credentials HOST=localhost PORT=8082`

- Or, one command: 
- `make postgres-reset-schema && make noetl-restart && make register-test-credentials HOST=localhost PORT=8082 && make register-test-playbooks HOST=localhost PORT=8082`

The CLI expects actual file paths when registering. Point it at the fixtures directory (the metadata paths remain unchanged inside the files):

```bash
for pb in tests/fixtures/playbooks/*.yaml; do \
  noetl register "$pb" --host localhost --port 8082; \
done
```

Register credential payloads required by the fixtures:

```bash
for cred in tests/fixtures/credentials/*.json; do \
  noetl credential register "$cred" --host localhost --port 8082; \
done
```

> Tip: replace `noetl` with `.venv/bin/noetl` if you rely on the project virtualenv.

## Running the fixtures

Use `make noetl-execute PLAYBOOK=<Playbook Path>` with the fixture metadata path (unchanged `tests/...` identifiers):

- Basic smoke test: `make noetl-execute PLAYBOOK=tests/simple_test`
- HTTP loop variants: run both `make noetl-execute PLAYBOOK=tests/loop_http_test` and `make noetl-execute PLAYBOOK=tests/loop_http_test_sequential`
- Loop controller demos: `make noetl-execute PLAYBOOK=tests/loop_controller_http_save` and `make noetl-execute PLAYBOOK=tests/loop_controller_numbers`
- Postgres saves: `make noetl-execute PLAYBOOK=tests/postgres_save_simple`, `make noetl-execute PLAYBOOK=tests/postgres_save_simple2`, and `make noetl-execute PLAYBOOK=tests/test_postgres_storage`
- Multi-stage pipeline: `make noetl-execute PLAYBOOK=tests/http_duckdb_postgres`
- Lightweight ingestion: `make noetl-execute PLAYBOOK=tests/city_http_to_pg`
- Unified auth showcase: `make noetl-execute PLAYBOOK=tests/unified_auth_example` (and legacy `tests/unified_auth_demo`)

Each execution writes an event log to `logs/event.json`. The Postgres scenarios also write rows into the tables noted in the inventory above.

## Verifying results

- Postgres saves: query `public.postgres_save_demo` to confirm new rows (`SELECT id, message, created_at FROM public.postgres_save_demo ORDER BY created_at DESC LIMIT 5;`).
- Storage demo: inspect `weather_alert_summary` for the alert aggregates generated by `tests/test_postgres_storage`.
- HTTP pipelines: review `logs/event_log.json` for aggregate payloads or exported URIs. The DuckDB fixture emits COPY commands targeting `gs://...` URIs when the unified credentials are present.

## Exporting logs again later

If you need to re-export execution artifacts, use:

- `make export-event-log ID=<execution_id>`
- `make export-queue ID=<execution_id>`

Outputs land in `logs/event.json` and `logs/queue.json` respectively.

## Troubleshooting

- Credential or connection errors:
  - Ensure you registered every JSON credential from `tests/fixtures/credentials/` and that the server is running.
  - Double-check Postgres settings in `.env`.
- HTTP flakiness:
  - Remote weather APIs occasionally error; rerun the fixture or adjust city lists as needed.
- No executions appear:
  - Confirm workers are running with `ps aux | grep 'noetl worker' | grep -v grep`.
  - Inspect the worker and server logs in the `logs/` directory.

## Clean up

- Stop workers and server: `make noetl-stop`
- Optional database cleanup:
  - `DROP TABLE public.postgres_save_demo;`
  - `DROP TABLE weather_alert_summary;`

The fixtures remain in `tests/fixtures/playbooks/` so future migrations can reuse the same registration commands without touching metadata paths.
