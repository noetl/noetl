apiVersion: noetl.io/v1
kind: Playbook

metadata:
  name: http_duckdb_postgres
  path: tests/fixtures/playbooks/http_duckdb_postgres   # catalog path; do not change in tests

workload:
  message: HTTP -> DuckDB -> Postgres pipeline
  cities:
  - name: London
    lat: 51.51
    lon: -0.13
  - name: Paris
    lat: 48.85
    lon: 2.35
  - name: Berlin
    lat: 52.52
    lon: 13.41
  base_url: https://api.open-meteo.com/v1
  gcs_bucket: noetl-demo-19700101
workflow:
- step: start
  desc: Start pipeline
  next:
  - step: ensure_pg_table
- step: ensure_pg_table
  desc: Ensure raw HTTP results table exists in Postgres
  type: postgres
  auth: pg_local
  command: |
    CREATE TABLE IF NOT EXISTS public.weather_http_raw (
      id TEXT PRIMARY KEY,
      execution_id TEXT,
      iter_index INTEGER,
      city TEXT,
      url TEXT,
      elapsed DOUBLE PRECISION,
      payload TEXT,
      created_at TIMESTAMPTZ DEFAULT now()
    );
  next:
  - step: http_loop
    data:
      cities: '{{ workload.cities }}'
- step: http_loop
  desc: Fetch hourly temperatures for each city and save raw rows
  type: iterator
  collection: '{{ workload.cities }}'
  element: city
  mode: async
  task:
    data:
      latitude: '{{ city.lat }}'
      longitude: '{{ city.lon }}'
      hourly: temperature_2m
      forecast_days: 1
    type: http
    endpoint: '{{ workload.base_url }}/forecast'
    headers:
      User-Agent: NoETL City HTTP -> PG Demo/1.0
    assert:
      expects:
        - latitude
        - longitude
        - hourly
        - forecast_days
      returns:
        - data.url
        - data.elapsed
        - data.payload
    save:
      data:
        id: '{{ execution_id }}:{{ city.name }}:{{ http_loop.result_index }}'
        execution_id: '{{ execution_id }}'
        iter_index: '{{ http_loop.result_index }}'
        city: '{{ city.name }}'
        url: "{{ this.data.url if this is defined and this.data is defined else '' }}"
        elapsed: "{{ (this.data.elapsed | default(0)) if this is defined and this.data is defined else 0 }}"
        payload: "{{ (this.data | tojson) if this is defined and this.data is defined else '' }}"
      storage: postgres
      auth: pg_local
      table: public.weather_http_raw
      mode: upsert
      key: id
  next:
  - step: aggregate_with_duckdb
- step: aggregate_with_duckdb
  data:
    require_cloud_output: true
  desc: Read Postgres rows in DuckDB, aggregate, write to GCS using unified auth dictionary
  type: duckdb
  auth:
    pg_db:
      source: credential
      type: postgres
      key: pg_local
    gcs_secret:
      source: credential
      type: hmac
      key: gcs_hmac_local
      scope: gs://{{ workload.gcs_bucket }}
  assert:
    expects:
      - auth.pg_db
      - auth.gcs_secret
      - data.require_cloud_output
    returns:
      - weather_flat
      - weather_agg
  commands: |
    -- Load needed extensions
    INSTALL postgres; LOAD postgres;
    INSTALL httpfs;  LOAD httpfs;

    -- Attach using the postgres credential via alias 'pg_db'
    ATTACH '' AS pg_db (TYPE postgres, SECRET pg_db);

    -- GCS secrets are auto-created from auth mapping; no SQL needed here.

    -- Flattened view from Postgres-attached table
    CREATE OR REPLACE TABLE weather_flat AS
    SELECT id, city, url AS source_url, elapsed AS elapsed_sec, payload
    FROM pg_db.public.weather_http_raw
    WHERE execution_id = '{{ execution_id }}';

    -- Aggregate by city (simple count)
    CREATE OR REPLACE TABLE weather_agg AS
    SELECT city, COUNT(*) AS rows_per_city
    FROM weather_flat
    GROUP BY city;

    -- Write results using the GCS credential
    COPY weather_flat TO 'gs://{{ workload.gcs_bucket }}/weather/flat_{{ execution_id }}.parquet' (FORMAT PARQUET);
    COPY weather_agg  TO 'gs://{{ workload.gcs_bucket }}/weather/agg_{{ execution_id }}.parquet'  (FORMAT PARQUET);
  next:
  - step: ensure_metrics_table
- step: ensure_metrics_table
  desc: Ensure metrics table exists in Postgres
  type: postgres
  auth: pg_local
  command: |
    CREATE TABLE IF NOT EXISTS public.weather_pipeline_metrics (
      execution_id TEXT PRIMARY KEY,
      pg_rows_saved INTEGER,
      gcs_flat_uri TEXT,
      gcs_agg_uri  TEXT,
      created_at   TIMESTAMPTZ DEFAULT now()
    );
  next:
  - step: end
- step: end
  desc: Finish
  type: postgres
  auth: pg_local
  command: |
    INSERT INTO public.weather_pipeline_metrics (execution_id, pg_rows_saved, gcs_flat_uri, gcs_agg_uri)
    VALUES (
      '{{ execution_id }}',
      (SELECT COUNT(*) FROM public.weather_http_raw WHERE execution_id = '{{ execution_id }}'),
      'gs://{{ workload.gcs_bucket }}/weather/flat_{{ execution_id }}.parquet',
      'gs://{{ workload.gcs_bucket }}/weather/agg_{{ execution_id }}.parquet'
    )
    ON CONFLICT (execution_id) DO UPDATE SET
      pg_rows_saved = EXCLUDED.pg_rows_saved,
      gcs_flat_uri = EXCLUDED.gcs_flat_uri,
      gcs_agg_uri = EXCLUDED.gcs_agg_uri
