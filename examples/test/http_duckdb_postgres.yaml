apiVersion: noetl.io/v1
kind: Playbook
name: http_duckdb_postgres
path: examples/test/http_duckdb_postgres

workload:
  message: "HTTP -> DuckDB -> Postgres pipeline"
  cities:
    - name: "London"
      lat: 51.51
      lon: -0.13
    - name: "Paris"
      lat: 48.85
      lon: 2.35
    - name: "Berlin"
      lat: 52.52
      lon: 13.41
  base_url: "https://api.open-meteo.com/v1"
  gcs_bucket: "noetl-demo-19700101"   # set this to an actual bucket; requires HMAC key_id/secret_key

workflow:
  - step: start
    desc: "Start pipeline"
    next:
      - step: ensure_pg_table

  - step: ensure_pg_table
    desc: "Ensure raw HTTP results table exists in Postgres"
    type: postgres
    credential: pg_local
    command: |
      CREATE TABLE IF NOT EXISTS public.weather_http_raw (
        id TEXT PRIMARY KEY,
        execution_id TEXT,
        iter_index INTEGER,
        city TEXT,
        url TEXT,
        elapsed DOUBLE PRECISION,
        payload TEXT,
        created_at TIMESTAMPTZ DEFAULT now()
      );
    next:
      - step: http_loop
        input:
          cities: "{{ workload.cities }}"

  - step: http_loop
    desc: "Fetch hourly temperatures for each city via child playbook"
    type: playbook
    path: examples/test/city_http_to_pg
    loop:
      in: "{{ cities }}"
      iterator: city_item
      mode: async
    with:
      city: "{{ city_item }}"
      base_url: "{{ workload.base_url }}"
      parent_execution_id: "{{ execution_id }}"
      index: "{{ _loop.current_index }}"
    next:
      - step: get_pg_credential

  - step: get_pg_credential
    desc: "Fetch Postgres credential from NoETL server"
    type: http
    method: GET
    endpoint: "{{ env.NOETL_SERVER_URL | default('http://localhost:8082') }}/api/credentials/pg_local?include_data=true"
    next:
      - step: get_gcs_credential

  - step: get_gcs_credential
    desc: "Fetch GCS HMAC credential from NoETL server"
    type: http
    method: GET
    endpoint: "{{ env.NOETL_SERVER_URL | default('http://localhost:8082') }}/api/credentials/gcs_hmac_local?include_data=true"
    next:
      - step: aggregate_with_duckdb

  - step: aggregate_with_duckdb
    desc: "Read Postgres rows in DuckDB, aggregate, write to GCS with explicit DuckDB secrets"
    type: duckdb
    with:
      # Flatten server HTTP responses to the decrypted credential payloads
      # HTTP action result schema: result.data => { status_code, headers, url, elapsed, data: <payload> }
      # We want the inner decrypted payload object under .data
      pg: "{{ get_pg_credential.data.data }}"
      gcs: "{{ get_gcs_credential.data.data }}"
    commands: |
      -- Load required extensions
      INSTALL httpfs;  LOAD httpfs;
      INSTALL postgres; LOAD postgres;

      -- Explicit Postgres attach using credential fields
      ATTACH 'dbname={{ pg.db_name }} user={{ pg.db_user }} password={{ pg.db_password }} host={{ pg.db_host }} port={{ pg.db_port }}' AS postgres_db (TYPE postgres);

      -- Explicit DuckDB secret for GCS with scoped access to the bucket
      CREATE OR REPLACE SECRET noetl_gcs_secret (
        TYPE gcs,
        KEY_ID '{{ gcs.key_id }}',
        SECRET '{{ gcs.secret_key }}',
        SCOPE 'gs://{{ workload.gcs_bucket }}'
      );

      -- Flattened view from Postgres-attached table
      CREATE OR REPLACE TABLE weather_flat AS
      SELECT id, city, url AS source_url, elapsed AS elapsed_sec, payload
      FROM postgres_db.public.weather_http_raw
      WHERE execution_id = '{{ execution_id }}';

      -- Aggregate by city (simple count)
      CREATE OR REPLACE TABLE weather_agg AS
      SELECT city, COUNT(*) AS rows_per_city
      FROM weather_flat
      GROUP BY city;

      -- Write to GCS as Parquet via DuckDB secrets
      COPY weather_flat TO 'gs://{{ workload.gcs_bucket }}/weather/flat_{{ execution_id }}.parquet' (FORMAT PARQUET);
      COPY weather_agg  TO 'gs://{{ workload.gcs_bucket }}/weather/agg_{{ execution_id }}.parquet'  (FORMAT PARQUET);
    next:
      - step: ensure_metrics_table

  - step: ensure_metrics_table
    desc: "Ensure metrics table exists in Postgres"
    type: postgres
    credential: pg_local
    command: |
      CREATE TABLE IF NOT EXISTS public.weather_pipeline_metrics (
        execution_id TEXT PRIMARY KEY,
        pg_rows_saved INTEGER,
        gcs_flat_uri TEXT,
        gcs_agg_uri  TEXT,
        created_at   TIMESTAMPTZ DEFAULT now()
      );
    next:
      - step: end

  - step: end
    desc: "Finish"
    save:
      storage:
        kind: postgres
        credential: pg_local
      table: public.weather_pipeline_metrics
      mode: upsert
      key: execution_id
      data:
        execution_id: "{{ execution_id }}"
        pg_rows_saved: "{{ http_loop.count }}"
        gcs_flat_uri: "gs://{{ workload.gcs_bucket }}/weather/flat_{{ execution_id }}.parquet"
        gcs_agg_uri:  "gs://{{ workload.gcs_bucket }}/weather/agg_{{ execution_id }}.parquet"
