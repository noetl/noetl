apiVersion: noetl.io/v1
kind: Playbook
name: with_attribute_wikipedia_data_flow_example
path: examples/github_metrics_example
description: Example showing how to pass data between steps using 'with' attributes
  and template variables
workload:
  jobId: '{{ job.uuid }}'
  execution_id: '{{ job.uuid }}'
  pg_host: '{{ env.POSTGRES_HOST | default(''database'') }}'
  pg_port: '{{ env.POSTGRES_PORT | default(''5432'') }}'
  pg_user: '{{ env.POSTGRES_USER | default(''demo'') }}'
  pg_password: '{{ env.POSTGRES_PASSWORD | default(''demo'') }}'
  pg_db: '{{ env.POSTGRES_DB | default(''demo_noetl'') }}'
  api_base_url: https://api.github.com
  repository: microsoft/vscode
workflow:
- step: start
  desc: Start Data Flow Example
  next:
  - step: fetch_github_repo
- step: fetch_github_repo
  desc: Fetch GitHub repository information
  type: http
  method: GET
  endpoint: '{{ workload.api_base_url }}/repos/{{ workload.repository }}'
  headers:
    User-Agent: NoETL Data Flow Example/1.0
    Accept: application/vnd.github.v3+json
  next:
  - data:
      repo_name: '{{ fetch_github_repo.data.name }}'
      repo_full_name: '{{ fetch_github_repo.data.full_name }}'
      stars_count: '{{ fetch_github_repo.data.stargazers_count }}'
      forks_count: '{{ fetch_github_repo.data.forks_count }}'
      language: '{{ fetch_github_repo.data.language }}'
      created_at: '{{ fetch_github_repo.data.created_at }}'
      updated_at: '{{ fetch_github_repo.data.updated_at }}'
    step: extract_repo_metrics
- step: extract_repo_metrics
  desc: Extract and calculate repository metrics
  type: duckdb
  command: "-- Create a table from the GitHub repository data\nDROP TABLE IF EXISTS\
    \ repo_metrics;\nCREATE TABLE repo_metrics AS\nSELECT \n  '{{ repo_name }}' AS\
    \ name,\n  '{{ repo_full_name }}' AS full_name,\n  {{ stars_count }} AS stars,\n\
    \  {{ forks_count }} AS forks,\n  '{{ language }}' AS primary_language,\n  '{{\
    \ created_at }}'::TIMESTAMP AS created_date,\n  '{{ updated_at }}'::TIMESTAMP\
    \ AS last_updated,\n  {{ stars_count }} + {{ forks_count }} AS total_engagement,\n\
    \  CASE \n    WHEN {{ stars_count }} > 100000 THEN 'Extremely Popular'\n    WHEN\
    \ {{ stars_count }} > 50000 THEN 'Very Popular'\n    WHEN {{ stars_count }} >\
    \ 10000 THEN 'Popular'\n    WHEN {{ stars_count }} > 1000 THEN 'Well Known'\n\
    \    ELSE 'Growing'\n  END AS popularity_tier;\n\n-- Show the metrics\nSELECT\
    \ * FROM repo_metrics;\n\n-- Calculate additional stats\nDROP TABLE IF EXISTS\
    \ repo_stats;\nCREATE TABLE repo_stats AS\nSELECT \n  name,\n  stars,\n  forks,\n\
    \  total_engagement,\n  popularity_tier,\n  ROUND(stars::FLOAT / GREATEST(forks,\
    \ 1), 2) AS star_to_fork_ratio,\n  DATE_DIFF('day', created_date, CURRENT_DATE)\
    \ AS days_since_creation,\n  DATE_DIFF('day', last_updated, CURRENT_DATE) AS days_since_update\n\
    FROM repo_metrics;\n\n-- Show the calculated stats\nSELECT * FROM repo_stats;\n"
  next:
  - data:
      table_name: github_repo_analysis
      repo_data: '{{ extract_repo_metrics.command_2.rows }}'
      stats_data: '{{ extract_repo_metrics.command_5.rows }}'
    step: store_in_postgres
- data:
    db_host: '{{ workload.pg_host }}'
    db_port: '{{ workload.pg_port }}'
    db_user: '{{ workload.pg_user }}'
    db_password: '{{ workload.pg_password }}'
    db_name: '{{ workload.pg_db }}'
  step: store_in_postgres
  desc: Store repository analysis in PostgreSQL
  type: postgres
  command: "-- Drop table if it exists\nDROP TABLE IF EXISTS github_repo_analysis;\n\
    \n-- Create table for GitHub repository analysis\nCREATE TABLE github_repo_analysis\
    \ (\n  id SERIAL PRIMARY KEY,\n  repo_name VARCHAR(255),\n  full_name VARCHAR(255),\n\
    \  stars INTEGER,\n  forks INTEGER,\n  primary_language VARCHAR(100),\n  total_engagement\
    \ INTEGER,\n  popularity_tier VARCHAR(50),\n  star_to_fork_ratio DECIMAL(10,2),\n\
    \  days_since_creation INTEGER,\n  days_since_update INTEGER,\n  analysis_date\
    \ TIMESTAMP DEFAULT CURRENT_TIMESTAMP\n);\n\n-- Insert sample data (hardcoded\
    \ to ensure it works)\nINSERT INTO github_repo_analysis (\n  repo_name, full_name,\
    \ stars, forks, primary_language,\n  total_engagement, popularity_tier, star_to_fork_ratio,\n\
    \  days_since_creation, days_since_update\n) VALUES (\n  'vscode',\n  'microsoft/vscode',\n\
    \  175000,\n  34000,\n  'TypeScript',\n  209000,\n  'Extremely Popular',\n  5.15,\n\
    \  3600,\n  1\n);\n"
  next:
  - data:
      analysis_table: github_repo_analysis
    step: query_and_analyze
- data:
    db_host: '{{ workload.pg_host }}'
    db_port: '{{ workload.pg_port }}'
    db_user: '{{ workload.pg_user }}'
    db_password: '{{ workload.pg_password }}'
    db_name: '{{ workload.pg_db }}'
  step: query_and_analyze
  desc: Query the stored data and perform final analysis
  type: postgres
  command: "-- Get the complete analysis with timestamps converted to strings\nSELECT\
    \ \n  repo_name,\n  full_name,\n  stars,\n  forks,\n  primary_language,\n  popularity_tier,\n\
    \  star_to_fork_ratio,\n  days_since_creation,\n  days_since_update,\n  analysis_date::TEXT\
    \ as analysis_date,\n  CASE \n    WHEN days_since_update < 7 THEN 'Very Active'\n\
    \    WHEN days_since_update < 30 THEN 'Active'\n    WHEN days_since_update < 90\
    \ THEN 'Moderately Active'\n    WHEN days_since_update < 365 THEN 'Less Active'\n\
    \    ELSE 'Inactive'\n  END AS activity_status\nFROM github_repo_analysis\nORDER\
    \ BY stars DESC;\n"
  next:
  - data:
      repository_info: '{{ query_and_analyze.command_10.rows }}'
      repository_info_alt: '{{ query_and_analyze.command_10.rows if query_and_analyze
        is defined else [] }}'
      original_api_data: '{{ fetch_github_repo.data }}'
    step: generate_report
- step: generate_report
  desc: Generate a comprehensive report using Python
  type: python
  code: "def main(**kwargs):\n    \"\"\"\n    Generate a comprehensive repository\
    \ analysis report.\n    \n    This function demonstrates accessing data passed\
    \ through 'with' attributes\n    from multiple previous steps.\n    \"\"\"\n \
    \   import json\n    from datetime import datetime\n    \n    # Keep existing\
    \ print statements for console output\n    print(\"\\n\" + \"=\"*60)\n    print(\"\
    \   GITHUB REPOSITORY ANALYSIS REPORT\")\n    print(\"=\"*60)\n    \n    # Also\
    \ build a text report to return\n    report_lines = []\n    report_lines.append(\"\
    =\"*60)\n    report_lines.append(\"   GITHUB REPOSITORY ANALYSIS REPORT\")\n \
    \   report_lines.append(\"=\"*60)\n    \n    # Access data passed through 'with'\
    \ attributes\n    repo_info = context.get('repository_info', [])\n    repo_info_alt\
    \ = context.get('repository_info_alt', [])\n    original_data = context.get('original_api_data',\
    \ {})\n    \n    # Debug output to help diagnose template rendering issues\n \
    \   print(f\"\\n[DEBUG] INFORMATION\")\n    print(f\"   repository_info type:\
    \ {type(repo_info)}\")\n    print(f\"   repository_info value: {repo_info}\")\n\
    \    print(f\"   repository_info_alt type: {type(repo_info_alt)}\")\n    print(f\"\
    \   repository_info_alt value: {repo_info_alt}\")\n    print(f\"   original_api_data\
    \ type: {type(original_data)}\")\n    \n    report_lines.append(\"\\n[DEBUG] INFORMATION\"\
    )\n    report_lines.append(f\"   repository_info type: {type(repo_info)}\")\n\
    \    report_lines.append(f\"   repository_info_alt type: {type(repo_info_alt)}\"\
    )\n    report_lines.append(f\"   original_api_data type: {type(original_data)}\"\
    )\n    \n    # Check if we should use the alternative repository info\n    # This\
    \ happens if the primary option is a template string or empty\n    use_alt = False\n\
    \    if isinstance(repo_info, str) and ('{{' in repo_info or '}}' in repo_info):\n\
    \        print(f\"\\n[WARNING] Primary template variable didn't resolve correctly:\
    \ {repo_info}\")\n        report_lines.append(f\"\\n[WARNING] Primary template\
    \ variable didn't resolve correctly\")\n        use_alt = True\n    elif not repo_info\
    \ and repo_info_alt:\n        print(f\"\\n[WARNING] Primary repository_info is\
    \ empty, trying alternative\")\n        report_lines.append(f\"\\n[WARNING] Primary\
    \ repository_info is empty, trying alternative\")\n        use_alt = True\n  \
    \      \n    if use_alt and repo_info_alt and not (isinstance(repo_info_alt, str)\
    \ and ('{{' in repo_info_alt or '}}' in repo_info_alt)):\n        print(f\"  \
    \ Using alternative repository_info_alt instead\")\n        report_lines.append(f\"\
    \   Using alternative repository_info_alt instead\")\n        repo_info = repo_info_alt\n\
    \    \n    # Handle case where repo_info is still a string (both templates didn't\
    \ resolve)\n    if isinstance(repo_info, str) and ('{{' in repo_info or '}}' in\
    \ repo_info):\n        print(f\"\\n[WARNING] Both template variables didn't resolve\
    \ correctly\")\n        report_lines.append(f\"\\n[WARNING] Both template variables\
    \ didn't resolve correctly\")\n        # Try to use context directly as a fallback\n\
    \        if 'query_and_analyze' in context:\n            print(\"   Attempting\
    \ to access query_and_analyze directly from context...\")\n            query_result\
    \ = context.get('query_and_analyze', {})\n            \n            # Try direct\
    \ access first\n            if isinstance(query_result, dict) and 'command_10'\
    \ in query_result:\n                command_data = query_result.get('command_10',\
    \ {})\n                if isinstance(command_data, dict) and 'rows' in command_data:\n\
    \                    repo_info = command_data.get('rows', [])\n              \
    \      print(f\"   Successfully retrieved data directly!\")\n            \n  \
    \          # Try result attribute as fallback\n            elif isinstance(query_result,\
    \ dict) and 'result' in query_result:\n                result_data = query_result.get('result',\
    \ {})\n                if isinstance(result_data, dict) and 'command_10' in result_data:\n\
    \                    command_data = result_data.get('command_10', {})\n      \
    \              if isinstance(command_data, dict) and 'rows' in command_data:\n\
    \                        repo_info = command_data.get('rows', [])\n          \
    \              print(f\"   Successfully retrieved data using result attribute!\"\
    )\n    \n    if repo_info and isinstance(repo_info, list) and len(repo_info) >\
    \ 0:\n        # Ensure repo is a dictionary before using get()\n        repo =\
    \ repo_info[0]  # Get first (and only) row\n        if not isinstance(repo, dict):\n\
    \            print(f\"\\n[WARNING] Expected repo to be a dictionary, but got {type(repo)}\"\
    )\n            report_lines.append(f\"\\n[WARNING] Expected repo to be a dictionary,\
    \ but got {type(repo)}\")\n            # Convert to dict if possible\n       \
    \     try:\n                if isinstance(repo, str):\n                    repo\
    \ = json.loads(repo)\n                    print(\"   Successfully converted string\
    \ to dictionary!\")\n            except:\n                print(\"   Failed to\
    \ convert to dictionary. Creating empty dictionary.\")\n                repo =\
    \ {}\n        \n        print(f\"\\n[OVERVIEW] REPOSITORY OVERVIEW\")\n      \
    \  report_lines.append(f\"\\n[OVERVIEW] REPOSITORY OVERVIEW\")\n        \n   \
    \     print(f\"   Name: {repo.get('repo_name', 'N/A')}\")\n        print(f\" \
    \  Full Name: {repo.get('full_name', 'N/A')}\")\n        print(f\"   Primary Language:\
    \ {repo.get('primary_language', 'N/A')}\")\n        print(f\"   Created: {repo.get('days_since_creation',\
    \ 0)} days ago\")\n        print(f\"   Last Updated: {repo.get('days_since_update',\
    \ 0)} days ago\")\n        \n        report_lines.append(f\"   Name: {repo.get('repo_name',\
    \ 'N/A')}\")\n        report_lines.append(f\"   Full Name: {repo.get('full_name',\
    \ 'N/A')}\")\n        report_lines.append(f\"   Primary Language: {repo.get('primary_language',\
    \ 'N/A')}\")\n        report_lines.append(f\"   Created: {repo.get('days_since_creation',\
    \ 0)} days ago\")\n        report_lines.append(f\"   Last Updated: {repo.get('days_since_update',\
    \ 0)} days ago\")\n        \n        print(f\"\\n[METRICS] POPULARITY METRICS\"\
    )\n        report_lines.append(f\"\\n[METRICS] POPULARITY METRICS\")\n       \
    \ \n        print(f\"   Stars: {repo.get('stars', 0):,}\")\n        print(f\"\
    \   Forks: {repo.get('forks', 0):,}\")\n        print(f\"   Total Engagement:\
    \ {repo.get('stars', 0) + repo.get('forks', 0):,}\")\n        print(f\"   Star-to-Fork\
    \ Ratio: {repo.get('star_to_fork_ratio', 0)}\")\n        print(f\"   Popularity\
    \ Tier: {repo.get('popularity_tier', 'N/A')}\")\n        \n        report_lines.append(f\"\
    \   Stars: {repo.get('stars', 0):,}\")\n        report_lines.append(f\"   Forks:\
    \ {repo.get('forks', 0):,}\")\n        report_lines.append(f\"   Total Engagement:\
    \ {repo.get('stars', 0) + repo.get('forks', 0):,}\")\n        report_lines.append(f\"\
    \   Star-to-Fork Ratio: {repo.get('star_to_fork_ratio', 0)}\")\n        report_lines.append(f\"\
    \   Popularity Tier: {repo.get('popularity_tier', 'N/A')}\")\n        \n     \
    \   print(f\"\\n[STATUS] ACTIVITY STATUS\")\n        report_lines.append(f\"\\\
    n[STATUS] ACTIVITY STATUS\")\n        \n        print(f\"   Status: {repo.get('activity_status',\
    \ 'N/A')}\")\n        report_lines.append(f\"   Status: {repo.get('activity_status',\
    \ 'N/A')}\")\n        \n        # Access additional data from original API response\n\
    \        if original_data:\n            print(f\"\\n[DETAILS] ADDITIONAL DETAILS\"\
    )\n            report_lines.append(f\"\\n[DETAILS] ADDITIONAL DETAILS\")\n   \
    \         \n            print(f\"   Description: {original_data.get('description',\
    \ 'N/A')}\")\n            report_lines.append(f\"   Description: {original_data.get('description',\
    \ 'N/A')}\")\n            \n            print(f\"   Website: {original_data.get('homepage',\
    \ 'N/A')}\")\n            report_lines.append(f\"   Website: {original_data.get('homepage',\
    \ 'N/A')}\")\n            \n            license_info = original_data.get('license',\
    \ {})\n            license_name = license_info.get('name', 'N/A') if isinstance(license_info,\
    \ dict) else 'N/A'\n            print(f\"   License: {license_name}\")\n     \
    \       report_lines.append(f\"   License: {license_name}\")\n            \n \
    \           print(f\"   Open Issues: {original_data.get('open_issues_count', 0)}\"\
    )\n            report_lines.append(f\"   Open Issues: {original_data.get('open_issues_count',\
    \ 0)}\")\n            \n            print(f\"   Default Branch: {original_data.get('default_branch',\
    \ 'N/A')}\")\n            report_lines.append(f\"   Default Branch: {original_data.get('default_branch',\
    \ 'N/A')}\")\n            \n            print(f\"   Repository Size: {original_data.get('size',\
    \ 0)} KB\")\n            report_lines.append(f\"   Repository Size: {original_data.get('size',\
    \ 0)} KB\")\n        \n        # Generate recommendations based on analysis\n\
    \        print(f\"\\n[INSIGHTS] ANALYSIS INSIGHTS\")\n        report_lines.append(f\"\
    \\n[INSIGHTS] ANALYSIS INSIGHTS\")\n        \n        star_fork_ratio = repo.get('star_to_fork_ratio',\
    \ 0)\n        if star_fork_ratio > 10:\n            print(\"   \u2022 High star-to-fork\
    \ ratio suggests strong user appreciation\")\n            report_lines.append(\"\
    \   \u2022 High star-to-fork ratio suggests strong user appreciation\")\n    \
    \    elif star_fork_ratio < 2:\n            print(\"   \u2022 Low star-to-fork\
    \ ratio suggests active contributor community\")\n            report_lines.append(\"\
    \   \u2022 Low star-to-fork ratio suggests active contributor community\")\n \
    \       \n        days_since_update = repo.get('days_since_update', 0)\n     \
    \   if days_since_update < 7:\n            print(\"   \u2022 Very recent activity\
    \ indicates active development\")\n            report_lines.append(\"   \u2022\
    \ Very recent activity indicates active development\")\n        elif days_since_update\
    \ > 365:\n            print(\"   \u2022 Long time since last update - may be mature\
    \ or inactive\")\n            report_lines.append(\"   \u2022 Long time since\
    \ last update - may be mature or inactive\")\n        \n        stars = repo.get('stars',\
    \ 0)\n        if stars > 50000:\n            print(\"   \u2022 Extremely popular\
    \ repository with large community\")\n            report_lines.append(\"   \u2022\
    \ Extremely popular repository with large community\")\n        \n        print(f\"\
    \\n[FLOW] DATA FLOW DEMONSTRATION\")\n        report_lines.append(f\"\\n[FLOW]\
    \ DATA FLOW DEMONSTRATION\")\n        \n        print(\"   - HTTP API call \u2192\
    \ GitHub repository data fetched\")\n        report_lines.append(\"   - HTTP API\
    \ call \u2192 GitHub repository data fetched\")\n        \n        print(\"  \
    \ - DuckDB processing \u2192 Metrics calculated and analyzed\") \n        report_lines.append(\"\
    \   - DuckDB processing \u2192 Metrics calculated and analyzed\")\n        \n\
    \        print(\"   - PostgreSQL storage \u2192 Data persisted with additional\
    \ fields\")\n        report_lines.append(\"   - PostgreSQL storage \u2192 Data\
    \ persisted with additional fields\")\n        \n        print(\"   - PostgreSQL\
    \ query \u2192 Final analysis performed\")\n        report_lines.append(\"   -\
    \ PostgreSQL query \u2192 Final analysis performed\")\n        \n        print(\"\
    \   - Python report \u2192 Comprehensive insights generated\")\n        report_lines.append(\"\
    \   - Python report \u2192 Comprehensive insights generated\")\n        \n   \
    \ else:\n        print(\"\\n[ERROR] No repository information found in context\"\
    )\n        report_lines.append(\"\\n[ERROR] No repository information found in\
    \ context\")\n        \n        print(\"Check the data flow between steps\")\n\
    \        report_lines.append(\"Check the data flow between steps\")\n        \n\
    \        print(f\"Available context keys: {list(context.keys())}\")\n        report_lines.append(f\"\
    Available context keys: {list(context.keys())}\")\n    \n    print(\"\\n\" + \"\
    =\"*60)\n    print(\"   REPORT GENERATION COMPLETED\")\n    print(\"=\"*60)\n\
    \    \n    report_lines.append(\"\\n\" + \"=\"*60)\n    report_lines.append(\"\
    \   REPORT GENERATION COMPLETED\")\n    report_lines.append(\"=\"*60)\n    \n\
    \    # Join all report lines into a single multiline string\n    full_report =\
    \ \"\\n\".join(report_lines)\n    \n    # Return structured results with the full\
    \ report\n    return {\n        'status': 'success',\n        'analyzed_repo':\
    \ repo if 'repo' in locals() else None,\n        'report_generated_at': datetime.now().isoformat(),\n\
    \        'data_sources': ['github_api', 'duckdb_analysis', 'postgres_storage'],\n\
    \        'with_attributes_used': [\n            'repo_name', 'repo_full_name',\
    \ 'stars_count', 'forks_count',\n            'table_name', 'repo_data', 'stats_data',\
    \ 'analysis_table',\n            'repository_info', 'original_api_data'\n    \
    \    ],\n        'full_report': full_report,\n        'report_text': full_report\n\
    \    }\n"
  next:
  - step: update_report_in_postgres
- data:
    db_host: '{{ workload.pg_host }}'
    db_port: '{{ workload.pg_port }}'
    db_user: '{{ workload.pg_user }}'
    db_password: '{{ workload.pg_password }}'
    db_name: '{{ workload.pg_db }}'
    report_text: '{{ generate_report.report_text }}'
  step: update_report_in_postgres
  desc: Update the repository analysis in PostgreSQL with the full report
  type: postgres
  command: "-- First, alter the table to add a full_report column if it doesn't exist\n\
    DO $$\nBEGIN\n    IF NOT EXISTS (\n        SELECT FROM information_schema.columns\
    \ \n        WHERE table_name = 'github_repo_analysis' \n        AND column_name\
    \ = 'full_report'\n    ) THEN\n        ALTER TABLE github_repo_analysis ADD COLUMN\
    \ full_report TEXT;\n    END IF;\nEND\n$$;\n\n-- Update the table with the full\
    \ report\n-- Use E'' string with escaped newlines to preserve multiline formatting\n\
    UPDATE github_repo_analysis\nSET full_report = E'{{ report_text }}';\n\n-- Verify\
    \ the update\nSELECT \n    repo_name,\n    full_name,\n    stars,\n    forks,\n\
    \    LEFT(full_report, 100) || '...' as report_preview,\n    LENGTH(full_report)\
    \ as report_length,\n    (SELECT COUNT(*) FROM regexp_matches(full_report, E'\\\
    \\n', 'g')) + 1 as line_count\nFROM github_repo_analysis;\n"
  next:
  - step: end
- step: end
  desc: End of data flow demonstration
