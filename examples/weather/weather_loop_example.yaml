# This is a NoETL DSL Playbook for iterating over cities to fetch and evaluate weather data.
# It includes a loop to process each city, fetch weather data, evaluate conditions, and handle alerts or logging.
# The playbooks demonstrates nested loops for processing city districts, with conditions to skip certain districts.
# noetl playbooks --execute --path "workflows/weather/weather_example" --payload '{"cities": [{"name": "New York", "lat": 40.71, "lon": -74.01}], "temperature_threshold": 30}'


apiVersion: noetl.io/v1
kind: Playbook
name: weather_example
path: examples/weather/weather_loop_example  # Unique path identifier for this playbooks

workload:  # Input parameters section accessible throughout the workflow
  jobId: "{{ job.uuid }}"
  state: ready
  cities:  # List of cities to process in the loop
    - name: "London"  # City name
      lat: 51.51  # Latitude
      lon: -0.13  # Longitude
    - name: "Paris"
      lat: 48.85
      lon: 2.35
    - name: "Berlin"
      lat: 52.52
      lon: 13.41
  base_url: "https://api.open-meteo.com/v1"  # Base URL for weather API
  temperature_threshold: 12  # Threshold for alerting on temperature
  # Postgres connection parameters (override via environment if desired)
  pg_host: "{{ env.POSTGRES_HOST | default('localhost') }}"
  pg_port: "{{ env.POSTGRES_PORT | default('30543') }}"
  pg_user: "{{ env.POSTGRES_USER | default('demo') }}"
  pg_password: "{{ env.POSTGRES_PASSWORD | default('demo') }}"
  pg_db: "{{ env.POSTGRES_DB | default('demo_noetl') }}"

workflow:  # Workflow steps and transitions
  - step: start  # Entry point of the workflow
    desc: "Start Weather Analysis Workflow"
    next:  # Transition rules based on condition
      - when: "{{ workload.state == 'ready' }}"  # Condition for transition
        then:
          - step: city_loop  # If condition met, goto city_loop step
      - else:
          - step: end  # If not ready, end the workflow

  - step: city_loop
    desc: "Iterate over cities using sub-playbook"
    type: playbook
    path: examples/weather/city_process
    loop:
      in: "{{ workload.cities }}"
      iterator: city
    with:
      city: "{{ city }}"
      base_url: "{{ workload.base_url }}"
      temperature_threshold: "{{ workload.temperature_threshold }}"
    next:
      - step: aggregate_alerts
        with:
          alerts: "{{ city_loop.results }}"

  # Steps between city_loop and end_city_loop were moved into examples/weather/city_process

  - step: aggregate_alerts
    desc: "Aggregate results after all city loops complete"
    type: workbook
    name: aggregate_alerts_task
    with:
      alerts: "{{ city_loop.results }}"
    next:
      - step: log_aggregate_result
        with:
          summary: "{{ aggregate_alerts.summary }}"

  - step: log_aggregate_result
    desc: "Log the aggregated alert summary"
    type: workbook
    name: log_aggregate_result_task
    with:
      summary: "{{ aggregate_alerts.summary }}"
    next:
      - when: "{{ aggregate_alerts.global_alert }}"
        then:
          - step: global_alert_step
      - else:
          - step: store_summary_duckdb

  - step: global_alert_step
    desc: "Send a global alert if any city triggered an alert"
    type: workbook
    name: global_alert_task
    with:
      summary: "{{ aggregate_alerts.summary }}"
    next:
      - step: store_summary_duckdb

  - step: store_summary_duckdb
    desc: "Persist aggregated summary into DuckDB"
    type: workbook
    name: store_summary_duckdb_task
    with:
      alert_cities: "{{ aggregate_alerts.summary.alert_cities }}"
      alert_count: "{{ aggregate_alerts.summary.count }}"
    next:
      - step: store_summary_postgres

  - step: store_summary_postgres
    desc: "Persist aggregated summary into Postgres"
    type: workbook
    name: store_summary_postgres_task
    with:
      alert_cities: '["test_city"]'
      alert_count: 1
      db_host: "{{ workload.pg_host }}"
      db_port: "{{ workload.pg_port }}"
      db_user: "{{ workload.pg_user }}"
      db_password: "{{ workload.pg_password }}"
      db_name: "{{ workload.pg_db }}"
    next:
      - step: end

  - step: end
    desc: "End of workflow"


workbook:
  - name: evaluate_weather
    type: python
    with:
      city: "{{ city }}"
      threshold: "{{ temperature_threshold }}"
      forecast_data: "{{ get_forecast }}"
    code: |
      def main(city, threshold, forecast_data):
          print(f"City: {city}")
          print(f"Threshold: {threshold}")
          print(f"Forecast data type: {type(forecast_data)}")
          threshold = float(threshold) if threshold else 5
          print(f"Threshold after conversion: {threshold}")
          temps = []
          if isinstance(forecast_data, dict):
              print(f"Forecast data keys: {forecast_data.keys()}")
              hourly = forecast_data.get('hourly', {})
              if isinstance(hourly, dict) and 'temperature_2m' in hourly:
                  temps = hourly['temperature_2m']
                  print(f"Found temps in hourly.temperature_2m: {temps}")
              elif 'data' in forecast_data and isinstance(forecast_data['data'], dict):
                  data = forecast_data['data']
                  print(f"Data keys: {data.keys()}")
                  data_hourly = data.get('hourly', {})
                  if isinstance(data_hourly, dict) and 'temperature_2m' in data_hourly:
                      temps = data_hourly['temperature_2m']
                      print(f"Found temps in data.hourly.temperature_2m: {temps}")
          max_temp = max(temps) if temps else 0
          print(f"Max temperature: {max_temp}")
          alert = max_temp > threshold
          print(f"Alert needed: {alert}")
          result = {
              "city": city["name"],
              "max_temp": max_temp,
              "alert": alert
          }
          print(f"Returning result: {result}")
          return result

  - name: alert_task
    type: http
    method: POST
    endpoint: "https://postman-echo.com/post"
    payload:
      city: "{{ city }}"
      temperature: "{{ temperature }}"
      message: "High temperature alert."

  - name: log_task
    type: http
    method: POST
    endpoint: "https://postman-echo.com/post"
    payload:
      city: "{{ city }}"
      message: "No alert needed."

  - name: get_city_districts
    type: http
    method: GET
    endpoint: "https://postman-echo.com/post"

  - name: process_district
    type: python
    with:
      city: "{{ city }}"
      district: "{{ district }}"
    code: |
      def main(city, district):
          return {
              "city": city["name"],
              "district": district["name"],
              "processed": True,
              "timestamp": "2024-01-01T12:00:00Z"
          }

  - name: aggregate_alerts_task
    type: python
    with:
      alerts: "{{ alerts }}"
    code: |
      def main(alerts):
          import ast
          # Normalize alerts input
          if isinstance(alerts, str):
              try:
                  alerts = ast.literal_eval(alerts)
              except Exception:
                  alerts = []
          alerts = alerts or []

          # Unwrap nested results if coming from sub-playbook aggregates
          normalized = []
          for item in alerts:
              if isinstance(item, dict):
                  if 'fetch_and_evaluate' in item and isinstance(item['fetch_and_evaluate'], dict):
                      normalized.append(item['fetch_and_evaluate'])
                  else:
                      normalized.append(item)
          
          # Compute summary
          alert_cities = [a for a in normalized if isinstance(a, dict) and a.get('alert')]
          global_alert = bool(alert_cities)
          summary = {
              "alert_cities": [a.get("city") for a in alert_cities],
              "count": len(alert_cities)
          }
          return {"global_alert": global_alert, "summary": summary}

  - name: global_alert_task
    type: http
    method: POST
    endpoint: "https://postman-echo.com/post"
    payload:
      summary: "{{ summary }}"
      message: "Global weather alert triggered."

  - name: log_aggregate_result_task
    type: python
    with:
      summary: "{{ summary }}"
    code: |
      def main(summary):
          print(f"Aggregated weather alert summary: {summary}")
          return {"logged": True, "summary": summary}

  - name: store_summary_duckdb_task
    type: duckdb
    with:
      alert_cities: "{{ alert_cities }}"
      alert_count: "{{ alert_count }}"
    command: |
      -- Create DuckDB table for weather alert summary and insert the current summary
      CREATE TABLE IF NOT EXISTS weather_alert_summary (
        id BIGINT,
        alert_cities TEXT,
        alert_count INTEGER,
        created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
      );
      -- Insert aggregated summary. DuckDB does not support SQLite's strftime('%s', ...); use date_part('epoch', ...) for epoch seconds
      INSERT INTO weather_alert_summary (id, alert_cities, alert_count)
        VALUES ((date_part('epoch', current_timestamp)*1000)::BIGINT, '{{ alert_cities | tojson }}', {{ alert_count }});

      SELECT * FROM weather_alert_summary ORDER BY created_at DESC LIMIT 5;

  - name: store_summary_postgres_task
    type: postgres
    with:
      alert_cities: "{{ alert_cities }}"
      alert_count: "{{ alert_count }}"
      db_host: "{{ workload.pg_host }}"
      db_port: "{{ workload.pg_port }}"
      db_user: "{{ workload.pg_user }}"
      db_password: "{{ workload.pg_password }}"
      db_name: "{{ workload.pg_db }}"
    command: |
      -- Insert aggregated weather alert summary into Postgres
      -- Ensure target table exists
      CREATE TABLE IF NOT EXISTS weather_alert_summary (
        id SERIAL PRIMARY KEY,
        alert_cities TEXT,
        alert_count INTEGER,
        created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
      );

      -- Insert aggregated summary
      INSERT INTO weather_alert_summary (alert_cities, alert_count)
        VALUES ('{{ alert_cities | tojson }}', {{ alert_count }});

      -- Return a small result preview
      SELECT * FROM weather_alert_summary ORDER BY id DESC LIMIT 5;
