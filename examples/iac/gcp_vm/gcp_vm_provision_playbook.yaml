apiVersion: noetl.io/v1
kind: Playbook
name: gcp_vm_provision
path: gcp/vm_provision
workload:
  jobId: '{{ job.uuid }}'
  execution_id: '{{ job.uuid }}'
  project_id: '{{ env.GCP_PROJECT_ID | default(''your-gcp-project-id'') }}'
  zone: '{{ env.GCP_ZONE | default(''us-central1-a'') }}'
  machine_type: '{{ env.GCP_MACHINE_TYPE | default(''f1-micro'') }}'
  vm_name: '{{ env.GCP_VM_NAME | default(''noetl-test-vm'') }}'
  pg_host: '{{ env.POSTGRES_HOST | default(''localhost'') }}'
  pg_port: '{{ env.POSTGRES_PORT | default(''5432'') }}'
  pg_user: '{{ env.POSTGRES_USER | default(''postgres'') }}'
  pg_password: '{{ env.POSTGRES_PASSWORD | default(''postgres'') }}'
  pg_db: '{{ env.POSTGRES_DB | default(''noetl'') }}'
workflow:
- step: start
  desc: Start GCP VM Provisioning Workflow
  next:
  - step: create_vm_tracking_table
- step: create_vm_tracking_table
  desc: Create VM tracking table in PostgreSQL if not exists
  type: workbook
  task: create_vm_tracking_table_task
  next:
  - step: get_gcp_access_token
- step: get_gcp_access_token
  desc: Get GCP access token for API authentication
  type: workbook
  task: get_gcp_access_token_task
  next:
  - step: provision_vm
- data:
    access_token: '{{ get_gcp_access_token.access_token }}'
  step: provision_vm
  desc: Provision VM in Google Cloud using REST API
  type: workbook
  task: provision_vm_task
  next:
  - step: track_vm_creation
- data:
    vm_operation: '{{ provision_vm.data }}'
  step: track_vm_creation
  desc: Track VM creation in PostgreSQL
  type: workbook
  task: track_vm_creation_task
  next:
  - step: check_vm_status
- data:
    access_token: '{{ get_gcp_access_token.access_token }}'
    operation_name: '{{ provision_vm.data.name }}'
  step: check_vm_status
  desc: Check VM creation status
  type: workbook
  task: check_vm_status_task
  next:
  - step: get_vm_details
    condition: '{{ check_vm_status.data.status == ''DONE'' and check_vm_status.data.error
      is not defined }}'
  - step: handle_vm_error
    condition: '{{ check_vm_status.data.status == ''DONE'' and check_vm_status.data.error
      is defined }}'
  - step: wait_and_check_again
    condition: '{{ check_vm_status.data.status != ''DONE'' }}'
- step: wait_and_check_again
  desc: Wait and check VM status again
  type: workbook
  task: wait_task
  next:
  - step: check_vm_status
- data:
    error_details: '{{ check_vm_status.data.error }}'
  step: handle_vm_error
  desc: Handle VM creation error
  type: workbook
  task: handle_vm_error_task
  next:
  - step: end
- data:
    access_token: '{{ get_gcp_access_token.access_token }}'
  step: get_vm_details
  desc: Get VM details after successful creation
  type: workbook
  task: get_vm_details_task
  next:
  - step: store_vm_details
- data:
    vm_details: '{{ get_vm_details.data }}'
  step: store_vm_details
  desc: Store VM details in PostgreSQL
  type: workbook
  task: store_vm_details_task
  next:
  - step: transform_vm_data
- step: transform_vm_data
  desc: Transform VM data using DuckDB
  type: workbook
  task: transform_vm_data_task
  next:
  - step: end
- data:
    result: VM provisioning workflow completed
  step: end
  desc: End of workflow
workbook:
- name: create_vm_tracking_table_task
  type: postgres
  command: "CREATE TABLE IF NOT EXISTS gcp_vm_instances (\n  id SERIAL PRIMARY KEY,\n\
    \  execution_id VARCHAR(64),\n  vm_name VARCHAR(100),\n  project_id VARCHAR(100),\n\
    \  zone VARCHAR(50),\n  machine_type VARCHAR(50),\n  status VARCHAR(20),\n  creation_timestamp\
    \ TIMESTAMP,\n  last_updated TIMESTAMP DEFAULT NOW(),\n  ip_address VARCHAR(20),\n\
    \  network VARCHAR(100),\n  cpu_platform VARCHAR(50),\n  disk_size_gb INTEGER,\n\
    \  disk_type VARCHAR(50),\n  metadata JSONB,\n  labels JSONB,\n  raw_details JSONB\n\
    );\n\nCREATE TABLE IF NOT EXISTS gcp_vm_operations (\n  id SERIAL PRIMARY KEY,\n\
    \  execution_id VARCHAR(64),\n  operation_id VARCHAR(100),\n  operation_type VARCHAR(50),\n\
    \  target_vm VARCHAR(100),\n  status VARCHAR(20),\n  start_time TIMESTAMP DEFAULT\
    \ NOW(),\n  end_time TIMESTAMP,\n  error_message TEXT,\n  raw_response JSONB\n\
    );\n"
- name: get_gcp_access_token_task
  type: python
  code: "def main():\n    import subprocess\n    import json\n    \n    try:\n   \
    \     # Use gcloud CLI to get access token (in a real environment)\n        #\
    \ This is a simulation for the example\n        # In production, you would use\
    \ a service account key or OAuth2\n        \n        # Simulated token for demonstration\
    \ purposes\n        # In a real environment, you would use:\n        # result\
    \ = subprocess.run([\"gcloud\", \"auth\", \"print-access-token\"], capture_output=True,\
    \ text=True)\n        # access_token = result.stdout.strip()\n        \n     \
    \   # For this example, we'll use a placeholder token\n        access_token =\
    \ \"ya29.EXAMPLE-ACCESS-TOKEN-FOR-DEMO-PURPOSES-ONLY\"\n        \n        return\
    \ {\n            \"status\": \"success\",\n            \"access_token\": access_token,\n\
    \            \"message\": \"Successfully retrieved GCP access token (simulated\
    \ for demo)\"\n        }\n        \n    except Exception as e:\n        return\
    \ {\n            \"status\": \"error\",\n            \"message\": f\"Failed to\
    \ get GCP access token: {str(e)}\"\n        }\n"
- name: provision_vm_task
  type: http
  method: POST
  endpoint: https://compute.googleapis.com/compute/v1/projects/{{ workload.project_id
    }}/zones/{{ workload.zone }}/instances
  headers:
    Content-Type: application/json
    Authorization: Bearer {{ access_token }}
  payload:
    name: '{{ workload.vm_name }}'
    machineType: projects/{{ workload.project_id }}/zones/{{ workload.zone }}/machineTypes/{{
      workload.machine_type }}
    disks:
    - boot: true
      autoDelete: true
      initializeParams:
        sourceImage: projects/debian-cloud/global/images/family/debian-11
        diskSizeGb: '10'
        diskType: projects/{{ workload.project_id }}/zones/{{ workload.zone }}/diskTypes/pd-standard
    networkInterfaces:
    - network: projects/{{ workload.project_id }}/global/networks/default
      accessConfigs:
      - name: External NAT
        type: ONE_TO_ONE_NAT
    metadata:
      items:
      - key: startup-script
        value: '#!/bin/bash

          echo ''VM provisioned by NoETL'' > /tmp/noetl_provision.log'
    labels:
      environment: test
      provisioner: noetl
- data:
    vm_operation: '{{ vm_operation }}'
  name: track_vm_creation_task
  type: postgres
  command: "INSERT INTO gcp_vm_operations (\n  execution_id, \n  operation_id, \n\
    \  operation_type, \n  target_vm, \n  status, \n  raw_response\n)\nVALUES (\n\
    \  '{{ job.uuid }}',\n  '{{ vm_operation.name | default(\"unknown\") }}',\n  'insert',\n\
    \  '{{ workload.vm_name }}',\n  '{{ vm_operation.status | default(\"PENDING\"\
    ) }}',\n  '{{ vm_operation | tojson }}'\n);\n"
- name: check_vm_status_task
  type: http
  method: GET
  endpoint: https://compute.googleapis.com/compute/v1/projects/{{ workload.project_id
    }}/zones/{{ workload.zone }}/operations/{{ operation_name }}
  headers:
    Authorization: Bearer {{ access_token }}
- name: wait_task
  type: python
  code: "def main():\n    import time\n    \n    # Wait for 10 seconds before checking\
    \ again\n    time.sleep(10)\n    \n    return {\n        \"status\": \"success\"\
    ,\n        \"message\": \"Waited 10 seconds before checking VM status again\"\n\
    \    }\n"
- data:
    error_details: '{{ error_details }}'
  name: handle_vm_error_task
  type: postgres
  command: "UPDATE gcp_vm_operations\nSET \n  status = 'ERROR',\n  end_time = NOW(),\n\
    \  error_message = '{{ error_details.errors[0].message | default(\"Unknown error\"\
    ) }}'\nWHERE \n  execution_id = '{{ job.uuid }}'\nAND\n  target_vm = '{{ workload.vm_name\
    \ }}';\n"
- name: get_vm_details_task
  type: http
  method: GET
  endpoint: https://compute.googleapis.com/compute/v1/projects/{{ workload.project_id
    }}/zones/{{ workload.zone }}/instances/{{ workload.vm_name }}
  headers:
    Authorization: Bearer {{ access_token }}
- data:
    vm_details: '{{ vm_details }}'
  name: store_vm_details_task
  type: postgres
  command: "INSERT INTO gcp_vm_instances (\n  execution_id,\n  vm_name,\n  project_id,\n\
    \  zone,\n  machine_type,\n  status,\n  creation_timestamp,\n  ip_address,\n \
    \ network,\n  cpu_platform,\n  disk_size_gb,\n  disk_type,\n  metadata,\n  labels,\n\
    \  raw_details\n)\nVALUES (\n  '{{ job.uuid }}',\n  '{{ vm_details.name }}',\n\
    \  '{{ workload.project_id }}',\n  '{{ workload.zone }}',\n  '{{ workload.machine_type\
    \ }}',\n  '{{ vm_details.status }}',\n  '{{ vm_details.creationTimestamp }}',\n\
    \  '{{ vm_details.networkInterfaces[0].accessConfigs[0].natIP | default(\"\")\
    \ }}',\n  '{{ vm_details.networkInterfaces[0].network | default(\"default\") }}',\n\
    \  '{{ vm_details.cpuPlatform | default(\"unknown\") }}',\n  {{ vm_details.disks[0].diskSizeGb\
    \ | default(10) }},\n  '{{ vm_details.disks[0].type | default(\"pd-standard\"\
    ) }}',\n  '{{ vm_details.metadata | tojson }}',\n  '{{ vm_details.labels | tojson\
    \ }}',\n  '{{ vm_details | tojson }}'\n);\n\nUPDATE gcp_vm_operations\nSET \n\
    \  status = 'DONE',\n  end_time = NOW()\nWHERE \n  execution_id = '{{ job.uuid\
    \ }}'\nAND\n  target_vm = '{{ workload.vm_name }}';\n"
- name: transform_vm_data_task
  type: duckdb
  command: "-- Install and load PostgreSQL extension\nINSTALL postgres;\nLOAD postgres;\n\
    \n-- Create PostgreSQL secret for authentication\nCREATE OR REPLACE SECRET postgres_secret\
    \ (\n    TYPE POSTGRES,\n    HOST '{{ workload.pg_host }}',\n    PORT {{ workload.pg_port\
    \ }},\n    DATABASE '{{ workload.pg_db }}',\n    USER '{{ workload.pg_user }}',\n\
    \    PASSWORD '{{ workload.pg_password }}'\n);\n\n-- Attach PostgreSQL database\n\
    ATTACH DATABASE 'postgres_secret' AS postgres_db (TYPE postgres);\n\n-- Create\
    \ a summary view of VM instances\nCREATE OR REPLACE TABLE vm_summary AS\nSELECT\
    \ \n  vm_name,\n  project_id,\n  zone,\n  machine_type,\n  status,\n  creation_timestamp,\n\
    \  ip_address,\n  cpu_platform,\n  disk_size_gb\nFROM postgres_db.gcp_vm_instances\n\
    WHERE execution_id = '{{ job.uuid }}';\n\n-- Show the summary\nSELECT * FROM vm_summary;\n\
    \n-- Export the summary to CSV\nCOPY vm_summary TO '/tmp/vm_summary_{{ job.uuid\
    \ }}.csv' (HEADER, DELIMITER ',');\n\n-- Clean up\nDROP TABLE vm_summary;\nDROP\
    \ SECRET postgres_secret;"
